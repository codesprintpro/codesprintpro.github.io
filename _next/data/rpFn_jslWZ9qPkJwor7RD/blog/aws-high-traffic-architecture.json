{"pageProps":{"post":{"title":"AWS Architecture Patterns for High-Traffic Applications","description":"Learn how to architect systems that handle millions of requests on AWS — covering load balancing, auto-scaling, RDS with read replicas, ElastiCache, SQS decoupling, and CloudFront CDN.","date":"2025-01-19","category":"AWS","tags":["aws","architecture","high availability","scalability","cloud"],"featured":false,"affiliateSection":"aws-resources","slug":"aws-high-traffic-architecture","readingTime":"14 min read","excerpt":"Architecting on AWS is not about using every service in the catalog — it's about choosing the right services for your scale, stitching them together correctly, and understanding the failure modes of each. This article wa…","contentHtml":"<p>Architecting on AWS is not about using every service in the catalog — it's about choosing the right services for your scale, stitching them together correctly, and understanding the failure modes of each. This article walks through a production-grade, high-traffic architecture with the reasoning behind each decision.</p>\n<h2>The Reference Architecture</h2>\n<p>Before diving into each layer, it helps to see how all the pieces fit together. The diagram below shows the full request path — from a user's browser through DNS, CDN, load balancer, compute, caching, and into the database, with async job processing on the side. Understanding this end-to-end flow will make each layer's purpose clearer as you build it.</p>\n<pre><code>Internet\n    │\n    ▼\n┌───────────────────────────────────────────┐\n│           Route 53 (DNS)                  │\n│    Latency-based routing to nearest region│\n└─────────────────┬─────────────────────────┘\n                  │\n    ┌─────────────▼──────────────┐\n    │    CloudFront CDN           │\n    │    Static assets + API cache│\n    │    WAF + Shield protection  │\n    └─────────────┬──────────────┘\n                  │\n    ┌─────────────▼──────────────┐\n    │  Application Load Balancer  │\n    │  (ALB) — path-based routing │\n    └──┬──────────┬──────────────┘\n       │          │\n  ┌────▼──┐  ┌────▼──────────┐\n  │ ECS   │  │  ECS Fargate  │\n  │Fargate│  │  (API service)│\n  │(web)  │  │  Auto-scaling │\n  └────┬──┘  └────┬──────────┘\n       │          │\n       └────┬─────┘\n            │\n  ┌─────────▼──────────────────────────┐\n  │           ElastiCache Redis         │\n  │     (session, hot data, rate limit) │\n  └─────────────────┬──────────────────┘\n                    │ cache miss\n  ┌─────────────────▼──────────────────┐\n  │        RDS Aurora PostgreSQL        │\n  │   Primary (writes) + Reader x2      │\n  │   Multi-AZ, automatic failover      │\n  └─────────────────┬──────────────────┘\n                    │\n  ┌─────────────────▼──────────────────┐\n  │              SQS                    │\n  │    (async job decoupling)           │\n  └─────────────────┬──────────────────┘\n                    │\n  ┌─────────────────▼──────────────────┐\n  │         Lambda / ECS Workers        │\n  │    (email, notifications, reports)  │\n  └────────────────────────────────────┘\n</code></pre>\n<p>Notice that no single component handles the entire request — each layer offloads work to the next. This separation of concerns is what lets the system scale each component independently without rebuilding the whole stack.</p>\n<h2>Layer 1: Traffic Entry — CloudFront + WAF</h2>\n<p>CloudFront is your first line of defense and performance optimization. Deploy it in front of everything — not just static assets.</p>\n<p>Before writing any Terraform, it is worth understanding how CloudFront decides what to cache and for how long. The cache behavior table below maps URL path patterns to caching policies — this is the design decision that determines how much traffic ever reaches your origin servers. Without this differentiation, you either cache user-specific data incorrectly or miss the opportunity to cache public data entirely.</p>\n<pre><code>CloudFront use cases:\n1. Static assets (S3): JS, CSS, images → cached at 600+ edge locations globally\n2. API responses: Cache GET endpoints with low volatility (product catalog, pricing)\n3. DDoS mitigation: CloudFront + AWS Shield Standard absorbs L3/L4 attacks for free\n\nCloudFront cache behaviors:\n  Path: /static/*           → Cache: 1 year, compress: gzip/brotli\n  Path: /api/products/*     → Cache: 5 minutes (TTL), invalidate on update\n  Path: /api/user/*         → No cache (personalized)\n  Path: /api/checkout/*     → No cache, forward all headers\n</code></pre>\n<p>The following Terraform resource creates the CloudFront distribution with two cache behaviors: a default behavior with no caching (safe for dynamic API responses) and an ordered behavior for static assets with a one-year TTL. The <code>web_acl_id</code> attachment is what connects WAF rules — without it, your CDN layer has no protection against malicious traffic patterns.</p>\n<pre><code class=\"language-terraform\">resource \"aws_cloudfront_distribution\" \"main\" {\n  origin {\n    domain_name = aws_lb.main.dns_name\n    origin_id   = \"alb-origin\"\n\n    custom_origin_config {\n      http_port              = 80\n      https_port             = 443\n      origin_protocol_policy = \"https-only\"\n      origin_ssl_protocols   = [\"TLSv1.2\"]\n    }\n  }\n\n  default_cache_behavior {\n    allowed_methods        = [\"DELETE\", \"GET\", \"HEAD\", \"OPTIONS\", \"PATCH\", \"POST\", \"PUT\"]\n    cached_methods         = [\"GET\", \"HEAD\"]\n    target_origin_id       = \"alb-origin\"\n    viewer_protocol_policy = \"redirect-to-https\"\n    compress               = true\n\n    forwarded_values {\n      query_string = true\n      headers      = [\"Authorization\", \"Origin\"]\n      cookies { forward = \"none\" }\n    }\n\n    min_ttl     = 0\n    default_ttl = 0   # No caching for dynamic content by default\n    max_ttl     = 86400\n  }\n\n  # Static assets: long cache\n  ordered_cache_behavior {\n    path_pattern     = \"/static/*\"\n    min_ttl          = 86400\n    default_ttl      = 31536000  # 1 year\n    max_ttl          = 31536000\n    compress         = true\n    # ... same methods and origin\n  }\n\n  web_acl_id = aws_wafv2_web_acl.main.arn\n  price_class = \"PriceClass_100\"  # US + Europe edge locations only (cost optimization)\n}\n</code></pre>\n<p>The <code>price_class = \"PriceClass_100\"</code> setting limits edge locations to the US and Europe — a deliberate cost tradeoff. If your users are global, bump this to <code>PriceClass_All</code>. Every cache hit here means one fewer request hitting your ALB and compute layer, which is where real money and latency accumulates at scale.</p>\n<h2>Layer 2: Load Balancing — ALB vs NLB</h2>\n<p>Requests that miss the CDN cache arrive at your load balancer. The choice between ALB and NLB matters because they operate at different OSI layers and have very different cost and feature profiles.</p>\n<p><strong>ALB (Application Load Balancer)</strong> for HTTP/HTTPS:</p>\n<ul>\n<li>Path-based routing: <code>/api/*</code> → API service, <code>/admin/*</code> → admin service</li>\n<li>Host-based routing: <code>api.example.com</code> → API target group</li>\n<li>Request tracing (X-Amzn-Trace-Id headers)</li>\n<li>Native gRPC support</li>\n<li>Cost: ~$16/month base + per LCU</li>\n</ul>\n<p><strong>NLB (Network Load Balancer)</strong> for TCP/UDP:</p>\n<ul>\n<li>Ultra-low latency (&#x3C; 1ms) for TCP-based protocols</li>\n<li>Static IP per AZ (needed for IP whitelisting)</li>\n<li>Handles millions of connections per second</li>\n<li>Use for: gaming servers, WebSockets at extreme scale, Kafka MSK clusters</li>\n</ul>\n<p>For standard web APIs, ALB is the right choice.</p>\n<p>The target group health check configuration below is where most teams make silent mistakes. The <code>DeregistrationDelay</code> setting is especially important — without a drain period, the ALB will send requests to containers that have already started shutting down, producing mysterious 502 errors during deployments.</p>\n<pre><code class=\"language-yaml\"># ALB target group settings for containerized services\nTargetGroup:\n  HealthCheck:\n    Path: /health\n    HealthyThresholdCount: 2     # 2 consecutive successes = healthy\n    UnhealthyThresholdCount: 3   # 3 consecutive failures = unhealthy\n    Interval: 15                 # Check every 15s\n    Timeout: 5\n  DeregistrationDelay: 30        # Drain connections for 30s before removing instance\n  Protocol: HTTP\n  Port: 8080\n</code></pre>\n<h2>Layer 3: Compute — ECS Fargate with Auto-Scaling</h2>\n<p>ECS Fargate eliminates EC2 management while providing container orchestration. With the traffic entry layer handling caching and routing, your Fargate tasks only need to handle requests that actually require compute — but they need to scale efficiently when traffic spikes.</p>\n<p>The auto-scaling policy below uses three metrics simultaneously. Relying on CPU alone is a common mistake — a memory-bound service or a queue-driven spike will not show CPU pressure until it is already too late. Using all three signals means the system reacts correctly regardless of the bottleneck type.</p>\n<pre><code class=\"language-yaml\"># ECS Service auto-scaling configuration\nAutoScaling:\n  MinCapacity: 2                 # Never scale below 2 (for HA across AZs)\n  MaxCapacity: 50\n\n  ScalingPolicy:\n    Type: TargetTrackingScaling\n    Metrics:\n      - ECSServiceAverageCPUUtilization: 70%  # Scale out when CPU > 70%\n      - ECSServiceAverageMemoryUtilization: 80%\n      - ALBRequestCountPerTarget: 1000         # Scale out at 1000 req/target\n\n  # Scale-in protection: don't kill instances handling long requests\n  ScaleInCooldown: 300           # Wait 5 minutes after scale-in\n  ScaleOutCooldown: 60           # Scale out quickly\n</code></pre>\n<p>Note the asymmetric cooldowns: scale out fast (60 seconds) to absorb traffic spikes, but scale in slowly (300 seconds) to avoid terminating containers mid-request. If your containers handle long-running operations, increase the scale-in cooldown to match your p99 request duration.</p>\n<p><strong>Container configuration for production:</strong></p>\n<p>The container definition below wires together all the details ECS needs to run your service safely. Pay particular attention to the <code>startPeriod</code> in the health check — this gives the JVM or application framework time to initialize before ECS starts counting health check failures. Set it too low and ECS will kill healthy containers before they finish starting up.</p>\n<pre><code class=\"language-json\">{\n  \"name\": \"api-service\",\n  \"image\": \"123456789.dkr.ecr.us-east-1.amazonaws.com/api:latest\",\n  \"cpu\": 512,\n  \"memory\": 1024,\n  \"environment\": [\n    {\"name\": \"SPRING_PROFILES_ACTIVE\", \"value\": \"prod\"},\n    {\"name\": \"DB_URL\", \"valueFrom\": \"arn:aws:ssm:us-east-1::parameter/prod/db-url\"}\n  ],\n  \"healthCheck\": {\n    \"command\": [\"CMD-SHELL\", \"curl -f http://localhost:8080/health || exit 1\"],\n    \"interval\": 15,\n    \"timeout\": 5,\n    \"retries\": 3,\n    \"startPeriod\": 60\n  },\n  \"logConfiguration\": {\n    \"logDriver\": \"awslogs\",\n    \"options\": {\n      \"awslogs-group\": \"/ecs/api-service\",\n      \"awslogs-region\": \"us-east-1\",\n      \"awslogs-stream-prefix\": \"ecs\"\n    }\n  }\n}\n</code></pre>\n<h2>Layer 4: Caching — ElastiCache Redis</h2>\n<p>ElastiCache Redis reduces database load by 80-95% for read-heavy workloads. Before choosing a caching pattern, you need to understand the tradeoffs — each pattern has different consistency guarantees and failure behavior, and picking the wrong one is a common source of bugs in high-traffic systems.</p>\n<pre><code>Cache patterns:\n\n1. Cache-aside (most common):\n   Read: Check cache → miss → read DB → write cache → return\n   Write: Update DB → invalidate cache (or write-through)\n\n2. Write-through:\n   Write: Update DB + update cache (synchronously)\n   Read: Always from cache (never a miss)\n   Downside: Cache is never stale; write latency increases\n\n3. Write-behind (write-back):\n   Write: Update cache → queue DB write asynchronously\n   Risk: Cache failure = data loss\n   Use for: Click counters, view counts (high-write, low-loss-risk)\n</code></pre>\n<p>Cache-aside is the default for most API workloads because it tolerates cache failures gracefully — a cache miss just falls through to the database. Write-through is the right choice when staleness is unacceptable (e.g., financial balances). Write-behind is only appropriate when you can accept losing writes in a cache failure scenario.</p>\n<p>The Terraform configuration below provisions a Redis replication group with automatic failover and Multi-AZ enabled. The <code>num_cache_clusters: 3</code> setting gives you one primary and two replicas — if the primary fails, AWS automatically promotes a replica within seconds. Without <code>automatic_failover_enabled</code>, your application would be writing to a dead primary until you manually intervened.</p>\n<pre><code class=\"language-terraform\">resource \"aws_elasticache_replication_group\" \"redis\" {\n  replication_group_id       = \"prod-redis\"\n  description                = \"Production Redis cluster\"\n  node_type                  = \"cache.r7g.large\"  # 13.07 GB RAM\n  num_cache_clusters         = 3                  # 1 primary + 2 replicas\n  automatic_failover_enabled = true               # Auto-promote replica on primary failure\n  multi_az_enabled           = true               # Spread across AZs\n  at_rest_encryption_enabled = true\n  transit_encryption_enabled = true\n  auth_token                 = var.redis_auth_token\n\n  # Maintenance window during low traffic\n  maintenance_window = \"sun:05:00-sun:06:00\"\n  snapshot_window    = \"04:00-05:00\"\n  snapshot_retention_limit = 7  # Keep 7 days of snapshots\n}\n</code></pre>\n<h2>Layer 5: Database — RDS Aurora PostgreSQL</h2>\n<p>With caching handling the majority of reads, your database primarily needs to handle writes and cache misses. Aurora PostgreSQL is the right choice here because it gives you PostgreSQL compatibility with a distributed storage engine built for high availability.</p>\n<p>Aurora is PostgreSQL-compatible but with a distributed storage engine that provides:</p>\n<ul>\n<li><strong>6-way replication</strong> across 3 AZs automatically (no configuration needed)</li>\n<li><strong>15 read replicas</strong> per cluster (vs 5 for standard RDS)</li>\n<li><strong>Aurora Serverless v2</strong> for variable workloads (scales instantly from 0.5 to 128 ACUs)</li>\n<li><strong>Sub-second failover</strong> (vs 60-120s for standard RDS Multi-AZ)</li>\n</ul>\n<p>At scale, a single database connection pool pointed at the writer endpoint becomes a bottleneck. The Java configuration below implements read/write splitting — writes always go to the primary Aurora writer, and reads tagged with <code>@Transactional(readOnly=true)</code> are routed to the reader endpoint, which Aurora load-balances across your replicas. This pattern alone can offload 70-90% of your database traffic off the primary.</p>\n<pre><code class=\"language-java\">// Java connection configuration with read/write splitting\n@Configuration\npublic class DataSourceConfig {\n\n    @Bean\n    @Primary\n    public DataSource writeDataSource() {\n        HikariConfig config = new HikariConfig();\n        config.setJdbcUrl(System.getenv(\"AURORA_WRITER_ENDPOINT\")); // cluster endpoint\n        config.setMaximumPoolSize(20);\n        config.setMinimumIdle(5);\n        config.setConnectionTimeout(3000);\n        config.setIdleTimeout(600000);\n        return new HikariDataSource(config);\n    }\n\n    @Bean\n    public DataSource readDataSource() {\n        HikariConfig config = new HikariConfig();\n        config.setJdbcUrl(System.getenv(\"AURORA_READER_ENDPOINT\")); // reader endpoint = load balanced across replicas\n        config.setMaximumPoolSize(50); // Readers can handle more connections\n        config.setReadOnly(true);\n        return new HikariDataSource(config);\n    }\n\n    // Route @Transactional(readOnly=true) to reader, writes to primary\n    @Bean\n    public DataSource routingDataSource(\n            @Qualifier(\"writeDataSource\") DataSource write,\n            @Qualifier(\"readDataSource\") DataSource read) {\n        Map&#x3C;Object, Object> dataSources = new HashMap&#x3C;>();\n        dataSources.put(\"write\", write);\n        dataSources.put(\"read\", read);\n\n        AbstractRoutingDataSource routing = new AbstractRoutingDataSource() {\n            @Override\n            protected Object determineCurrentLookupKey() {\n                return TransactionSynchronizationManager.isCurrentTransactionReadOnly()\n                    ? \"read\" : \"write\";\n            }\n        };\n        routing.setTargetDataSources(dataSources);\n        routing.setDefaultTargetDataSource(write);\n        return routing;\n    }\n}\n</code></pre>\n<p>The key takeaway: the <code>AbstractRoutingDataSource</code> inspects Spring's <code>TransactionSynchronizationManager</code> at runtime to choose the datasource — no application code needs to know which database it is talking to. Your existing <code>@Transactional(readOnly=true)</code> annotations on service methods are the only signal needed to route traffic correctly.</p>\n<h2>Layer 6: Async Decoupling — SQS + Lambda</h2>\n<p>Synchronous calls to slow operations (email, PDF generation, third-party APIs) increase latency and reduce availability. Decouple them with SQS.</p>\n<p>The problem this solves is straightforward: if sending an order confirmation email takes 800ms and Mailgun is down, your <code>/checkout</code> endpoint fails with a 503. By publishing to SQS instead, the order creation succeeds in under 50ms and the email delivery retries independently — a failure in the downstream system no longer propagates back to your user.</p>\n<pre><code class=\"language-java\">// Publish to SQS (non-blocking, returns immediately)\n@Service\npublic class OrderService {\n\n    @Autowired\n    private SqsAsyncClient sqsClient;\n\n    @Value(\"${sqs.order-events.url}\")\n    private String queueUrl;\n\n    public Order createOrder(OrderRequest request) {\n        Order order = orderRepository.save(buildOrder(request));\n\n        // Async: don't wait for these — they'll process in background\n        sqsClient.sendMessage(SendMessageRequest.builder()\n            .queueUrl(queueUrl)\n            .messageBody(objectMapper.writeValueAsString(new OrderCreatedEvent(order)))\n            .messageGroupId(order.getUserId())         // FIFO: preserve per-user order\n            .messageDeduplicationId(order.getId())     // Idempotent\n            .build());\n\n        return order; // Return immediately — don't wait for email/notification\n    }\n}\n\n// Lambda consumer: processes SQS messages\n@Component\npublic class OrderEventHandler {\n\n    @SqsListener(\"${sqs.order-events.url}\")\n    public void handleOrderCreated(OrderCreatedEvent event) {\n        emailService.sendOrderConfirmation(event);\n        inventoryService.reserve(event.getItems());\n        analyticsService.trackConversion(event);\n    }\n}\n</code></pre>\n<p><strong>SQS Configuration for reliability:</strong></p>\n<p>The Terraform configuration below is where the resilience is actually built. The dead letter queue with <code>maxReceiveCount: 3</code> ensures that a message that consistently fails processing (a malformed payload, a bug in your handler) does not loop forever and block other messages. The <code>visibility_timeout_seconds</code> must be longer than your Lambda's maximum execution time — if it is not, SQS will make the message visible again while your function is still processing it, causing duplicate processing.</p>\n<pre><code class=\"language-terraform\">resource \"aws_sqs_queue\" \"order_events\" {\n  name                        = \"order-events.fifo\"\n  fifo_queue                  = true\n  content_based_deduplication = false\n\n  # Dead Letter Queue: move unprocessable messages after 3 attempts\n  redrive_policy = jsonencode({\n    deadLetterTargetArn = aws_sqs_queue.order_events_dlq.arn\n    maxReceiveCount     = 3\n  })\n\n  # Visibility timeout > Lambda function max execution time\n  visibility_timeout_seconds = 120  # 2 minutes\n  message_retention_seconds  = 86400 * 7  # 7 days\n}\n</code></pre>\n<h2>Observability: CloudWatch + X-Ray</h2>\n<p>With the core architecture in place, you need to see what is happening inside it. Structured logging is the foundation — CloudWatch Logs Insights can run SQL-like queries against JSON logs, letting you find all errors for a specific user or calculate p99 latency across a time window in seconds.</p>\n<p>The Spring AOP aspect below intercepts every request handler without modifying individual controllers. Emitting structured JSON for both success and error paths means every request is queryable in CloudWatch without string parsing — you can query <code>status=\"error\"</code> and immediately see error rates by method.</p>\n<pre><code class=\"language-java\">// Structured logging (CloudWatch Insights can query JSON logs)\n@Aspect\n@Component\npublic class RequestLoggingAspect {\n\n    @Around(\"@annotation(org.springframework.web.bind.annotation.RequestMapping)\")\n    public Object logRequest(ProceedingJoinPoint pjp) throws Throwable {\n        long start = System.currentTimeMillis();\n        try {\n            Object result = pjp.proceed();\n            log.info(\"{\\\"event\\\":\\\"request\\\",\\\"method\\\":\\\"{}\\\",\\\"duration_ms\\\":{},\\\"status\\\":\\\"success\\\"}\",\n                pjp.getSignature().getName(), System.currentTimeMillis() - start);\n            return result;\n        } catch (Exception e) {\n            log.error(\"{\\\"event\\\":\\\"request\\\",\\\"method\\\":\\\"{}\\\",\\\"duration_ms\\\":{},\\\"status\\\":\\\"error\\\",\\\"error\\\":\\\"{}\\\"}\",\n                pjp.getSignature().getName(), System.currentTimeMillis() - start, e.getMessage());\n            throw e;\n        }\n    }\n}\n</code></pre>\n<p><strong>Key CloudWatch alarms to set:</strong></p>\n<p>Alarms are your early warning system — they tell you something is wrong before your customers do. The two alarms below cover the most critical signals: error rate at the load balancer (the first place you will see cascading failures) and database CPU (the most common database bottleneck under sustained load). Set these before you go live, not after the first incident.</p>\n<pre><code class=\"language-terraform\"># ALB error rate alarm\nresource \"aws_cloudwatch_metric_alarm\" \"alb_5xx\" {\n  alarm_name          = \"prod-alb-5xx-rate\"\n  comparison_operator = \"GreaterThanThreshold\"\n  evaluation_periods  = 2\n  metric_name         = \"HTTPCode_ELB_5XX_Count\"\n  namespace           = \"AWS/ApplicationELB\"\n  period              = 60\n  statistic           = \"Sum\"\n  threshold           = 50       # Alert if >50 5xx errors per minute\n  alarm_actions       = [aws_sns_topic.alerts.arn]\n}\n\n# RDS CPU alarm\nresource \"aws_cloudwatch_metric_alarm\" \"rds_cpu\" {\n  alarm_name          = \"prod-aurora-cpu\"\n  metric_name         = \"CPUUtilization\"\n  namespace           = \"AWS/RDS\"\n  threshold           = 80       # Alert at 80% CPU\n  period              = 300      # 5-minute average\n}\n</code></pre>\n<h2>Cost Optimization</h2>\n<p>Once your architecture is functional and observable, cost optimization is about choosing the right purchasing model for each layer's usage pattern. The six levers below apply to every production AWS architecture — each one saves money without changing your application code.</p>\n<pre><code>Architecture cost levers:\n\n1. Reserved Instances for predictable baseline (1-year RI = 30-40% savings)\n   → ECS Fargate Compute Savings Plans, RDS Reserved Instances\n\n2. Spot Instances for fault-tolerant batch workloads\n   → Lambda@Edge, ECS Spot (with Spot interruption handling)\n\n3. S3 Intelligent-Tiering for infrequently accessed objects\n   → Automatically moves to cheaper storage tiers\n\n4. CloudFront reduces origin (ALB + compute) costs by serving cache\n   → Every cache hit saves an ALB request + compute + DB query\n\n5. Aurora Serverless v2 for dev/staging environments\n   → Scales to zero when idle → pay only when in use\n\n6. DynamoDB on-demand vs provisioned\n   → On-demand for unpredictable workloads (pay per request)\n   → Provisioned + auto-scaling for predictable traffic (cheaper)\n</code></pre>\n<p>This architecture handles 100K+ RPS with sub-100ms p99 latency. The key architectural principles: cache aggressively at every layer, decouple async work from the request path, use managed services to reduce operational overhead, and design for failure at every layer.</p>\n<p>The AWS Well-Architected Framework labels these as the Reliability, Performance, and Cost pillars. In practice, they're just good engineering — the same principles that worked before cloud, applied to managed services.</p>\n","tableOfContents":[{"id":"the-reference-architecture","text":"The Reference Architecture","level":2},{"id":"layer-1-traffic-entry-cloudfront-waf","text":"Layer 1: Traffic Entry — CloudFront + WAF","level":2},{"id":"layer-2-load-balancing-alb-vs-nlb","text":"Layer 2: Load Balancing — ALB vs NLB","level":2},{"id":"layer-3-compute-ecs-fargate-with-auto-scaling","text":"Layer 3: Compute — ECS Fargate with Auto-Scaling","level":2},{"id":"layer-4-caching-elasticache-redis","text":"Layer 4: Caching — ElastiCache Redis","level":2},{"id":"layer-5-database-rds-aurora-postgresql","text":"Layer 5: Database — RDS Aurora PostgreSQL","level":2},{"id":"layer-6-async-decoupling-sqs-lambda","text":"Layer 6: Async Decoupling — SQS + Lambda","level":2},{"id":"observability-cloudwatch-x-ray","text":"Observability: CloudWatch + X-Ray","level":2},{"id":"cost-optimization","text":"Cost Optimization","level":2}]},"relatedPosts":[{"title":"AWS Lambda in Production: Cold Starts, Concurrency, and Cost Optimization","description":"How Lambda execution environments work, cold start mitigation strategies, concurrency limits and throttling, Lambda power tuning, VPC networking costs, and when Lambda is the wrong tool.","date":"2025-06-28","category":"AWS","tags":["aws","lambda","serverless","java","cold start","performance","cost optimization"],"featured":false,"affiliateSection":"aws-resources","slug":"aws-lambda-production-patterns","readingTime":"7 min read","excerpt":"Lambda's value proposition is compelling: run code without managing servers, pay per invocation, scale from zero to 10,000 concurrent executions without configuration. The reality is a set of execution model nuances that…"},{"title":"Kubernetes in Production: Patterns Every Backend Engineer Must Know","description":"Resource requests and limits, liveness vs readiness probes, rolling deployments, HPA configuration, pod disruption budgets, and the mistakes that cause production outages in Kubernetes.","date":"2025-06-08","category":"AWS","tags":["kubernetes","k8s","devops","containers","deployment","aws","eks"],"featured":false,"affiliateSection":"aws-resources","slug":"kubernetes-production-best-practices","readingTime":"6 min read","excerpt":"Running a container in Kubernetes and running a production workload in Kubernetes are different disciplines. The gap between  and a service that survives node failures, deployment rollouts, and traffic spikes without use…"},{"title":"Terraform Infrastructure as Code: Production Patterns and Pitfalls","description":"Production Terraform: module design, state management with S3 and DynamoDB locking, workspace strategies for multi-environment deployments, sensitive variable handling, drift detection, and the Terraform anti-patterns that cause outages.","date":"2025-05-14","category":"AWS","tags":["terraform","infrastructure as code","aws","devops","s3","modules","ci/cd"],"featured":false,"affiliateSection":"aws-resources","slug":"terraform-infrastructure-as-code","readingTime":"7 min read","excerpt":"Terraform is the industry-standard tool for Infrastructure as Code (IaC) — defining cloud infrastructure as declarative HCL configuration that can be version-controlled, reviewed, and applied reproducibly. The value prop…"}]},"__N_SSG":true}