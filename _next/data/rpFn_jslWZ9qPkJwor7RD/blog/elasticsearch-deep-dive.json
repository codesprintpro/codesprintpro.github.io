{"pageProps":{"post":{"title":"Elasticsearch Deep Dive: Inverted Index, Mappings, and Query DSL","description":"Understand how Elasticsearch stores and retrieves data using inverted indexes. Learn mapping design, query DSL patterns, aggregations, and production tuning for search-heavy applications.","date":"2025-02-24","category":"Databases","tags":["elasticsearch","search","inverted index","java","databases"],"featured":false,"affiliateSection":"database-resources","slug":"elasticsearch-deep-dive","readingTime":"11 min read","excerpt":"Most engineers use Elasticsearch as a black box: index some JSON, run a search, get results. When search quality is poor or performance degrades at scale, they reach for random settings without understanding why. This ar…","contentHtml":"<p>Most engineers use Elasticsearch as a black box: index some JSON, run a search, get results. When search quality is poor or performance degrades at scale, they reach for random settings without understanding why. This article explains the internals that make Elasticsearch work — and why your index design decisions matter enormously.</p>\n<h2>How Elasticsearch Stores Data</h2>\n<p>Elasticsearch is built on Apache Lucene. The core data structure is the <strong>inverted index</strong> — a mapping from terms to the documents containing them.</p>\n<p>Think of an inverted index like the index at the back of a textbook. Instead of reading every page to find where \"Kafka\" is mentioned, you look up \"Kafka\" in the index and get a list of page numbers. Elasticsearch builds this structure automatically when you index a document, analyzing text into individual terms and recording which documents contain each term. This is why full-text search in Elasticsearch is so fast — it never has to scan document content at query time.</p>\n<pre><code>Documents:\n  Doc 1: \"Kafka is a distributed streaming platform\"\n  Doc 2: \"Redis is an in-memory data structure store\"\n  Doc 3: \"Kafka and Redis are both used in distributed systems\"\n\nInverted Index (simplified):\n  Term        → Document IDs (posting list)\n  \"kafka\"     → [1, 3]\n  \"redis\"     → [2, 3]\n  \"distributed\" → [1, 3]\n  \"streaming\" → [1]\n  \"memory\"    → [2]\n  \"systems\"   → [3]\n\nQuery: \"kafka distributed\"\n  → Find docs with \"kafka\": {1, 3}\n  → Find docs with \"distributed\": {1, 3}\n  → Intersection: {1, 3}\n  → Score by BM25 relevance (term frequency, inverse document frequency)\n  → Return Doc 1 (more relevant: both terms in shorter text)\n</code></pre>\n<p>Each posting list also stores:</p>\n<ul>\n<li>Term frequency in each document (for relevance scoring)</li>\n<li>Position of each term (for phrase queries)</li>\n<li>Offsets (for highlighting)</li>\n</ul>\n<h2>Index Architecture</h2>\n<p>Understanding how Elasticsearch distributes data across a cluster is essential before you make sizing decisions. Each index is split into shards — independent Lucene indexes that can live on different nodes. Replicas provide both redundancy and read throughput, since any replica can serve search requests. The diagram below shows a 3-shard index with one replica each, spread across 3 nodes so that every node holds one primary and one replica — no single node failure takes down any shard.</p>\n<pre><code>Elasticsearch Cluster:\n  ┌─────────────────────────────────────────────────────┐\n  │                    Cluster                           │\n  │  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐\n  │  │   Node 1     │  │   Node 2     │  │   Node 3     │\n  │  │  (Master)    │  │              │  │              │\n  │  │              │  │              │  │              │\n  │  │  Shard 0 (P) │  │  Shard 1 (P) │  │  Shard 2 (P) │\n  │  │  Shard 1 (R) │  │  Shard 2 (R) │  │  Shard 0 (R) │\n  │  └──────────────┘  └──────────────┘  └──────────────┘\n  └─────────────────────────────────────────────────────┘\n\n  Index \"products\": 3 primary shards, 1 replica each\n  P = Primary, R = Replica\n  Total shards: 6 (3 primary + 3 replica)\n</code></pre>\n<p>Each <strong>shard</strong> is a complete Lucene index. Documents are routed to shards by:</p>\n<pre><code>shard_id = hash(document_id) % number_of_primary_shards\n</code></pre>\n<p><strong>Shard sizing guidelines:</strong></p>\n<ul>\n<li>Target 20-50 GB per shard (larger = slower GC and recovery)</li>\n<li>Number of shards = expected total data / 30 GB (rounded up)</li>\n<li>Don't over-shard: each shard has overhead (~few MB), and more shards = more coordination cost</li>\n</ul>\n<h2>Mapping Design: The Most Important Decision</h2>\n<p>Mappings define how documents and their fields are stored and indexed. Poor mapping design is the #1 cause of Elasticsearch performance problems.</p>\n<p>Mappings are to Elasticsearch what a schema is to a relational database — but with higher stakes. You cannot change a field's type after indexing data without reindexing everything. Choosing <code>text</code> instead of <code>keyword</code> for a category field means you can't aggregate by category. Getting this right upfront saves you from expensive reindexing operations in production.</p>\n<pre><code class=\"language-json\">// Product catalog mapping\nPUT /products\n{\n  \"settings\": {\n    \"number_of_shards\": 3,\n    \"number_of_replicas\": 1,\n    \"refresh_interval\": \"5s\",          // How often new docs become searchable\n    \"analysis\": {\n      \"analyzer\": {\n        \"product_analyzer\": {\n          \"type\": \"custom\",\n          \"tokenizer\": \"standard\",\n          \"filter\": [\"lowercase\", \"stop\", \"snowball\"]  // Stemming: \"running\" → \"run\"\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"id\":          { \"type\": \"keyword\" },           // Exact match only\n      \"name\":        {\n        \"type\": \"text\",\n        \"analyzer\": \"product_analyzer\",\n        \"fields\": {\n          \"raw\": { \"type\": \"keyword\" },               // For sorting and aggregations\n          \"suggest\": { \"type\": \"completion\" }         // For autocomplete\n        }\n      },\n      \"description\": { \"type\": \"text\", \"analyzer\": \"product_analyzer\" },\n      \"price\":       { \"type\": \"scaled_float\", \"scaling_factor\": 100 },\n      \"category\":    { \"type\": \"keyword\" },           // For filtering and facets\n      \"tags\":        { \"type\": \"keyword\" },\n      \"in_stock\":    { \"type\": \"boolean\" },\n      \"rating\":      { \"type\": \"half_float\" },\n      \"created_at\":  { \"type\": \"date\" },\n\n      // Nested: preserve object identity for inner hits\n      \"variants\": {\n        \"type\": \"nested\",\n        \"properties\": {\n          \"color\": { \"type\": \"keyword\" },\n          \"size\":  { \"type\": \"keyword\" },\n          \"stock\": { \"type\": \"integer\" }\n        }\n      }\n    }\n  }\n}\n</code></pre>\n<p>Notice that <code>name</code> is mapped as both <code>text</code> (for full-text search) and <code>keyword</code> (for sorting and faceting) using the <code>fields</code> feature. This is a common pattern — you want to search within the name using analyzed text, but you also want to sort results alphabetically, which requires the unanalyzed keyword version.</p>\n<p><strong>Critical mapping decisions:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Field Type</th>\n<th>Use When</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>keyword</code></td>\n<td>Exact match, sorting, aggregations (category, ID, status)</td>\n</tr>\n<tr>\n<td><code>text</code></td>\n<td>Full-text search (descriptions, names) — analyzed and tokenized</td>\n</tr>\n<tr>\n<td><code>nested</code></td>\n<td>Arrays of objects where you need to query inner fields independently</td>\n</tr>\n<tr>\n<td><code>object</code></td>\n<td>Simple nested objects without cross-field query requirements</td>\n</tr>\n<tr>\n<td><code>date</code></td>\n<td>Timestamps — store as ISO 8601, query with date math</td>\n</tr>\n<tr>\n<td><code>scaled_float</code></td>\n<td>Prices, percentages (avoids float precision issues)</td>\n</tr>\n</tbody>\n</table>\n<p><strong>Avoid:</strong></p>\n<ul>\n<li><code>dynamic: true</code> in production — unknown fields get auto-mapped, causing mapping explosions</li>\n<li>Storing large binary data (use S3 + store URL)</li>\n<li>Deep nesting (Elasticsearch flattens it, but queries get complex)</li>\n</ul>\n<h2>Query DSL: From Simple to Complex</h2>\n<p>With mappings in place, you are ready to build queries. Elasticsearch's Query DSL is a JSON-based language that composes simple building blocks into arbitrarily complex search logic. The progression below goes from a basic match query to a full bool query with filters and aggregations — the same pattern you will use in most real-world search features.</p>\n<h3>Full-Text Search</h3>\n<p>The <code>match</code> query is the workhorse of Elasticsearch — it analyzes your search string using the same analyzer as the indexed field, then finds documents containing the resulting terms. The <code>fuzziness: AUTO</code> option adds typo tolerance by allowing small edit-distance variations, so \"headpones\" still finds \"headphones\".</p>\n<pre><code class=\"language-json\">// Match query: analyzes query string, standard choice for full-text\nGET /products/_search\n{\n  \"query\": {\n    \"match\": {\n      \"name\": {\n        \"query\": \"wireless bluetooth headphones\",\n        \"operator\": \"and\",        // All terms must match (default: \"or\")\n        \"fuzziness\": \"AUTO\"       // Typo tolerance\n      }\n    }\n  }\n}\n\n// Multi-match: search across multiple fields with field boosting\nGET /products/_search\n{\n  \"query\": {\n    \"multi_match\": {\n      \"query\": \"gaming laptop\",\n      \"fields\": [\"name^3\", \"description\", \"tags^2\"],  // ^N = boost factor\n      \"type\": \"best_fields\"\n    }\n  }\n}\n</code></pre>\n<h3>Boolean Queries (Filtering + Searching)</h3>\n<p>The bool query is where real search features come alive. It combines full-text search with structured filtering in a single query, and the distinction between <code>must</code> and <code>filter</code> clauses is one of the most important performance decisions you will make.</p>\n<pre><code class=\"language-json\">// Find: in-stock Sony headphones under $200, sorted by rating\nGET /products/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": [\n        { \"match\": { \"name\": \"headphones\" } }      // Affects relevance score\n      ],\n      \"filter\": [\n        { \"term\": { \"category\": \"electronics\" } }, // Does NOT affect score (cached)\n        { \"term\": { \"in_stock\": true } },\n        { \"range\": { \"price\": { \"lte\": 200 } } },\n        { \"prefix\": { \"brand.raw\": \"Sony\" } }\n      ],\n      \"must_not\": [\n        { \"term\": { \"tags\": \"refurbished\" } }\n      ],\n      \"should\": [\n        { \"term\": { \"tags\": \"featured\" } }         // Optional boost\n      ],\n      \"minimum_should_match\": 0\n    }\n  },\n  \"sort\": [\n    { \"rating\": { \"order\": \"desc\" } },\n    \"_score\"\n  ]\n}\n</code></pre>\n<p><strong><code>filter</code> vs <code>must</code>:</strong> Filters don't compute relevance scores and are cached by Elasticsearch. Always use <code>filter</code> for structured criteria (category, price range, boolean flags) and <code>must</code> only for full-text queries that should influence ranking.</p>\n<h3>Aggregations: Faceted Search</h3>\n<p>Aggregations are what power the sidebar filters you see on every e-commerce site — \"Electronics (143)\", \"$500-$1000\", \"4+ stars\". The query below runs a search and simultaneously computes facet counts, price distribution, and average rating, all in a single request. Without aggregations, you would need separate queries for each of these counts.</p>\n<pre><code class=\"language-json\">// Product search with facets (category counts, price histogram)\nGET /products/_search\n{\n  \"query\": { \"match\": { \"name\": \"laptop\" } },\n  \"aggs\": {\n    \"by_category\": {\n      \"terms\": { \"field\": \"category\", \"size\": 10 }\n    },\n    \"price_ranges\": {\n      \"range\": {\n        \"field\": \"price\",\n        \"ranges\": [\n          { \"to\": 500 },\n          { \"from\": 500, \"to\": 1000 },\n          { \"from\": 1000, \"to\": 2000 },\n          { \"from\": 2000 }\n        ]\n      }\n    },\n    \"avg_rating\": { \"avg\": { \"field\": \"rating\" } },\n    \"in_stock_count\": {\n      \"filter\": { \"term\": { \"in_stock\": true } }\n    }\n  },\n  \"size\": 10\n}\n</code></pre>\n<h3>Nested Queries</h3>\n<p>Nested queries exist because of how Elasticsearch flattens arrays of objects. Without <code>nested</code> type and queries, searching for \"red L variant\" might match a product that has a red M and a blue L as separate variants — not what you want. The <code>nested</code> query preserves object boundaries within arrays so that all conditions must match within the same variant object.</p>\n<pre><code class=\"language-json\">// Find products that have a red variant in size L\n{\n  \"query\": {\n    \"nested\": {\n      \"path\": \"variants\",\n      \"query\": {\n        \"bool\": {\n          \"filter\": [\n            { \"term\": { \"variants.color\": \"red\" } },\n            { \"term\": { \"variants.size\": \"L\" } },\n            { \"range\": { \"variants.stock\": { \"gt\": 0 } } }\n          ]\n        }\n      },\n      \"inner_hits\": {}  // Return the matching variant in the result\n    }\n  }\n}\n</code></pre>\n<h2>Java Client (Official Elasticsearch Java API)</h2>\n<p>The official Java client uses a fluent builder API that mirrors the JSON Query DSL structure. The search service below combines multi-field search with category and price filters, and appends an aggregation for facets — all in a single type-safe call. The builder pattern makes it easy to conditionally add clauses based on which filters the user actually provided.</p>\n<pre><code class=\"language-java\">@Service\npublic class ProductSearchService {\n\n    @Autowired\n    private ElasticsearchClient client;\n\n    public SearchResult&#x3C;Product> search(ProductSearchRequest req) throws IOException {\n        SearchResponse&#x3C;Product> response = client.search(s -> s\n            .index(\"products\")\n            .query(q -> q\n                .bool(b -> {\n                    if (req.getQuery() != null) {\n                        b.must(m -> m.multiMatch(mm -> mm\n                            .query(req.getQuery())\n                            .fields(\"name^3\", \"description\", \"tags^2\")\n                            .fuzziness(\"AUTO\")\n                        ));\n                    }\n                    if (req.getCategory() != null) {\n                        b.filter(f -> f.term(t -> t.field(\"category\").value(req.getCategory())));\n                    }\n                    if (req.getMaxPrice() != null) {\n                        b.filter(f -> f.range(r -> r.field(\"price\").lte(JsonData.of(req.getMaxPrice()))));\n                    }\n                    b.filter(f -> f.term(t -> t.field(\"in_stock\").value(true)));\n                    return b;\n                })\n            )\n            .sort(so -> so.field(f -> f.field(\"_score\").order(SortOrder.Desc)))\n            .sort(so -> so.field(f -> f.field(\"rating\").order(SortOrder.Desc)))\n            .from(req.getPage() * req.getSize())\n            .size(req.getSize())\n            .aggregations(\"categories\", a -> a.terms(t -> t.field(\"category\").size(20)))\n            , Product.class\n        );\n\n        return buildResult(response);\n    }\n}\n</code></pre>\n<h2>Production Tuning</h2>\n<p>Production Elasticsearch performance comes down to three areas: JVM memory settings, index configuration for your write pattern, and ongoing monitoring. The settings below are starting points — you will need to adjust based on your cluster's actual size and workload.</p>\n<pre><code class=\"language-yaml\"># JVM heap: 50% of RAM, max 32GB (compressed OOPs stop working above 32GB)\nES_JAVA_OPTS: \"-Xms16g -Xmx16g\"\n\n# elasticsearch.yml\nindices.memory.index_buffer_size: 20%      # Buffer for indexing (default 10%)\nindices.fielddata.cache.size: 20%          # FieldData cache for aggregations\n</code></pre>\n<p>During bulk data loads (initial indexing or migration), disabling replicas and relaxing the refresh interval can dramatically increase throughput. The steps below show how to maximize write speed during ingestion, then restore production settings when done. The <code>forcemerge</code> step is important: it compacts many small Lucene segments into one, which significantly speeds up queries on the freshly loaded index.</p>\n<pre><code class=\"language-bash\"># Index settings for write-heavy ingestion\nPUT /products/_settings\n{\n  \"refresh_interval\": \"30s\",              # Less frequent refresh = faster indexing\n  \"number_of_replicas\": 0                 # Disable replicas during bulk load, re-enable after\n}\n\n# After bulk load, re-enable:\nPUT /products/_settings\n{ \"number_of_replicas\": 1, \"refresh_interval\": \"5s\" }\n\n# Force merge after bulk load (improves query performance)\nPOST /products/_forcemerge?max_num_segments=1\n</code></pre>\n<p><strong>Monitoring KPIs:</strong></p>\n<ul>\n<li><strong>Search latency</strong>: <code>p99 &#x3C; 200ms</code> for most queries</li>\n<li><strong>Indexing latency</strong>: <code>p99 &#x3C; 500ms</code> for real-time indexing</li>\n<li><strong>JVM heap used</strong>: alert at 85% (above 75% triggers GC pressure)</li>\n<li><strong>Disk I/O</strong>: sustained high disk I/O = segment merges happening (normal)</li>\n<li><strong>Rejected requests</strong>: thread pool rejections = cluster overwhelmed, add nodes or reduce load</li>\n</ul>\n<p>Elasticsearch rewards careful mapping design and query construction far more than hardware scaling. Get the mapping right first, use filters instead of queries wherever possible, and let aggregations tell you what your data looks like.</p>\n","tableOfContents":[{"id":"how-elasticsearch-stores-data","text":"How Elasticsearch Stores Data","level":2},{"id":"index-architecture","text":"Index Architecture","level":2},{"id":"mapping-design-the-most-important-decision","text":"Mapping Design: The Most Important Decision","level":2},{"id":"query-dsl-from-simple-to-complex","text":"Query DSL: From Simple to Complex","level":2},{"id":"full-text-search","text":"Full-Text Search","level":3},{"id":"boolean-queries-filtering-searching","text":"Boolean Queries (Filtering + Searching)","level":3},{"id":"aggregations-faceted-search","text":"Aggregations: Faceted Search","level":3},{"id":"nested-queries","text":"Nested Queries","level":3},{"id":"java-client-official-elasticsearch-java-api","text":"Java Client (Official Elasticsearch Java API)","level":2},{"id":"production-tuning","text":"Production Tuning","level":2}]},"relatedPosts":[{"title":"Cassandra Data Modeling: Design for Queries, Not Entities","description":"Apache Cassandra data modeling from first principles: partition key design, clustering columns, denormalization strategies, avoiding hot partitions, materialized views vs. manual duplication, and the anti-patterns that kill Cassandra performance.","date":"2025-06-18","category":"Databases","tags":["cassandra","nosql","data modeling","distributed databases","partition key","cql","time series"],"featured":false,"affiliateSection":"database-resources","slug":"cassandra-data-modeling","readingTime":"9 min read","excerpt":"Cassandra is a write-optimized distributed database built for linear horizontal scalability. It stores data in a distributed hash ring — every node is equal, there's no primary, and data placement is determined by partit…"},{"title":"DynamoDB Advanced Patterns: Single-Table Design and Beyond","description":"Production DynamoDB: single-table design with access pattern mapping, GSI overloading, sparse indexes, adjacency lists for graph relationships, DynamoDB Streams for event-driven architectures, and the read/write capacity math that prevents bill shock.","date":"2025-06-13","category":"Databases","tags":["dynamodb","aws","nosql","single-table design","gsi","dynamodb streams","serverless"],"featured":false,"affiliateSection":"database-resources","slug":"dynamodb-advanced-patterns","readingTime":"9 min read","excerpt":"DynamoDB is a fully managed key-value and document database that delivers single-digit millisecond performance at any scale. It achieves this with a fundamental constraint: you must define your access patterns before you…"},{"title":"Zero-Downtime Database Migrations: Patterns for Production","description":"How to safely migrate production databases without downtime: expand-contract pattern, backward-compatible schema changes, rolling deployments with dual-write, column renaming strategies, and the PostgreSQL-specific techniques for large table alterations.","date":"2025-06-08","category":"Databases","tags":["database","migrations","postgresql","zero downtime","devops","schema evolution","flyway","liquibase"],"featured":false,"affiliateSection":"database-resources","slug":"zero-downtime-database-migrations","readingTime":"8 min read","excerpt":"Database migrations are the most dangerous part of a deployment. Application code changes are stateless and reversible — rollback a bad deploy and your code is back to the previous version. Database schema changes are st…"}]},"__N_SSG":true}