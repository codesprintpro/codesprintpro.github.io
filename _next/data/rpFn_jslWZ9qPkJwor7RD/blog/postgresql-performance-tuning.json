{"pageProps":{"post":{"title":"PostgreSQL Performance Tuning: From Slow Queries to Sub-Millisecond Reads","description":"A production guide to PostgreSQL query optimization: EXPLAIN ANALYZE, index design, VACUUM tuning, connection pooling with PgBouncer, partitioning, and the configuration changes that actually move the needle.","date":"2025-06-03","category":"Databases","tags":["postgresql","databases","performance","sql","indexing","query optimization"],"featured":false,"affiliateSection":"database-resources","slug":"postgresql-performance-tuning","readingTime":"9 min read","excerpt":"PostgreSQL ships with defaults tuned for a 512MB machine from 2005. Every production deployment needs to be re-tuned. Beyond that, most slow queries are not a PostgreSQL problem — they're a query design problem that Post…","contentHtml":"<p>PostgreSQL ships with defaults tuned for a 512MB machine from 2005. Every production deployment needs to be re-tuned. Beyond that, most slow queries are not a PostgreSQL problem — they're a query design problem that PostgreSQL surfaces. This article covers both: the query patterns that create avoidable load, and the server configuration that extracts maximum performance from your hardware.</p>\n<h2>Reading EXPLAIN ANALYZE Like a Senior DBA</h2>\n<p>Every performance investigation starts here:</p>\n<pre><code class=\"language-sql\">EXPLAIN (ANALYZE, BUFFERS, FORMAT TEXT)\nSELECT u.id, u.name, COUNT(o.id) as order_count\nFROM users u\nLEFT JOIN orders o ON o.user_id = u.id\nWHERE u.status = 'active'\n  AND u.created_at > '2024-01-01'\nGROUP BY u.id, u.name\nORDER BY order_count DESC\nLIMIT 100;\n</code></pre>\n<p>Key output fields to read:</p>\n<pre><code>Hash Left Join  (cost=12500.00..89432.00 rows=100 width=40)\n                (actual time=1823.421..4231.005 rows=100 loops=1)\n  Buffers: shared hit=2841 read=31823\n  ->  Seq Scan on users  (cost=0.00..42000.00 rows=500000 width=32)\n                         (actual time=0.023..1203.000 rows=500000 loops=1)\n        Filter: ((status = 'active') AND (created_at > '2024-01-01'))\n        Rows Removed by Filter: 250000\n  ->  Hash  (cost=8000.00..8000.00 rows=2000000 width=16) (...)\n        Buckets: 131072  Batches: 16  Memory Usage: 4096kB\n</code></pre>\n<p><strong>What to look for:</strong></p>\n<ul>\n<li><code>Seq Scan</code> on large tables: missing index</li>\n<li><code>actual time</code> much higher than <code>cost</code>: stale statistics — run <code>ANALYZE</code></li>\n<li><code>Buffers: read=31823</code>: reading 31K pages from disk (cache miss) — memory too small or missing index</li>\n<li><code>Rows Removed by Filter: 250000</code>: filter applied post-scan — index on filter column needed</li>\n<li><code>Batches: 16</code> on Hash: hash join spilled to disk — increase <code>work_mem</code></li>\n</ul>\n<h2>Index Design That Actually Helps</h2>\n<h3>Composite Indexes: Column Order Matters</h3>\n<pre><code class=\"language-sql\">-- Query:\nSELECT * FROM orders\nWHERE user_id = 123 AND status = 'pending' AND created_at > NOW() - INTERVAL '7 days';\n\n-- WRONG: index can only use leftmost prefix\nCREATE INDEX idx_orders_status_user ON orders (status, user_id);\n-- Query has high-cardinality filter (user_id) after low-cardinality (status) — bad\n\n-- RIGHT: highest cardinality first, then equality, then range\nCREATE INDEX idx_orders_user_status_created ON orders (user_id, status, created_at DESC);\n-- user_id equality → status equality → created_at range: all 3 columns used\n</code></pre>\n<p><strong>Rule:</strong> Equality columns before range columns. High-cardinality before low-cardinality within equality columns.</p>\n<h3>Partial Indexes for Selective Queries</h3>\n<pre><code class=\"language-sql\">-- Only index active users (90% of queries)\nCREATE INDEX idx_users_active_created\nON users (created_at DESC)\nWHERE status = 'active';\n\n-- Only index unprocessed orders\nCREATE INDEX idx_orders_pending\nON orders (created_at, user_id)\nWHERE status = 'pending';\n-- If 5% of orders are pending, this index is 20× smaller — faster scans, better cache utilization\n</code></pre>\n<h3>Index-Only Scans with INCLUDE</h3>\n<pre><code class=\"language-sql\">-- Query needs id + email + name, but WHERE is on email\nCREATE INDEX idx_users_email ON users (email);\n-- Requires heap fetch to get id and name → not index-only\n\n-- Include the extra columns:\nCREATE INDEX idx_users_email_include ON users (email) INCLUDE (id, name);\n-- Query satisfied entirely from index — no heap access\n-- Check with EXPLAIN: \"Index Only Scan\" instead of \"Index Scan\"\n</code></pre>\n<h2>Fixing N+1 Queries</h2>\n<p>The most common performance killer in ORMs:</p>\n<pre><code class=\"language-sql\">-- N+1: 1 query for users + N queries for orders\nSELECT * FROM users WHERE status = 'active';\n-- Then for each user:\nSELECT * FROM orders WHERE user_id = $1;\n\n-- Fix: JOIN or subquery\nSELECT\n    u.id,\n    u.name,\n    COALESCE(\n        JSON_AGG(\n            JSON_BUILD_OBJECT('id', o.id, 'total', o.total)\n            ORDER BY o.created_at DESC\n        ) FILTER (WHERE o.id IS NOT NULL),\n        '[]'\n    ) AS recent_orders\nFROM users u\nLEFT JOIN LATERAL (\n    SELECT id, total, created_at\n    FROM orders\n    WHERE user_id = u.id\n    ORDER BY created_at DESC\n    LIMIT 5\n) o ON true\nWHERE u.status = 'active'\nGROUP BY u.id, u.name;\n</code></pre>\n<p><code>LATERAL JOIN</code> is PostgreSQL's correlated subquery that's evaluated per-row but uses indexes on the subquery table — perfect for \"top N per group\" patterns.</p>\n<h2>VACUUM and AUTOVACUUM Tuning</h2>\n<p>PostgreSQL uses MVCC — old row versions accumulate as \"dead tuples.\" VACUUM reclaims them. Without proper VACUUM, tables bloat and queries slow down.</p>\n<p>Default autovacuum triggers when 20% of a table is dead tuples (<code>autovacuum_vacuum_scale_factor = 0.2</code>). For a 10M row table, that's 2M dead rows before vacuum runs — too late.</p>\n<pre><code class=\"language-sql\">-- Per-table autovacuum tuning for high-update tables:\nALTER TABLE orders SET (\n    autovacuum_vacuum_scale_factor = 0.01,   -- Vacuum at 1% dead tuples (not 20%)\n    autovacuum_vacuum_threshold = 100,        -- Minimum 100 dead tuples\n    autovacuum_analyze_scale_factor = 0.005, -- Analyze at 0.5%\n    autovacuum_vacuum_cost_delay = 2          -- Less throttling for busy tables\n);\n\n-- Monitor table bloat:\nSELECT\n    schemaname,\n    tablename,\n    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS total_size,\n    n_dead_tup,\n    n_live_tup,\n    round(n_dead_tup::numeric / nullif(n_live_tup + n_dead_tup, 0) * 100, 2) AS dead_pct,\n    last_autovacuum\nFROM pg_stat_user_tables\nWHERE n_dead_tup > 10000\nORDER BY dead_pct DESC;\n</code></pre>\n<h2>Connection Pooling with PgBouncer</h2>\n<p>PostgreSQL creates a new OS process per connection (~5MB RAM each). At 500 connections: 2.5GB of RAM just for connection overhead. PgBouncer pools many client connections into a small number of server connections:</p>\n<pre><code class=\"language-ini\"># pgbouncer.ini\n[databases]\nmydb = host=localhost port=5432 dbname=mydb\n\n[pgbouncer]\nlisten_addr = 0.0.0.0\nlisten_port = 6432\nauth_type = scram-sha-256\nauth_file = /etc/pgbouncer/users.txt\n\n# Transaction pooling: release server connection on COMMIT/ROLLBACK\n# Most aggressive pooling — incompatible with prepared statements\npool_mode = transaction\n\ndefault_pool_size = 20       # Server connections per database/user pair\nmax_client_conn = 1000       # Max client connections PgBouncer accepts\nreserve_pool_size = 5        # Emergency connections\nreserve_pool_timeout = 3\nserver_idle_timeout = 600    # Close idle server connections after 10 min\n</code></pre>\n<p>With PgBouncer in transaction mode: 1,000 app threads → 20 actual PostgreSQL connections. PostgreSQL max_connections can be set to 50 instead of 1,000.</p>\n<p><strong>Caveat:</strong> Transaction pooling breaks SET LOCAL, LISTEN/NOTIFY, advisory locks, and session-level prepared statements. Use session pooling if your app uses these.</p>\n<h2>Partitioning for Large Tables</h2>\n<p>Table partitioning keeps query plans efficient by allowing PostgreSQL to skip entire partitions:</p>\n<pre><code class=\"language-sql\">-- Range partitioning by month for time-series data\nCREATE TABLE events (\n    id          BIGSERIAL,\n    user_id     BIGINT NOT NULL,\n    event_type  TEXT NOT NULL,\n    data        JSONB,\n    created_at  TIMESTAMPTZ NOT NULL DEFAULT NOW()\n) PARTITION BY RANGE (created_at);\n\nCREATE TABLE events_2025_01 PARTITION OF events\n    FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');\nCREATE TABLE events_2025_02 PARTITION OF events\n    FOR VALUES FROM ('2025-02-01') TO ('2025-03-01');\n-- ... automate with pg_partman extension\n\n-- Query with partition key in WHERE → partition pruning:\nSELECT * FROM events\nWHERE created_at BETWEEN '2025-01-01' AND '2025-01-31'\n  AND user_id = 12345;\n-- Scans only events_2025_01, not all partitions\n</code></pre>\n<p><strong>Partition maintenance:</strong> Use <code>pg_partman</code> to auto-create future partitions and drop old ones. Dropping an old partition is instant (DROP TABLE) — much faster than DELETE.</p>\n<h2>Key postgresql.conf Changes</h2>\n<pre><code class=\"language-ini\"># Memory (for a 16GB server):\nshared_buffers = 4GB              # 25% of RAM — PostgreSQL's buffer pool\neffective_cache_size = 12GB       # Tells query planner how much OS cache exists\nwork_mem = 64MB                   # Per sort/hash operation (set conservatively — multiplies)\nmaintenance_work_mem = 1GB        # For VACUUM, CREATE INDEX\n\n# WAL and checkpoints:\nwal_buffers = 64MB\ncheckpoint_completion_target = 0.9    # Spread checkpoint writes over 90% of interval\nmax_wal_size = 4GB                    # Allow larger WAL before forced checkpoint\n\n# Query planner:\nrandom_page_cost = 1.1               # SSD: set close to seq_page_cost (1.0)\n                                     # HDD: default 4.0 is appropriate\neffective_io_concurrency = 200       # SSD: set to 200; HDD: 2\nparallel_workers_per_gather = 4      # Enable parallel query execution\nmax_parallel_workers_per_gather = 4\n\n# Logging slow queries:\nlog_min_duration_statement = 1000    # Log queries > 1 second\nlog_checkpoints = on                 # Log checkpoint activity\nlog_autovacuum_min_duration = 250    # Log autovacuum runs > 250ms\n</code></pre>\n<p><code>work_mem</code> is the most dangerous setting. Each sort/hash operation uses up to <code>work_mem</code>. A query with 5 hash joins, run by 50 concurrent connections with 4 parallel workers = <code>50 × 5 × 4 × 64MB = 64GB</code>. Set it in session for analytical queries, not globally.</p>\n<h2>Statistics and Query Plans</h2>\n<p>PostgreSQL's query planner uses table statistics (row counts, value distributions) to choose plans. Stale statistics cause bad plans:</p>\n<pre><code class=\"language-sql\">-- Update statistics for a specific table:\nANALYZE orders;\n\n-- Increase statistics target for columns with skewed distributions:\nALTER TABLE orders ALTER COLUMN status SET STATISTICS 500;\n-- Default is 100 — more samples for better cardinality estimates\nANALYZE orders;\n\n-- Check when statistics were last updated:\nSELECT tablename, last_analyze, last_autoanalyze\nFROM pg_stat_user_tables\nWHERE tablename = 'orders';\n\n-- Force a specific plan for debugging (never in production permanently):\nSET enable_seqscan = off;  -- Force index usage\nEXPLAIN ANALYZE SELECT ...;\nSET enable_seqscan = on;\n</code></pre>\n<h2>Production Monitoring Queries</h2>\n<pre><code class=\"language-sql\">-- Top 10 slowest queries (requires pg_stat_statements extension):\nSELECT\n    query,\n    calls,\n    round(total_exec_time::numeric / calls, 2) AS avg_ms,\n    round(total_exec_time::numeric, 2) AS total_ms,\n    rows / calls AS avg_rows\nFROM pg_stat_statements\nORDER BY total_exec_time DESC\nLIMIT 10;\n\n-- Indexes never used (candidates for removal):\nSELECT\n    schemaname,\n    tablename,\n    indexname,\n    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size,\n    idx_scan AS times_used\nFROM pg_stat_user_indexes\nWHERE idx_scan = 0\n  AND indexname NOT LIKE '%pkey%'  -- Keep primary keys\nORDER BY pg_relation_size(indexrelid) DESC;\n\n-- Active locks (detect blocking queries):\nSELECT\n    pid,\n    now() - pg_stat_activity.query_start AS duration,\n    query,\n    state\nFROM pg_stat_activity\nWHERE (now() - pg_stat_activity.query_start) > interval '5 minutes'\nORDER BY duration DESC;\n</code></pre>\n<h2>Real Production Case: 15-Second Query to 80ms</h2>\n<p><strong>Starting point:</strong> E-commerce platform, orders table with 50M rows, query for customer order history timing out at 15 seconds.</p>\n<pre><code class=\"language-sql\">-- Original query:\nSELECT o.*, oi.*, p.name as product_name\nFROM orders o\nJOIN order_items oi ON oi.order_id = o.id\nJOIN products p ON p.id = oi.product_id\nWHERE o.customer_id = 12345\nORDER BY o.created_at DESC\nLIMIT 20;\n\n-- EXPLAIN showed:\n-- Seq Scan on orders (rows=50000000, actual rows=847, time=12000ms)\n</code></pre>\n<p><strong>Diagnosis:</strong> Sequential scan on orders table — no index on <code>customer_id</code>.</p>\n<p><strong>Fix 1:</strong> Composite index:</p>\n<pre><code class=\"language-sql\">CREATE INDEX CONCURRENTLY idx_orders_customer_created\nON orders (customer_id, created_at DESC);\n</code></pre>\n<p>Result: 15s → 400ms. Good progress.</p>\n<p><strong>Fix 2:</strong> EXPLAIN still showed <code>Buffers: read=12000</code> — reading 12K pages for the joins. Added covering index for order_items:</p>\n<pre><code class=\"language-sql\">CREATE INDEX CONCURRENTLY idx_order_items_order_product\nON order_items (order_id) INCLUDE (product_id, quantity, unit_price);\n</code></pre>\n<p>Result: 400ms → 80ms.</p>\n<p><strong>Fix 3:</strong> pg_stat_statements showed this query running 50,000 times/day. Added application-level Redis cache with 5-minute TTL for customer order history. Database load reduced by 90%.</p>\n<p>The lesson: indexing solves the query, caching solves the system.</p>\n","tableOfContents":[{"id":"reading-explain-analyze-like-a-senior-dba","text":"Reading EXPLAIN ANALYZE Like a Senior DBA","level":2},{"id":"index-design-that-actually-helps","text":"Index Design That Actually Helps","level":2},{"id":"composite-indexes-column-order-matters","text":"Composite Indexes: Column Order Matters","level":3},{"id":"partial-indexes-for-selective-queries","text":"Partial Indexes for Selective Queries","level":3},{"id":"index-only-scans-with-include","text":"Index-Only Scans with INCLUDE","level":3},{"id":"fixing-n1-queries","text":"Fixing N+1 Queries","level":2},{"id":"vacuum-and-autovacuum-tuning","text":"VACUUM and AUTOVACUUM Tuning","level":2},{"id":"connection-pooling-with-pgbouncer","text":"Connection Pooling with PgBouncer","level":2},{"id":"partitioning-for-large-tables","text":"Partitioning for Large Tables","level":2},{"id":"key-postgresqlconf-changes","text":"Key postgresql.conf Changes","level":2},{"id":"statistics-and-query-plans","text":"Statistics and Query Plans","level":2},{"id":"production-monitoring-queries","text":"Production Monitoring Queries","level":2},{"id":"real-production-case-15-second-query-to-80ms","text":"Real Production Case: 15-Second Query to 80ms","level":2}]},"relatedPosts":[{"title":"Cassandra Data Modeling: Design for Queries, Not Entities","description":"Apache Cassandra data modeling from first principles: partition key design, clustering columns, denormalization strategies, avoiding hot partitions, materialized views vs. manual duplication, and the anti-patterns that kill Cassandra performance.","date":"2025-06-18","category":"Databases","tags":["cassandra","nosql","data modeling","distributed databases","partition key","cql","time series"],"featured":false,"affiliateSection":"database-resources","slug":"cassandra-data-modeling","readingTime":"9 min read","excerpt":"Cassandra is a write-optimized distributed database built for linear horizontal scalability. It stores data in a distributed hash ring — every node is equal, there's no primary, and data placement is determined by partit…"},{"title":"DynamoDB Advanced Patterns: Single-Table Design and Beyond","description":"Production DynamoDB: single-table design with access pattern mapping, GSI overloading, sparse indexes, adjacency lists for graph relationships, DynamoDB Streams for event-driven architectures, and the read/write capacity math that prevents bill shock.","date":"2025-06-13","category":"Databases","tags":["dynamodb","aws","nosql","single-table design","gsi","dynamodb streams","serverless"],"featured":false,"affiliateSection":"database-resources","slug":"dynamodb-advanced-patterns","readingTime":"9 min read","excerpt":"DynamoDB is a fully managed key-value and document database that delivers single-digit millisecond performance at any scale. It achieves this with a fundamental constraint: you must define your access patterns before you…"},{"title":"Zero-Downtime Database Migrations: Patterns for Production","description":"How to safely migrate production databases without downtime: expand-contract pattern, backward-compatible schema changes, rolling deployments with dual-write, column renaming strategies, and the PostgreSQL-specific techniques for large table alterations.","date":"2025-06-08","category":"Databases","tags":["database","migrations","postgresql","zero downtime","devops","schema evolution","flyway","liquibase"],"featured":false,"affiliateSection":"database-resources","slug":"zero-downtime-database-migrations","readingTime":"8 min read","excerpt":"Database migrations are the most dangerous part of a deployment. Application code changes are stateless and reversible — rollback a bad deploy and your code is back to the previous version. Database schema changes are st…"}]},"__N_SSG":true}