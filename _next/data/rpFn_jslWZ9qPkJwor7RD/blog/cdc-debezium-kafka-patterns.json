{"pageProps":{"post":{"title":"Change Data Capture with Debezium: Real-Time Data Synchronization Patterns","description":"CDC lets you stream every database change as an event. Learn how Debezium captures PostgreSQL WAL logs, publishes to Kafka, and powers cache invalidation, search indexing, and microservice sync.","date":"2025-02-01","category":"Data Engineering","tags":["cdc","debezium","kafka","data engineering","postgresql","microservices"],"featured":false,"affiliateSection":"data-engineering-resources","slug":"cdc-debezium-kafka-patterns","readingTime":"11 min read","excerpt":"Change Data Capture (CDC) is one of those techniques that, once you understand it, you see it everywhere. The pattern: instead of your application explicitly publishing events when data changes, let the database engine i…","contentHtml":"<p>Change Data Capture (CDC) is one of those techniques that, once you understand it, you see it everywhere. The pattern: instead of your application explicitly publishing events when data changes, let the database engine itself be the event source — by reading its internal change log.</p>\n<p>This article explains how Debezium captures PostgreSQL WAL (Write-Ahead Log) entries and streams them to Kafka, and shows the production patterns this enables.</p>\n<h2>Why CDC?</h2>\n<h3>The Problem: Dual-Write</h3>\n<p>When a service needs to update a database AND publish an event (for cache invalidation, search indexing, microservice notification), the naive approach is dual-write. The code below looks straightforward, but it contains a race condition that will eventually corrupt your data in production — the kind of bug that's very hard to reproduce and very hard to explain to stakeholders.</p>\n<pre><code class=\"language-java\">// PROBLEMATIC: Dual-write with a race condition\npublic void createOrder(Order order) {\n    orderRepository.save(order);           // Step 1: DB write\n    kafkaTemplate.send(\"orders\", order);   // Step 2: Event publish\n    // If the app crashes between Step 1 and Step 2:\n    // → DB has the order, Kafka doesn't → systems are inconsistent\n}\n</code></pre>\n<p>This is a distributed transaction problem. Two-phase commit is operationally painful. CDC solves this by making the database write the single source of truth — the event is derived from the write, not paired with it.</p>\n<h3>The Outbox Pattern (Another Solution)</h3>\n<p>Before CDC was widely adopted, teams used the Outbox pattern as a more reliable alternative to dual-write. The idea is elegant: instead of writing to the database and Kafka separately, you write to two database tables in a single transaction, then a background process publishes the second table's entries to Kafka. Because both writes are in the same transaction, you eliminate the crash window entirely.</p>\n<pre><code class=\"language-java\">@Transactional\npublic void createOrder(Order order) {\n    orderRepository.save(order);\n    // Same transaction — atomic write to both tables\n    outboxRepository.save(new OutboxEvent(\"order.created\", order.toJson()));\n}\n\n// Separate poller (less elegant, but reliable)\n@Scheduled(fixedDelay = 1000)\npublic void publishOutboxEvents() {\n    List&#x3C;OutboxEvent> events = outboxRepository.findUnpublished();\n    events.forEach(e -> {\n        kafkaTemplate.send(e.getType(), e.getPayload());\n        outboxRepository.markPublished(e.getId());\n    });\n}\n</code></pre>\n<p>CDC with Debezium automates the outbox pattern — Debezium reads the outbox table changes from WAL and publishes them, eliminating the polling process.</p>\n<h2>How Debezium Works</h2>\n<p>Understanding Debezium requires understanding PostgreSQL's Write-Ahead Log. The WAL is PostgreSQL's crash recovery mechanism — every change is written there first before it touches the main table. Debezium acts as a logical replication client, reading those WAL entries and translating them into structured events. Think of Debezium as a translator sitting between your database's internal diary and your event streaming platform.</p>\n<pre><code>PostgreSQL WAL (Write-Ahead Log):\n  Every INSERT/UPDATE/DELETE is first written to the WAL before the main tables.\n  WAL is append-only and durable — used for crash recovery and replication.\n\nDebezium's mechanism:\n  1. Connects to PostgreSQL as a logical replication client\n  2. PostgreSQL sends WAL entries to Debezium via a replication slot\n  3. Debezium decodes WAL entries into structured change events\n  4. Events published to Kafka topics (one per table by default)\n\nPostgreSQL WAL entry for INSERT into orders:\n  {\n    \"op\": \"c\",          // c=create, u=update, d=delete, r=read (snapshot)\n    \"ts_ms\": 1704153600000,\n    \"before\": null,     // null for INSERT (no previous state)\n    \"after\": {\n      \"id\": \"ord-123\",\n      \"user_id\": \"usr-456\",\n      \"total\": 99.99,\n      \"status\": \"PENDING\",\n      \"created_at\": 1704153600000\n    },\n    \"source\": {\n      \"version\": \"2.5.0.Final\",\n      \"connector\": \"postgresql\",\n      \"name\": \"pg-prod\",\n      \"ts_ms\": 1704153600000,\n      \"snapshot\": \"false\",\n      \"db\": \"myapp\",\n      \"schema\": \"public\",\n      \"table\": \"orders\",\n      \"txId\": 789,\n      \"lsn\": 24023128   // Log Sequence Number — WAL position\n    }\n  }\n</code></pre>\n<p>The <code>before</code> and <code>after</code> fields are especially useful — for UPDATE operations, you get both the old and new values, enabling downstream consumers to detect exactly what changed rather than having to compare against a previous state they may have stored. The <code>lsn</code> (Log Sequence Number) is Debezium's bookmark in the WAL — it uses this to resume from exactly the right position after a restart.</p>\n<h2>PostgreSQL Configuration</h2>\n<p>Before Debezium can connect, PostgreSQL needs to be configured to support logical replication. The default WAL level (<code>replica</code>) only supports physical replication for read replicas — you need to change it to <code>logical</code> to allow Debezium to decode the WAL entries into structured events.</p>\n<pre><code class=\"language-bash\"># postgresql.conf — requires PostgreSQL restart\n wal_level = logical                    # Default is 'replica' — change to 'logical'\nmax_replication_slots = 5              # Debezium uses one slot per connector\nmax_wal_senders = 5                    # Max concurrent replication connections\n\n# Retention: don't let WAL grow unbounded if Debezium falls behind\n wal_keep_size = 1024                   # Keep at least 1GB of WAL segments\n</code></pre>\n<p>With the server configured, create a dedicated replication user with the minimum necessary permissions — this follows the principle of least privilege and limits blast radius if the credentials are ever compromised.</p>\n<pre><code class=\"language-sql\">-- Create a replication user with minimal permissions\nCREATE ROLE debezium REPLICATION LOGIN PASSWORD 'strong_password';\nGRANT SELECT ON ALL TABLES IN SCHEMA public TO debezium;\nGRANT CREATE ON DATABASE myapp TO debezium;  -- For creating replication slots\n\n-- Verify replication slots (Debezium creates these automatically)\nSELECT slot_name, plugin, slot_type, active, restart_lsn FROM pg_replication_slots;\n-- slot_name: debezium_pg_prod\n-- plugin: pgoutput (or decoderbufs)\n-- active: true (Debezium is connected)\n</code></pre>\n<h2>Debezium Connector Configuration</h2>\n<p>Debezium runs as a Kafka Connect plugin, which means you deploy it by submitting a JSON configuration to the Kafka Connect REST API. The configuration below sets up capture for three tables and uses Avro serialization with a Schema Registry — this is the production-grade setup that handles schema evolution safely.</p>\n<pre><code class=\"language-json\">{\n  \"name\": \"postgres-connector\",\n  \"config\": {\n    \"connector.class\": \"io.debezium.connector.postgresql.PostgresConnector\",\n    \"plugin.name\": \"pgoutput\",\n    \"tasks.max\": \"1\",\n\n    \"database.hostname\": \"postgres.internal\",\n    \"database.port\": \"5432\",\n    \"database.user\": \"debezium\",\n    \"database.password\": \"${file:/opt/kafka/connect/secrets.properties:DB_PASSWORD}\",\n    \"database.dbname\": \"myapp\",\n    \"database.server.name\": \"pg-prod\",\n\n    \"table.include.list\": \"public.orders,public.products,public.users\",\n\n    \"slot.name\": \"debezium_pg_prod\",\n    \"publication.name\": \"debezium_publication\",\n    \"publication.autocreate.mode\": \"filtered\",\n\n    \"snapshot.mode\": \"initial\",\n    \"snapshot.locking.mode\": \"none\",\n\n    \"topic.prefix\": \"pg-prod\",\n    \"topic.creation.default.replication.factor\": 3,\n    \"topic.creation.default.partitions\": 6,\n\n    \"key.converter\": \"io.confluent.kafka.serializers.KafkaAvroSerializer\",\n    \"key.converter.schema.registry.url\": \"http://schema-registry:8081\",\n    \"value.converter\": \"io.confluent.kafka.serializers.KafkaAvroSerializer\",\n    \"value.converter.schema.registry.url\": \"http://schema-registry:8081\",\n\n    \"transforms\": \"unwrap\",\n    \"transforms.unwrap.type\": \"io.debezium.transforms.ExtractNewRecordState\",\n    \"transforms.unwrap.drop.tombstones\": \"false\",\n    \"transforms.unwrap.delete.handling.mode\": \"rewrite\"\n  }\n}\n</code></pre>\n<p>The <code>transforms.unwrap</code> section applies the <code>ExtractNewRecordState</code> Single Message Transform (SMT), which strips the Debezium metadata envelope and gives consumers a clean, flat event with just the row data. Without this transform, consumers would need to parse the nested <code>before</code>/<code>after</code> structure on every event.</p>\n<p>This produces Kafka topics:</p>\n<ul>\n<li><code>pg-prod.public.orders</code> — all order changes</li>\n<li><code>pg-prod.public.products</code> — all product changes</li>\n<li><code>pg-prod.public.users</code> — all user changes</li>\n</ul>\n<h2>Consumer Patterns</h2>\n<p>Now that changes are flowing into Kafka topics, you can attach multiple independent consumers — each solving a different downstream problem without any coupling between them. This fan-out is CDC's key architectural benefit: one data source, many consumers, zero application changes required to add a new one.</p>\n<h3>Pattern 1: Cache Invalidation</h3>\n<p>Cache invalidation is one of the hardest problems in distributed systems. CDC makes it straightforward: every time a row changes in the database, Kafka delivers the event to your cache invalidator, which removes the stale entry. The cache and database can never diverge for more than the Kafka propagation latency (typically under a second).</p>\n<pre><code class=\"language-java\">@Component\npublic class OrderCacheInvalidator {\n\n    @Autowired\n    private RedisTemplate&#x3C;String, Object> redis;\n\n    @KafkaListener(topics = \"pg-prod.public.orders\", groupId = \"cache-invalidator\")\n    public void handleOrderChange(ConsumerRecord&#x3C;String, OrderChangeEvent> record) {\n        OrderChangeEvent event = record.value();\n\n        // The ExtractNewRecordState transform extracts the \"after\" state\n        // event.getId() is the order ID (set as Kafka message key)\n        String cacheKey = \"order:\" + event.getId();\n\n        if (event.getOp().equals(\"d\")) {\n            // DELETE: remove from cache\n            redis.delete(cacheKey);\n        } else {\n            // INSERT or UPDATE: invalidate so next read fetches fresh data\n            // (or write-through: set the new value directly)\n            redis.delete(cacheKey);\n        }\n\n        log.debug(\"Invalidated cache for order {}, op={}\", event.getId(), event.getOp());\n    }\n}\n</code></pre>\n<h3>Pattern 2: Elasticsearch Indexing</h3>\n<p>Keeping your search index in sync with your database is a problem CDC solves cleanly. Previously this required either synchronous writes to Elasticsearch in your application code (coupling your service to your search infrastructure) or a scheduled batch job that lagged hours behind. With CDC, your search index stays near-real-time automatically.</p>\n<pre><code class=\"language-java\">@Component\npublic class ProductSearchIndexer {\n\n    @Autowired\n    private ElasticsearchClient esClient;\n\n    @KafkaListener(topics = \"pg-prod.public.products\", groupId = \"search-indexer\")\n    public void handleProductChange(ConsumerRecord&#x3C;String, ProductChangeEvent> record) {\n        ProductChangeEvent event = record.value();\n\n        if (event.getOp().equals(\"d\")) {\n            // Delete from search index\n            esClient.delete(d -> d\n                .index(\"products\")\n                .id(event.getId().toString())\n            );\n        } else {\n            // Upsert into search index\n            ProductSearchDocument doc = ProductSearchDocument.from(event);\n            esClient.index(i -> i\n                .index(\"products\")\n                .id(event.getId().toString())\n                .document(doc)\n            );\n        }\n    }\n}\n</code></pre>\n<h3>Pattern 3: Materialized View Maintenance (CQRS Read Model)</h3>\n<p>The CQRS (Command Query Responsibility Segregation) pattern separates the write model from the read model. CDC is the most natural way to keep the read model up-to-date — when the write model changes, Debezium publishes the event, and the read model updater below enriches and denormalizes it into a form optimized for fast queries. This eliminates expensive JOINs at read time by paying the cost once at write time.</p>\n<pre><code class=\"language-java\">// Separate read model: orders enriched with user info, denormalized for fast reads\n@Component\npublic class OrderReadModelUpdater {\n\n    @Autowired\n    private OrderReadRepository readRepository;\n\n    @Autowired\n    private UserService userService;\n\n    @KafkaListener(topics = \"pg-prod.public.orders\", groupId = \"read-model-updater\")\n    public void handleOrderChange(ConsumerRecord&#x3C;String, OrderChangeEvent> record) {\n        OrderChangeEvent event = record.value();\n\n        if (event.getOp().equals(\"d\")) {\n            readRepository.deleteById(event.getId());\n            return;\n        }\n\n        // Enrich with user data (from another service or local cache)\n        UserInfo user = userService.getUser(event.getUserId());\n\n        OrderReadModel readModel = OrderReadModel.builder()\n            .id(event.getId())\n            .userId(event.getUserId())\n            .userName(user.getName())         // Denormalized\n            .userEmail(user.getEmail())       // Denormalized\n            .total(event.getTotal())\n            .status(event.getStatus())\n            .updatedAt(Instant.now())\n            .build();\n\n        readRepository.upsert(readModel);\n    }\n}\n</code></pre>\n<p>The <code>userName</code> and <code>userEmail</code> fields being stored directly in the order read model means your order list queries never need to JOIN against the users table — a significant performance win at scale. The trade-off is that if a user updates their name, you need a separate process to backfill affected order read models.</p>\n<h2>The Outbox Pattern with Debezium</h2>\n<p>Building on the outbox pattern introduced earlier, you can combine it with Debezium to achieve the most reliable event publishing architecture available. The application writes to its domain table and an outbox table in a single transaction; Debezium reads the outbox changes and publishes them — no polling thread, no risk of missed events.</p>\n<pre><code class=\"language-java\">// Domain service: writes to domain table + outbox atomically\n@Service\n@Transactional\npublic class OrderService {\n\n    @Autowired\n    private OrderRepository orderRepository;\n\n    @Autowired\n    private OutboxRepository outboxRepository;\n\n    public Order createOrder(CreateOrderRequest request) {\n        Order order = orderRepository.save(buildOrder(request));\n\n        // Outbox entry: same transaction → guaranteed to be written\n        outboxRepository.save(OutboxEvent.builder()\n            .id(UUID.randomUUID())\n            .aggregateType(\"Order\")\n            .aggregateId(order.getId())\n            .type(\"order.created\")\n            .payload(objectMapper.writeValueAsString(OrderCreatedEvent.from(order)))\n            .build());\n\n        return order;\n    }\n}\n\n// Debezium watches the outbox table\n// When outbox row is inserted → WAL entry → Debezium reads → publishes to Kafka\n// No polling thread, no duplicate publish risk, no dual-write race condition\n</code></pre>\n<p>The beauty of this pattern is that your application code is simple and transactional — it writes to two tables and returns. All the complexity of reliable event delivery is handled by Debezium at the infrastructure layer, not scattered through your application code. The Kafka Connect EventRouter SMT routes each outbox event to the appropriate topic based on the <code>aggregate_type</code> field.</p>\n<pre><code class=\"language-json\">{\n  \"transforms\": \"outbox\",\n  \"transforms.outbox.type\": \"io.debezium.transforms.outbox.EventRouter\",\n  \"transforms.outbox.table.field.event.id\": \"id\",\n  \"transforms.outbox.table.field.event.type\": \"type\",\n  \"transforms.outbox.table.field.event.payload\": \"payload\",\n  \"transforms.outbox.route.by.field\": \"aggregate_type\",\n  \"transforms.outbox.route.topic.replacement\": \"outbox.${routedByValue}\"\n}\n</code></pre>\n<h2>Operational Considerations</h2>\n<h3>Replication Slot Lag</h3>\n<p>The most critical production concern: if Debezium is down or slow, PostgreSQL <strong>cannot clean up WAL</strong> until the replication slot reads it. WAL can grow to fill your disk.</p>\n<p>This is the one operational risk you must monitor closely. If your Debezium connector goes offline for hours during a busy period, your PostgreSQL disk can fill up entirely — which takes down your entire database, not just the CDC pipeline. Set up this query as an alert in your monitoring system, and treat it with the same urgency as disk space alerts.</p>\n<pre><code class=\"language-bash\"># Monitor replication slot lag (in bytes)\nSELECT slot_name,\n       pg_wal_lsn_diff(pg_current_wal_lsn(), restart_lsn) AS lag_bytes,\n       active\nFROM pg_replication_slots;\n\n# Alert if lag_bytes > 10GB (customize based on disk space and write rate)\n</code></pre>\n<p>Set a WAL disk limit and drop the slot if Debezium is offline too long:</p>\n<pre><code class=\"language-bash\"># Drop stalled replication slot (Debezium will re-snapshot on reconnect)\nSELECT pg_drop_replication_slot('debezium_pg_prod');\n</code></pre>\n<p>Dropping the slot is a drastic action — Debezium will need to perform a full snapshot on reconnect — but it's better than losing your primary database to disk exhaustion. The right approach is to automate slot removal after a configurable lag threshold.</p>\n<h3>Schema Evolution</h3>\n<p>When your database schema changes (new column, renamed column), Debezium handles this through Schema Registry versioning. Use <code>ALTER TABLE ... ADD COLUMN</code> safely — Debezium handles new columns gracefully. Renaming/dropping columns requires coordination with consumers.</p>\n<h3>Snapshot Mode</h3>\n<p>On initial deployment, Debezium can snapshot existing data:</p>\n<ul>\n<li><code>initial</code>: Snapshot all existing rows, then stream new changes (default — use for most cases)</li>\n<li><code>never</code>: Skip snapshot, only stream changes from now (use when data is already migrated)</li>\n<li><code>schema_only</code>: Only capture the schema, not existing data</li>\n</ul>\n<p>CDC with Debezium turns your database into a reliable event bus without changing application code. The WAL is already there — Debezium just makes it readable. For any microservice architecture where services need to react to data changes in other services' databases, CDC is the most reliable and operationally simple solution available.</p>\n","tableOfContents":[{"id":"why-cdc","text":"Why CDC?","level":2},{"id":"the-problem-dual-write","text":"The Problem: Dual-Write","level":3},{"id":"the-outbox-pattern-another-solution","text":"The Outbox Pattern (Another Solution)","level":3},{"id":"how-debezium-works","text":"How Debezium Works","level":2},{"id":"postgresql-configuration","text":"PostgreSQL Configuration","level":2},{"id":"debezium-connector-configuration","text":"Debezium Connector Configuration","level":2},{"id":"consumer-patterns","text":"Consumer Patterns","level":2},{"id":"pattern-1-cache-invalidation","text":"Pattern 1: Cache Invalidation","level":3},{"id":"pattern-2-elasticsearch-indexing","text":"Pattern 2: Elasticsearch Indexing","level":3},{"id":"pattern-3-materialized-view-maintenance-cqrs-read-model","text":"Pattern 3: Materialized View Maintenance (CQRS Read Model)","level":3},{"id":"the-outbox-pattern-with-debezium","text":"The Outbox Pattern with Debezium","level":2},{"id":"operational-considerations","text":"Operational Considerations","level":2},{"id":"replication-slot-lag","text":"Replication Slot Lag","level":3},{"id":"schema-evolution","text":"Schema Evolution","level":3},{"id":"snapshot-mode","text":"Snapshot Mode","level":3}]},"relatedPosts":[{"title":"Kafka Streams: Real-Time Stream Processing Without a Separate Cluster","description":"Production Kafka Streams: KStream vs KTable semantics, stateful transformations with RocksDB state stores, windowed aggregations, stream-table joins, topology design, changelog topics, and the operational patterns for running Kafka Streams in production.","date":"2025-04-24","category":"Data Engineering","tags":["kafka","kafka streams","stream processing","real-time","java","rocksdb","windowing","data engineering"],"featured":false,"affiliateSection":"data-engineering-resources","slug":"kafka-streams-real-time-processing","readingTime":"6 min read","excerpt":"Kafka Streams is a Java library for building real-time stream processing applications. Unlike Flink or Spark Streaming, it has no separate cluster — it runs as a library inside your Java application. Each instance of you…"}]},"__N_SSG":true}