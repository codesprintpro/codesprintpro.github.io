{"pageProps":{"post":{"title":"Java 21 Virtual Threads: The End of Reactive Programming Boilerplate","description":"Java 21 virtual threads let you write simple blocking code that scales like async. Understand how they work under the hood, when to use them, and what pitfalls to avoid.","date":"2025-02-05","category":"Java","tags":["java","java21","concurrency","virtual threads","spring boot"],"featured":true,"affiliateSection":"java-courses","slug":"java-virtual-threads-java21","readingTime":"12 min read","excerpt":"For the past decade, Java developers dealing with high-concurrency IO-bound workloads faced an uncomfortable choice: write readable sequential code that does not scale, or write reactive/async code that scales but is not…","contentHtml":"<p>For the past decade, Java developers dealing with high-concurrency IO-bound workloads faced an uncomfortable choice: write readable sequential code that does not scale, or write reactive/async code that scales but is notoriously difficult to debug and maintain. Project Loom, delivered in Java 21, eliminates this false dichotomy.</p>\n<p>Virtual threads let you write blocking sequential code that scales to millions of concurrent operations — no reactive frameworks, no callback chains, no <code>CompletableFuture</code> composition hell.</p>\n<h2>Why Platform Threads Don't Scale</h2>\n<p>A traditional Java <strong>platform thread</strong> maps 1:1 to an OS thread:</p>\n<ul>\n<li><strong>Stack size</strong>: 512KB to 1MB per thread</li>\n<li><strong>Practical OS limit</strong>: ~10,000 threads before scheduling overhead dominates</li>\n<li><strong>Blocking cost</strong>: A platform thread waiting on IO holds an OS thread — doing nothing</li>\n</ul>\n<p>At 10,000 concurrent requests each waiting 50ms for a database query, you need 10,000 OS threads. That's 5-10 GB of stack memory. This is why servlet containers default to 200 threads — not because engineers are lazy, but because threads are expensive.</p>\n<p>The reactive model addresses this by making IO non-blocking (callbacks, Mono/Flux). The thread releases while IO waits, then a callback runs when IO completes. High throughput, low thread count — but at serious complexity cost. To understand why that complexity matters, consider what a real concurrent fetch looks like once you leave the happy path. The following example demonstrates a parallel user profile build using <code>CompletableFuture</code> — notice how much ceremony you need just to run three calls concurrently and handle a failure:</p>\n<pre><code class=\"language-java\">// CompletableFuture: parallel user profile fetch — readable, but complex\npublic CompletableFuture&#x3C;UserProfile> buildProfile(String userId) {\n    return CompletableFuture\n        .supplyAsync(() -> userService.fetch(userId))\n        .thenCombine(\n            CompletableFuture.supplyAsync(() -> subscriptionService.fetch(userId)),\n            (user, sub) -> {\n                try {\n                    List&#x3C;Product> recs = recommendationService.fetch(user.getPreferences());\n                    return new UserProfile(user, sub, recs);\n                } catch (Exception e) {\n                    throw new CompletionException(e);\n                }\n            }\n        )\n        .exceptionally(e -> {\n            log.error(\"Failed to build profile\", e);\n            return UserProfile.empty();\n        });\n}\n</code></pre>\n<p>Stack traces in reactive code show only the current stage. Thread-local context (MDC, security) breaks. The mental model is fundamentally different from sequential code.</p>\n<h2>How Virtual Threads Work</h2>\n<p>Before writing any code, it helps to understand the architectural difference between platform threads and virtual threads. Think of carrier threads as a small team of workers (one per CPU core), and virtual threads as a vast queue of tasks those workers pick up whenever they are free. When a virtual thread blocks on IO, the worker sets it aside and immediately picks up the next waiting task — nothing is wasted.</p>\n<pre><code>Platform Thread Model (1:1 with OS):\n\n  VT1 ──► OS Thread 1 (blocked on DB, holding OS thread)\n  VT2 ──► OS Thread 2 (blocked on HTTP call, holding OS thread)\n  ...\n  N limited by OS (typical max: 10K)\n\nVirtual Thread Model (M:N with OS):\n\n  VT1 ─┐\n  VT2 ─┤ Scheduled onto ─► Carrier Thread 1 (= 1 OS thread)\n  VT3 ─┤                 ─► Carrier Thread 2 (= 1 OS thread)\n  VTM ─┘                 ─► Carrier Thread N (N = CPU cores)\n\n  M can be millions — each VT is ~1KB on heap (not stack)\n</code></pre>\n<p>When a virtual thread hits a blocking operation (JDBC query, HTTP call, <code>Thread.sleep()</code>), the JVM <strong>unmounts</strong> the virtual thread from the carrier: saves its stack to the heap and lets the carrier take another virtual thread. When the IO completes, the virtual thread is rescheduled — mounted onto an available carrier. The OS never blocks.</p>\n<p>This is why virtual threads can handle 100K concurrent connections with only 8 carrier threads (one per CPU core).</p>\n<h2>Creating Virtual Threads</h2>\n<p>Java 21 gives you three ways to create virtual threads, each suited to a different context. Choose the one that fits how your application is structured — the <code>newVirtualThreadPerTaskExecutor</code> is the most practical choice for service-layer code because it integrates cleanly with <code>ExecutorService</code> and supports <code>Future</code>-based result collection:</p>\n<pre><code class=\"language-java\">// Method 1: Thread.ofVirtual()\nThread vt = Thread.ofVirtual()\n    .name(\"handler-\", 0)   // Named: handler-0, handler-1, ...\n    .start(() -> handleRequest(request));\n\n// Method 2: Virtual thread per task executor (most common in services)\ntry (ExecutorService exec = Executors.newVirtualThreadPerTaskExecutor()) {\n    Future&#x3C;UserProfile> profileFuture = exec.submit(() -> buildProfile(userId));\n    Future&#x3C;List&#x3C;Order>> ordersFuture = exec.submit(() -> fetchOrders(userId));\n\n    // Both run on virtual threads concurrently\n    // .get() blocks the calling virtual thread — unmounts it while waiting\n    UserProfile profile = profileFuture.get();\n    List&#x3C;Order> orders = ordersFuture.get();\n}\n\n// Method 3: Thread factory (for integrating with existing APIs)\nThreadFactory vtFactory = Thread.ofVirtual().factory();\nScheduledExecutorService scheduler = Executors.newScheduledThreadPool(0, vtFactory);\n</code></pre>\n<p>Notice that <code>.get()</code> in Method 2 blocks the <em>calling</em> virtual thread, not the carrier — so even your result-collection code is non-blocking at the OS level.</p>\n<h2>Structured Concurrency: The Right Way to Fan Out</h2>\n<p>Virtual threads solve the scalability problem, but running multiple concurrent tasks still requires coordination. Java 21 also introduces <code>StructuredTaskScope</code> — a cleaner model for running concurrent subtasks that makes the relationship between parent and child tasks explicit and ensures no subtask can outlive its enclosing scope:</p>\n<pre><code class=\"language-java\">import java.util.concurrent.StructuredTaskScope;\n\n// Old way: CompletableFuture fan-out\npublic UserDashboard buildDashboard(String userId) throws InterruptedException {\n    try (var scope = new StructuredTaskScope.ShutdownOnFailure()) {\n        // All three tasks start immediately on virtual threads\n        var userTask    = scope.fork(() -> userService.fetch(userId));\n        var ordersTask  = scope.fork(() -> orderService.fetchRecent(userId, 10));\n        var notifTask   = scope.fork(() -> notificationService.getUnread(userId));\n\n        // Wait for all — or cancel all if any fails (ShutdownOnFailure)\n        scope.join();\n        scope.throwIfFailed(e -> new DashboardBuildException(\"Failed to build dashboard\", e));\n\n        // All subtasks complete here — results are available\n        return new UserDashboard(\n            userTask.get(),\n            ordersTask.get(),\n            notifTask.get()\n        );\n    }\n    // Scope exit guarantees: no subtask outlives this block\n    // Any exception = all subtasks cancelled\n}\n</code></pre>\n<p><code>ShutdownOnFailure</code> is one scope policy. <code>ShutdownOnSuccess</code> cancels remaining tasks as soon as one succeeds — useful for \"first result wins\" patterns. This is a natural fit for scenarios like reading from multiple replicas where you care only about getting the fastest response, not all of them:</p>\n<pre><code class=\"language-java\">// Race multiple read replicas — use whichever responds first\npublic String readFromFastestReplica(String key) throws Exception {\n    try (var scope = new StructuredTaskScope.ShutdownOnSuccess&#x3C;String>()) {\n        scope.fork(() -> replica1.get(key));\n        scope.fork(() -> replica2.get(key));\n        scope.fork(() -> replica3.get(key));\n\n        scope.join();\n        return scope.result(); // First successful result\n    }\n}\n</code></pre>\n<p>The key insight here is that <code>ShutdownOnSuccess</code> automatically cancels the two slower replicas once the first result arrives, preventing wasted work and keeping resource consumption predictable.</p>\n<h2>Spring Boot 3.2 Configuration</h2>\n<p>Now that you understand how virtual threads work, enabling them in your Spring Boot application is deliberately straightforward. Virtual threads in Spring Boot 3.2+ require one line:</p>\n<pre><code class=\"language-yaml\"># application.yml\nspring:\n  threads:\n    virtual:\n      enabled: true\n</code></pre>\n<p>This switches Tomcat's thread pool to virtual threads. Each incoming HTTP request gets its own virtual thread. JDBC calls, Redis operations, and HTTP client calls block that virtual thread (not the carrier), freeing the carrier for other requests.</p>\n<p>Once you've enabled virtual threads, you can verify they are actually being used at runtime by adding a small diagnostic endpoint. This is especially useful when first rolling out the change to catch any misconfiguration early:</p>\n<pre><code class=\"language-java\">@RestController\npublic class DiagnosticsController {\n\n    @GetMapping(\"/thread-info\")\n    public Map&#x3C;String, Object> threadInfo() {\n        Thread t = Thread.currentThread();\n        return Map.of(\n            \"name\", t.getName(),\n            \"isVirtual\", t.isVirtual(),\n            \"isDaemon\", t.isDaemon()\n        );\n    }\n}\n// Returns: {\"name\":\"tomcat-handler-7\",\"isVirtual\":true,\"isDaemon\":true}\n</code></pre>\n<h2>Benchmark: Virtual Threads vs Platform Threads</h2>\n<p>The following benchmark results illustrate the real-world impact of virtual threads. The test simulates a realistic IO-bound endpoint — something like any database-backed REST API — where threads spend most of their time waiting rather than computing:</p>\n<pre><code>Environment: EC2 c5.2xlarge (8 vCPUs, 16GB RAM), JDK 21.0.2\n\nConcurrency │ Platform Threads (200 pool) │ Virtual Threads\n────────────┼─────────────────────────────┼─────────────────\n       200  │  3,960 rps, p99: 52ms       │  3,980 rps, p99: 51ms\n     1,000  │    980 rps, p99: 1.02s      │ 19,600 rps, p99: 52ms\n     5,000  │    timeout                  │ 98,000 rps, p99: 53ms\n    10,000  │    OOM / GC pressure        │ 195,000 rps, p99: 55ms\n\nMemory at 10,000 concurrent requests:\n  Platform Threads: OOM (200 thread pool creates massive queue backlog)\n  Virtual Threads: ~2.1 GB heap (10K stack frames at ~200KB each)\n</code></pre>\n<p>Below 200 concurrent requests, performance is identical. Above 200, platform threads queue up while virtual threads scale linearly with IO wait time.</p>\n<h2>Pitfall 1: Pinning</h2>\n<p>With the performance benefits clear, it's equally important to understand the one failure mode that can silently erase those gains. A virtual thread <strong>pins</strong> to its carrier when inside a <code>synchronized</code> block. While pinned, the carrier cannot take other virtual threads — blocking the OS thread and recreating the exact problem virtual threads were designed to solve.</p>\n<pre><code class=\"language-java\">// PROBLEM: synchronized + IO = carrier thread blocks\npublic synchronized String fetchData(String key) {\n    return database.query(\"SELECT value FROM cache WHERE key = ?\", key);\n    // Database call blocks inside synchronized → pins carrier thread\n}\n\n// SOLUTION: Replace synchronized with ReentrantLock\nprivate final ReentrantLock lock = new ReentrantLock();\n\npublic String fetchData(String key) {\n    lock.lock(); // Virtual thread parks here (unmountable), not carrier\n    try {\n        return database.query(\"SELECT value FROM cache WHERE key = ?\", key);\n    } finally {\n        lock.unlock();\n    }\n}\n\n// BETTER SOLUTION: Minimize lock scope — lock only for in-memory state\npublic String fetchData(String key) {\n    // IO outside the lock\n    String result = database.query(\"SELECT value FROM cache WHERE key = ?\", key);\n\n    // Lock only for the in-memory cache update\n    synchronized (this) {\n        localCache.put(key, result);\n    }\n    return result;\n}\n</code></pre>\n<p>The \"better solution\" above illustrates a broader principle: separate IO from in-memory coordination. By doing the database call outside the lock, you ensure the virtual thread can unmount during the slow operation, and only hold the lock for the fast, in-memory cache update. Use the JVM's built-in diagnostics to detect any remaining pinning in your application:</p>\n<pre><code class=\"language-bash\"># JVM flag: print stack trace when virtual thread pins for >20ms\njava -Djdk.tracePinnedThreads=full -jar app.jar\n\n# During load test, watch for:\n# VirtualThread[#48]/runnable@ForkJoinPool-1-worker-3\n#     java.base/.../Unsafe.park (pinned due to monitor hold)\n</code></pre>\n<p><strong>Common libraries with pinning issues (as of 2025):</strong></p>\n<ul>\n<li><strong>HikariCP</strong> &#x3C; 5.1.0: Uses <code>synchronized</code> internally. Workaround: set carrier thread pool size to match HikariCP max pool size</li>\n<li><strong>Some JDBC drivers</strong>: Oracle, older MySQL connectors</li>\n<li><strong>Legacy code</strong> with <code>synchronized</code> on IO paths</li>\n</ul>\n<h2>Pitfall 2: Thread-Local State</h2>\n<p>The second common pitfall involves how context is passed through the call stack. <code>ThreadLocal</code> works with virtual threads — each virtual thread has its own <code>ThreadLocal</code> map. The subtle problem is that <code>ThreadLocal</code> values set in one request can leak to subsequent requests if not cleaned up.</p>\n<pre><code class=\"language-java\">// LEAK: ThreadLocal not cleared\npublic void processRequest(Request req) {\n    MDC.put(\"requestId\", req.getId());    // Sets ThreadLocal\n    handleRequest(req);\n    // Missing: MDC.clear()\n    // If this virtual thread is reused, next request inherits old requestId\n}\n\n// SAFE: Always clean up in finally\npublic void processRequest(Request req) {\n    try {\n        MDC.put(\"requestId\", req.getId());\n        handleRequest(req);\n    } finally {\n        MDC.clear();\n    }\n}\n\n// BEST for Java 21+: Use ScopedValue (replaces ThreadLocal for shared context)\nstatic final ScopedValue&#x3C;RequestContext> REQUEST_CTX = ScopedValue.newInstance();\n\npublic void processRequest(Request req) {\n    ScopedValue.runWhere(REQUEST_CTX, new RequestContext(req), () -> {\n        handleRequest(req);\n    }); // ScopedValue automatically cleaned up when runWhere exits\n}\n\nprivate void deepInCallStack() {\n    // Access from anywhere without passing as parameter\n    RequestContext ctx = REQUEST_CTX.get();\n    MDC.put(\"requestId\", ctx.getRequestId());\n}\n</code></pre>\n<p><code>ScopedValue</code> is the long-term solution: it is immutable, automatically scoped to the <code>runWhere</code> block, and eliminates the cleanup burden entirely. Prefer it over <code>ThreadLocal</code> for any new code written on Java 21+.</p>\n<h2>When NOT to Use Virtual Threads</h2>\n<p>Virtual threads are a powerful tool, but they are not a universal replacement for every concurrency approach. Knowing the boundaries of their usefulness is as important as knowing how to enable them.</p>\n<ol>\n<li>\n<p><strong>CPU-bound work</strong>: Virtual threads only help when threads park (wait for IO). CPU-bound tasks never park — they keep the carrier busy. Use <code>ForkJoinPool</code> for CPU-intensive work.</p>\n</li>\n<li>\n<p><strong>Very high-frequency, very-short tasks</strong>: Nanosecond-duration tasks where virtual thread scheduling overhead dominates. Prefer <code>CompletableFuture</code> with a bounded pool.</p>\n</li>\n<li>\n<p><strong>Libraries with extensive native pinning</strong>: If critical paths run through JNI code that holds monitors, virtual threads cannot help.</p>\n</li>\n</ol>\n<p>For CPU-bound workloads, parallel streams backed by <code>ForkJoinPool</code> remain the right tool — they keep all cores busy with actual computation rather than waiting on IO:</p>\n<pre><code class=\"language-java\">// For CPU-bound parallel work, still use ForkJoinPool or parallel streams:\nList&#x3C;Result> results = items.parallelStream()\n    .map(this::expensiveComputation) // ForkJoinPool, not virtual threads\n    .collect(Collectors.toList());\n</code></pre>\n<h2>Migration Checklist</h2>\n<p>With the concepts and pitfalls covered, here is a practical, step-by-step checklist for migrating an existing Spring Boot application to virtual threads. Follow the steps in order — enabling virtual threads first and then diagnosing pinning issues is far more productive than auditing every <code>synchronized</code> block upfront:</p>\n<pre><code class=\"language-bash\"># 1. Upgrade\n#    Java: 21+\n#    Spring Boot: 3.2+\n#    Maven/Gradle: latest\n\n# 2. Enable virtual threads (one line)\necho \"spring.threads.virtual.enabled=true\" >> application.yml\n\n# 3. Detect pinning\njava -Djdk.tracePinnedThreads=full -jar app.jar\n# Run load test, watch logs for pinning events\n\n# 4. Replace synchronized+IO with ReentrantLock\ngrep -r \"synchronized\" src/main/java/ | grep -i \"repository\\|service\\|dao\"\n\n# 5. Upgrade HikariCP to 5.1.0+ (reduced synchronized blocks)\n# Or set: maximumPoolSize = expected concurrent DB operations (not threads)\n\n# 6. Remove artificial thread pool limits\n# Remove from application.properties:\n#   server.tomcat.threads.max=200\n#   spring.task.execution.pool.max-size=50\n# (Virtual threads don't need these — they scale automatically)\n\n# 7. Load test and compare p99 latency at high concurrency\n</code></pre>\n<p>Virtual threads represent a paradigm shift for Java. For the first time, high-concurrency IO-bound applications can be written with simple, sequential, debuggable code — and still achieve throughput that previously required reactive frameworks. The migration cost is near-zero for Spring Boot applications. The remaining challenge is library adoption, and that is improving rapidly with each JDK release.</p>\n","tableOfContents":[{"id":"why-platform-threads-dont-scale","text":"Why Platform Threads Don't Scale","level":2},{"id":"how-virtual-threads-work","text":"How Virtual Threads Work","level":2},{"id":"creating-virtual-threads","text":"Creating Virtual Threads","level":2},{"id":"structured-concurrency-the-right-way-to-fan-out","text":"Structured Concurrency: The Right Way to Fan Out","level":2},{"id":"spring-boot-32-configuration","text":"Spring Boot 3.2 Configuration","level":2},{"id":"benchmark-virtual-threads-vs-platform-threads","text":"Benchmark: Virtual Threads vs Platform Threads","level":2},{"id":"pitfall-1-pinning","text":"Pitfall 1: Pinning","level":2},{"id":"pitfall-2-thread-local-state","text":"Pitfall 2: Thread-Local State","level":2},{"id":"when-not-to-use-virtual-threads","text":"When NOT to Use Virtual Threads","level":2},{"id":"migration-checklist","text":"Migration Checklist","level":2}]},"relatedPosts":[{"title":"Java Concurrency Patterns: CompletableFuture, Structured Concurrency, and Thread-Safe Design","description":"Production Java concurrency: CompletableFuture pipelines, handling exceptions in async chains, Java 21 structured concurrency, thread-safe collection patterns, and the concurrency bugs that cause data corruption.","date":"2025-07-08","category":"Java","tags":["java","concurrency","completablefuture","virtual threads","java21","thread-safe","async"],"featured":false,"affiliateSection":"java-courses","slug":"java-concurrency-patterns","readingTime":"7 min read","excerpt":"Java concurrency has three eras: raw  and  (Java 1-4), the  framework (Java 5+), and the virtual thread/structured concurrency era (Java 21+). Each era's patterns still exist in production codebases. Understanding all th…"},{"title":"Java Memory Management Deep Dive: Heap, GC, and Production Tuning","description":"How the JVM allocates memory, how G1GC and ZGC work under the hood, heap analysis with JVM tools, and the GC tuning decisions that eliminate latency spikes in production Java services.","date":"2025-06-13","category":"Java","tags":["java","jvm","garbage collection","g1gc","zgc","heap","memory management","performance"],"featured":false,"affiliateSection":"java-courses","slug":"java-memory-management-deep-dive","readingTime":"7 min read","excerpt":"Java's garbage collector is the single biggest source of unexplained latency spikes in production services. A GC pause of 2 seconds is invisible in most logs but visible to every user who happened to make a request durin…"},{"title":"Spring Security OAuth2 and JWT: Production Implementation Guide","description":"Complete Spring Security OAuth2 implementation: JWT token validation, Resource Server configuration, method-level security, custom UserDetailsService, refresh token rotation, and the security pitfalls that lead to authentication bypasses.","date":"2025-06-03","category":"Java","tags":["spring security","oauth2","jwt","spring boot","authentication","authorization","java","security"],"featured":false,"affiliateSection":"java-courses","slug":"spring-security-oauth2-jwt","readingTime":"7 min read","excerpt":"Spring Security is one of the most powerful and most misunderstood frameworks in the Java ecosystem. Its flexibility is its strength — and its complexity. Misconfigured security is worse than no security, because it give…"}]},"__N_SSG":true}