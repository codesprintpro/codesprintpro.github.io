{"pageProps":{"post":{"title":"Event-Driven Architecture: CQRS and Event Sourcing in Practice","description":"Master CQRS (Command Query Responsibility Segregation) and Event Sourcing patterns for scalable, auditable systems. Includes Spring Boot + Axon Framework implementation with Kafka event store.","date":"2025-03-03","category":"System Design","tags":["event sourcing","cqrs","event-driven","kafka","spring boot","axon"],"featured":false,"affiliateSection":"system-design-courses","slug":"event-driven-cqrs-event-sourcing","readingTime":"14 min read","excerpt":"Traditional CRUD systems store current state. Event-driven systems store the history of state changes. This single difference is more profound than it first appears: instead of asking \"what is the current status of order…","contentHtml":"<p>Traditional CRUD systems store <strong>current state</strong>. Event-driven systems store the <strong>history of state changes</strong>. This single difference is more profound than it first appears: instead of asking \"what is the current status of order #123?\", you ask \"what sequence of events happened to order #123?\" — and you can derive the current status from that sequence at any point in time.</p>\n<p>The trade-off is real: event sourcing introduces complexity that a simple CRUD app doesn't need. But for systems where audit trails matter (finance, healthcare, e-commerce), where you need to replay history to fix bugs, or where you want to scale reads and writes independently, the pattern pays for itself over time. This article shows you when it's worth it and how to implement it right.</p>\n<h2>The Problem CQRS and Event Sourcing Solve</h2>\n<p>Consider what happens in a traditional system when an order is shipped. You run a single UPDATE statement and the previous state — when it was confirmed, who approved it, what the original items were — is gone forever. This is fine for many applications. It becomes a serious problem when:</p>\n<ul>\n<li>A compliance team asks: \"Show me every change made to this order and who made it.\"</li>\n<li>A bug caused incorrect state and you need to reconstruct what actually happened.</li>\n<li>Your dashboard query locks the table that your order creation query also needs.</li>\n</ul>\n<pre><code>Traditional CRUD:\n  UPDATE orders SET status = 'SHIPPED', updated_at = NOW() WHERE id = 123\n\n  Problems:\n  1. History lost — you can't answer \"when did this order become CONFIRMED?\"\n  2. Read and write load couple — slow reporting queries block order creation\n  3. No audit trail — compliance asks \"who changed this?\" and you have nothing\n  4. Temporal queries impossible — \"what was the state on Jan 1?\" = mystery\n\nEvent Sourcing:\n  INSERT INTO events (aggregate_id, type, data, timestamp) VALUES\n    (123, 'OrderCreated', {...}, T1),\n    (123, 'PaymentProcessed', {...}, T2),\n    (123, 'OrderShipped', {...}, T3)\n\n  Benefits:\n  1. Full history — every state change recorded\n  2. Rebuild any past state by replaying events to point-in-time\n  3. Natural audit log (SOX, GDPR, financial compliance)\n  4. Events drive downstream projections, notifications, analytics\n</code></pre>\n<p>Notice that in the event-sourced version, you never update a row — you only ever append new events. The current state of an order is derived by replaying those events from the beginning. This immutability is what gives you the time-machine capability.</p>\n<h2>CQRS: Separate Read and Write Models</h2>\n<p>CQRS (Command Query Responsibility Segregation) is a natural companion to event sourcing. The core idea is that the model you use to change data (the write model) doesn't have to be the same model you use to read data (the read model).</p>\n<ul>\n<li><strong>Command side</strong>: Handles writes. Validates business rules. Emits events. Optimised for correctness, not query flexibility.</li>\n<li><strong>Query side</strong>: Handles reads. Denormalized. Shaped to answer specific queries fast. Can have as many different read models as you need.</li>\n</ul>\n<pre><code>                    ┌─────────────────────┐\n                    │   Command Handler   │\nCommand ──────────► │ (validate + execute)│──► Event Store ──► Events\n                    └─────────────────────┘         │\n                                                     │ Event Bus\n                                                     │\n                    ┌─────────────────────┐          ▼\nQuery  ──────────► │   Query Handler     │◄── Read Model (Projections)\nResult ◄────────── │  (read-optimized)   │    (denormalized views)\n                    └─────────────────────┘\n</code></pre>\n<p>The write side emits events. Those events flow to one or more <strong>projections</strong> — read-optimized views of the data. You can have a projection for the customer dashboard, a different one for admin reporting, and another one for analytics — all built from the same stream of events. This is the real power: one source of truth, many tailored views.</p>\n<h2>Implementation: Order System with Axon Framework</h2>\n<h3>Commands and Events</h3>\n<p>The most important conceptual distinction in this pattern is the difference between <strong>commands</strong> and <strong>events</strong>. They sound similar but serve opposite purposes:</p>\n<ul>\n<li>A <strong>command</strong> is an <strong>intent</strong> — \"Please create this order.\" It's imperative and can be rejected. If business validation fails (e.g., the cart is empty), the command is rejected and no event is produced.</li>\n<li>An <strong>event</strong> is a <strong>fact</strong> — \"An order was created.\" It's past tense and immutable. Once emitted, it cannot be undone.</li>\n</ul>\n<p>This separation enforces a clean boundary: all validation happens before the event is produced. By the time an event exists, it represents something that definitively happened.</p>\n<pre><code class=\"language-java\">// Commands represent intent (\"do this\") — can be rejected\npublic record CreateOrderCommand(\n    @TargetAggregateIdentifier String orderId,\n    String customerId,\n    List&#x3C;OrderItem> items\n) {}\n\npublic record ConfirmOrderCommand(\n    @TargetAggregateIdentifier String orderId\n) {}\n\npublic record ShipOrderCommand(\n    @TargetAggregateIdentifier String orderId,\n    String trackingNumber\n) {}\n\n// Events represent facts (\"this happened\") — immutable, past tense\npublic record OrderCreatedEvent(\n    String orderId,\n    String customerId,\n    List&#x3C;OrderItem> items,\n    Instant createdAt\n) {}\n\npublic record OrderConfirmedEvent(\n    String orderId,\n    Instant confirmedAt\n) {}\n\npublic record OrderShippedEvent(\n    String orderId,\n    String trackingNumber,\n    Instant shippedAt\n) {}\n</code></pre>\n<p>Notice that commands are named imperatively (<code>CreateOrderCommand</code>) while events are named in past tense (<code>OrderCreatedEvent</code>). This naming convention isn't cosmetic — it reflects whether something is a request that could fail or a historical fact that already happened.</p>\n<h3>The Aggregate: Command Side</h3>\n<p>An <strong>aggregate</strong> is the consistency boundary in your domain model. It's the gatekeeper: all business rules live here, and it's the only thing that decides whether a command is valid and what events it produces.</p>\n<p>The crucial rule in event sourcing: <strong>state is never set directly in command handlers</strong>. Instead, a command handler validates the request and applies an event. The <code>@EventSourcingHandler</code> methods then update the internal state. This indirection exists because the same event sourcing handlers are called both when processing new commands <em>and</em> when replaying historical events to rebuild state. The state-change logic must live in one place.</p>\n<pre><code class=\"language-java\">@Aggregate\npublic class OrderAggregate {\n\n    @AggregateIdentifier\n    private String orderId;\n    private String customerId;\n    private OrderStatus status;\n    private List&#x3C;OrderItem> items;\n\n    // Constructor command handler: validates, then emits an event\n    @CommandHandler\n    public OrderAggregate(CreateOrderCommand command) {\n        // Step 1: Validate the business rule\n        if (command.items().isEmpty()) {\n            throw new IllegalArgumentException(\"Order must have at least one item\");\n        }\n\n        // Step 2: Apply an event — NEVER set fields directly here\n        // AggregateLifecycle.apply() calls the @EventSourcingHandler below\n        AggregateLifecycle.apply(new OrderCreatedEvent(\n            command.orderId(),\n            command.customerId(),\n            command.items(),\n            Instant.now()\n        ));\n    }\n\n    @CommandHandler\n    public void handle(ConfirmOrderCommand command) {\n        // Guard: only valid state transitions are allowed\n        if (status != OrderStatus.PENDING) {\n            throw new IllegalStateException(\"Can only confirm PENDING orders, current: \" + status);\n        }\n        AggregateLifecycle.apply(new OrderConfirmedEvent(orderId, Instant.now()));\n    }\n\n    @CommandHandler\n    public void handle(ShipOrderCommand command) {\n        if (status != OrderStatus.CONFIRMED) {\n            throw new IllegalStateException(\"Can only ship CONFIRMED orders\");\n        }\n        AggregateLifecycle.apply(new OrderShippedEvent(orderId, command.trackingNumber(), Instant.now()));\n    }\n\n    // @EventSourcingHandler: updates internal state from events.\n    // Called for NEW events (after apply()) AND when REPLAYING historical events.\n    // This is the only place where fields are assigned.\n    @EventSourcingHandler\n    public void on(OrderCreatedEvent event) {\n        this.orderId = event.orderId();\n        this.customerId = event.customerId();\n        this.items = event.items();\n        this.status = OrderStatus.PENDING;\n    }\n\n    @EventSourcingHandler\n    public void on(OrderConfirmedEvent event) {\n        this.status = OrderStatus.CONFIRMED;\n    }\n\n    @EventSourcingHandler\n    public void on(OrderShippedEvent event) {\n        this.status = OrderStatus.SHIPPED;\n    }\n}\n</code></pre>\n<p>The lifecycle when <code>ShipOrder</code> is received on a new request: Axon loads all past events for that order from the event store, replays them through the <code>@EventSourcingHandler</code> methods to reconstruct the current state, then calls the <code>@CommandHandler</code> with that state available. If validation passes, the new event is appended to the store. If it fails, nothing is written.</p>\n<h3>Query Side: Projections</h3>\n<p>A <strong>projection</strong> is a read-optimized view of your data, built by listening to events. Think of it as a continuously-updated materialized view. Unlike the command side (which is normalized and focused on correctness), projections are denormalized and shaped to answer specific queries as fast as possible.</p>\n<p>The key insight is that you can have as many projections as you want, each serving a different use case. A customer-facing dashboard projection might join order + customer data and cache it in Redis. An admin reporting projection might aggregate order totals by region and store them in a reporting database. Both are built from the same events — you're not duplicating writes, you're building tailored read models.</p>\n<pre><code class=\"language-java\">// Projection: listens to events and maintains a denormalized read model\n@Component\n@ProcessingGroup(\"order-projections\")\npublic class OrderProjection {\n\n    @Autowired\n    private OrderViewRepository repository;  // Simple JPA repository — plain SQL table\n\n    // When an order is created, build the initial read-model row\n    @EventHandler\n    public void on(OrderCreatedEvent event) {\n        OrderView view = new OrderView();\n        view.setOrderId(event.orderId());\n        view.setCustomerId(event.customerId());\n        view.setStatus(\"PENDING\");\n        view.setItemCount(event.items().size());\n        view.setTotalAmount(calculateTotal(event.items()));\n        view.setCreatedAt(event.createdAt());\n        repository.save(view);\n    }\n\n    // When an order is confirmed, update just the fields that changed\n    @EventHandler\n    public void on(OrderConfirmedEvent event) {\n        repository.findById(event.orderId()).ifPresent(view -> {\n            view.setStatus(\"CONFIRMED\");\n            view.setConfirmedAt(event.confirmedAt());\n            repository.save(view);\n        });\n    }\n\n    @EventHandler\n    public void on(OrderShippedEvent event) {\n        repository.findById(event.orderId()).ifPresent(view -> {\n            view.setStatus(\"SHIPPED\");\n            view.setTrackingNumber(event.trackingNumber());\n            view.setShippedAt(event.shippedAt());\n            repository.save(view);\n        });\n    }\n}\n\n// Query handlers serve the read model directly — no joins, no aggregation at query time\n@Component\npublic class OrderQueryHandler {\n\n    @Autowired\n    private OrderViewRepository repository;\n\n    @QueryHandler\n    public OrderView handle(GetOrderQuery query) {\n        return repository.findById(query.orderId())\n            .orElseThrow(() -> new OrderNotFoundException(query.orderId()));\n    }\n\n    @QueryHandler\n    public List&#x3C;OrderView> handle(GetCustomerOrdersQuery query) {\n        return repository.findByCustomerIdOrderByCreatedAtDesc(query.customerId());\n    }\n\n    @QueryHandler\n    public Page&#x3C;OrderView> handle(GetOrdersByStatusQuery query) {\n        return repository.findByStatus(query.status(), query.pageable());\n    }\n}\n</code></pre>\n<p>Notice that <code>GetCustomerOrdersQuery</code> is a simple <code>findByCustomerIdOrderByCreatedAtDesc</code> call — no complex joins, no aggregation, just a fast indexed lookup. The read model was pre-shaped at event time, so queries are cheap regardless of how complex the business logic is.</p>\n<h3>API Layer</h3>\n<p>The controller is deliberately thin. It delegates write operations to the <code>CommandGateway</code> (which routes to the aggregate) and read operations to the <code>QueryGateway</code> (which routes to the projections). The controller doesn't contain any business logic — it just translates HTTP into commands and queries.</p>\n<pre><code class=\"language-java\">@RestController\n@RequestMapping(\"/api/v1/orders\")\npublic class OrderController {\n\n    @Autowired\n    private CommandGateway commandGateway;  // Routes to @CommandHandler methods\n\n    @Autowired\n    private QueryGateway queryGateway;      // Routes to @QueryHandler methods\n\n    // WRITE side: send a command and get back the result asynchronously\n    // Returns 202 Accepted (not 201 Created) because events are processed async\n    @PostMapping\n    public CompletableFuture&#x3C;ResponseEntity&#x3C;String>> createOrder(\n            @RequestBody CreateOrderRequest request) {\n        String orderId = UUID.randomUUID().toString();\n        return commandGateway\n            .send(new CreateOrderCommand(orderId, request.customerId(), request.items()))\n            .thenApply(result -> ResponseEntity.accepted()\n                .header(\"Location\", \"/api/v1/orders/\" + orderId)\n                .body(orderId));\n    }\n\n    @PostMapping(\"/{id}/confirm\")\n    public CompletableFuture&#x3C;Void> confirmOrder(@PathVariable String id) {\n        return commandGateway.send(new ConfirmOrderCommand(id));\n    }\n\n    // READ side: query the denormalized projection, not the event store\n    @GetMapping(\"/{id}\")\n    public CompletableFuture&#x3C;OrderView> getOrder(@PathVariable String id) {\n        return queryGateway.query(new GetOrderQuery(id), OrderView.class);\n    }\n\n    @GetMapping\n    public CompletableFuture&#x3C;List&#x3C;OrderView>> getOrdersByStatus(\n            @RequestParam String status) {\n        return queryGateway.query(new GetOrdersByStatusQuery(status),\n            ResponseTypes.multipleInstancesOf(OrderView.class));\n    }\n}\n</code></pre>\n<p>Why <code>202 Accepted</code> instead of <code>201 Created</code>? Because CQRS systems are often eventually consistent — the command is processed and the event is stored, but the projection (which feeds the read model) updates asynchronously. Returning the orderId in the <code>Location</code> header lets the client poll for the created resource.</p>\n<h2>Event Sourcing Without a Framework</h2>\n<p>Axon is powerful but heavyweight. For teams that want the event sourcing concept without adopting a full framework, the pattern translates directly into plain Spring + JDBC.</p>\n<p>The essence of a DIY event store is simple: every state-changing operation appends a row to the <code>domain_events</code> table. To load an aggregate, you read all its events ordered by version and replay them — calling <code>aggregate.apply(event)</code> for each one — until the aggregate's internal state reflects the current reality.</p>\n<pre><code class=\"language-java\">@Service\npublic class OrderEventStore {\n\n    @Autowired\n    private JdbcTemplate jdbc;\n\n    @Autowired\n    private ObjectMapper mapper;\n\n    public void appendEvent(String aggregateId, DomainEvent event) {\n        long expectedVersion = getCurrentVersion(aggregateId);\n        // Each event gets the next version number — this is how ordering is guaranteed\n        jdbc.update(\"\"\"\n            INSERT INTO domain_events (aggregate_id, version, event_type, event_data, occurred_at)\n            VALUES (?, ?, ?, ?::jsonb, ?)\n            \"\"\",\n            aggregateId,\n            expectedVersion + 1,\n            event.getClass().getSimpleName(),\n            mapper.writeValueAsString(event),\n            event.getOccurredAt()\n        );\n    }\n\n    public List&#x3C;DomainEvent> loadEvents(String aggregateId) {\n        // Always load in ascending version order — replay must be chronological\n        return jdbc.query(\"\"\"\n            SELECT event_type, event_data\n            FROM domain_events\n            WHERE aggregate_id = ?\n            ORDER BY version ASC\n            \"\"\",\n            (rs, row) -> deserializeEvent(rs.getString(\"event_type\"), rs.getString(\"event_data\")),\n            aggregateId\n        );\n    }\n\n    // Load aggregate by replaying its entire event history\n    public OrderAggregate load(String orderId) {\n        List&#x3C;DomainEvent> events = loadEvents(orderId);\n        if (events.isEmpty()) throw new AggregateNotFoundException(orderId);\n\n        OrderAggregate aggregate = new OrderAggregate();\n        // Each call to apply() mutates the aggregate's internal state\n        // After the loop, aggregate reflects the current state\n        events.forEach(aggregate::apply);\n        return aggregate;\n    }\n}\n</code></pre>\n<p>The <code>load()</code> method is the core of event sourcing: start with an empty aggregate, replay every event from version 1 to the latest, and you have the current state. This is conceptually simple but has a performance implication for long-lived aggregates — which is why snapshots exist.</p>\n<h2>Event Store Schema</h2>\n<p>The schema design for an event store is deceptively simple but has important details worth understanding.</p>\n<pre><code class=\"language-sql\">CREATE TABLE domain_events (\n    id          BIGSERIAL PRIMARY KEY,\n    aggregate_id VARCHAR(36) NOT NULL,\n    version     INTEGER NOT NULL,\n    event_type  VARCHAR(100) NOT NULL,\n    event_data  JSONB NOT NULL,\n    occurred_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n    metadata    JSONB DEFAULT '{}',\n\n    -- This UNIQUE constraint is doing important work: it prevents two concurrent\n    -- transactions from both writing version=5 for the same aggregate.\n    -- The second one will get a DB constraint violation, not a silent overwrite.\n    -- This is \"optimistic concurrency control\" without explicit locking.\n    UNIQUE (aggregate_id, version)\n);\n\nCREATE INDEX idx_domain_events_aggregate_id ON domain_events (aggregate_id, version);\nCREATE INDEX idx_domain_events_type_time ON domain_events (event_type, occurred_at);\n\n-- Snapshot table (for aggregates with thousands of events)\nCREATE TABLE aggregate_snapshots (\n    aggregate_id  VARCHAR(36) PRIMARY KEY,\n    version       INTEGER NOT NULL,\n    snapshot_data JSONB NOT NULL,\n    created_at    TIMESTAMPTZ NOT NULL DEFAULT NOW()\n);\n</code></pre>\n<p>The <code>UNIQUE (aggregate_id, version)</code> constraint is the most important line. Without it, two concurrent requests processing the same aggregate could both read version 7, both decide to write version 8, and you'd have a conflict or data corruption. With the constraint, only one succeeds — the other gets a <code>UniqueConstraintViolationException</code> and must retry. This is optimistic concurrency control using the database's own integrity checks.</p>\n<h2>Snapshots: Avoiding Replay at Scale</h2>\n<p>Replaying 10 events to reconstruct an aggregate is trivial. Replaying 10,000 events every time an order is loaded is not. This is the snapshot problem — and it's real for long-running aggregates like user accounts or multi-year subscription records.</p>\n<p>The solution is to periodically save a complete snapshot of the aggregate's state. On the next load, instead of replaying from event 1, you restore from the snapshot and only replay events that occurred after the snapshot was taken.</p>\n<pre><code class=\"language-java\">@Service\npublic class SnapshotService {\n\n    private static final int SNAPSHOT_THRESHOLD = 100;\n\n    public OrderAggregate loadWithSnapshot(String orderId) {\n        Optional&#x3C;Snapshot> snapshot = snapshotRepo.findLatest(orderId);\n\n        OrderAggregate aggregate;\n        int fromVersion;\n\n        if (snapshot.isPresent()) {\n            // Fast path: restore from snapshot (O(1)), then replay only recent events\n            aggregate = mapper.convertValue(snapshot.get().getData(), OrderAggregate.class);\n            fromVersion = snapshot.get().getVersion();\n        } else {\n            // Slow path: no snapshot yet, replay from the beginning\n            aggregate = new OrderAggregate();\n            fromVersion = 0;\n        }\n\n        // Only load events AFTER the snapshot version — much smaller set\n        List&#x3C;DomainEvent> events = eventStore.loadEventsAfter(orderId, fromVersion);\n        events.forEach(aggregate::apply);\n\n        // If we've accumulated enough new events since last snapshot, take a new one\n        // This keeps the \"replay gap\" bounded at SNAPSHOT_THRESHOLD events maximum\n        if (aggregate.getVersion() - fromVersion >= SNAPSHOT_THRESHOLD) {\n            snapshotRepo.save(new Snapshot(orderId, aggregate.getVersion(), aggregate));\n        }\n\n        return aggregate;\n    }\n}\n</code></pre>\n<p>With snapshots, the worst-case replay is always bounded at <code>SNAPSHOT_THRESHOLD</code> events — in this case, 100. An aggregate that has processed 50,000 events over its lifetime loads in the same time as one that has processed 150, because the snapshot absorbs the bulk of the history.</p>\n<h2>When to Use Event Sourcing</h2>\n<p>Before adopting this pattern, be honest about whether your problem actually requires it.</p>\n<pre><code>✓ Use Event Sourcing when:\n  - Audit trail is required (finance, healthcare, legal)\n  - Temporal queries needed (\"what was state on date X?\")\n  - Event replay for debugging or what-if analysis\n  - Multiple read models from same data (CQRS works naturally)\n  - Event-driven integrations (events drive downstream services)\n\n✗ Avoid Event Sourcing when:\n  - Simple CRUD with no audit requirements\n  - Small team — complexity cost exceeds benefit\n  - Read-heavy workload with simple data shapes (just use a good DB)\n  - You need strong consistency across multiple aggregates\n    (sagas required for cross-aggregate transactions)\n\nThe complexity tax:\n  Traditional CRUD: 200 lines of Spring code\n  Event Sourcing equivalent: 500+ lines\n  Worth it if you have compliance/audit requirements or complex business domains\n</code></pre>\n<p>The real power of event sourcing appears months after deployment. A bug introduced data corruption in March? Replay events from February, apply a fix, and rebuild the projection from clean history — without losing anything. A product manager asks \"what did our order data look like before the pricing change in December?\" Query the event store with a timestamp filter. A new team wants a different reporting view? Build a new projection by replaying historical events. That capability — the time machine — is what makes the upfront complexity worthwhile for systems where history matters.</p>\n","tableOfContents":[{"id":"the-problem-cqrs-and-event-sourcing-solve","text":"The Problem CQRS and Event Sourcing Solve","level":2},{"id":"cqrs-separate-read-and-write-models","text":"CQRS: Separate Read and Write Models","level":2},{"id":"implementation-order-system-with-axon-framework","text":"Implementation: Order System with Axon Framework","level":2},{"id":"commands-and-events","text":"Commands and Events","level":3},{"id":"the-aggregate-command-side","text":"The Aggregate: Command Side","level":3},{"id":"query-side-projections","text":"Query Side: Projections","level":3},{"id":"api-layer","text":"API Layer","level":3},{"id":"event-sourcing-without-a-framework","text":"Event Sourcing Without a Framework","level":2},{"id":"event-store-schema","text":"Event Store Schema","level":2},{"id":"snapshots-avoiding-replay-at-scale","text":"Snapshots: Avoiding Replay at Scale","level":2},{"id":"when-to-use-event-sourcing","text":"When to Use Event Sourcing","level":2}]},"relatedPosts":[{"title":"Building Production Observability with OpenTelemetry and Grafana Stack","description":"End-to-end observability implementation: distributed tracing with OpenTelemetry, metrics with Prometheus, structured logging with Loki, and the dashboards and alerts that actually help during incidents.","date":"2025-07-03","category":"System Design","tags":["observability","opentelemetry","prometheus","grafana","loki","tracing","spring boot","monitoring"],"featured":false,"affiliateSection":"system-design-courses","slug":"observability-opentelemetry-production","readingTime":"6 min read","excerpt":"Observability is not the same as monitoring. Monitoring tells you something is wrong. Observability lets you understand why — by exploring system state through metrics, traces, and logs without needing to know in advance…"},{"title":"Event Sourcing and CQRS in Production: Beyond the Theory","description":"What event sourcing actually looks like in production Java systems: event store design, snapshot strategies, projection rebuilding, CQRS read model synchronization, and the operational challenges nobody talks about.","date":"2025-06-23","category":"System Design","tags":["event sourcing","cqrs","system design","java","distributed systems","kafka","spring boot"],"featured":false,"affiliateSection":"distributed-systems-books","slug":"event-sourcing-cqrs-production","readingTime":"7 min read","excerpt":"Event sourcing is one of those patterns that looks elegant in conference talks and becomes surprisingly complex in production systems. The theory — store events instead of state, derive state by replaying events — is sou…"},{"title":"gRPC vs REST vs GraphQL: Choosing the Right API Protocol","description":"A technical comparison of REST, gRPC, and GraphQL across performance, developer experience, schema evolution, streaming, and real production use cases. When each protocol wins and where each falls short.","date":"2025-06-18","category":"System Design","tags":["grpc","rest","graphql","api design","system design","microservices","protocol buffers"],"featured":false,"affiliateSection":"system-design-courses","slug":"grpc-vs-rest-vs-graphql","readingTime":"7 min read","excerpt":"API protocol selection has a longer lifespan than almost any other technical decision. REST APIs from 2010 are still running in production. gRPC services chosen for internal communication in 2018 are tightly coupled to t…"}]},"__N_SSG":true}