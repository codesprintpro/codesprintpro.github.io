{"pageProps":{"post":{"title":"Java Concurrency Patterns: CompletableFuture, Structured Concurrency, and Thread-Safe Design","description":"Production Java concurrency: CompletableFuture pipelines, handling exceptions in async chains, Java 21 structured concurrency, thread-safe collection patterns, and the concurrency bugs that cause data corruption.","date":"2025-07-08","category":"Java","tags":["java","concurrency","completablefuture","virtual threads","java21","thread-safe","async"],"featured":false,"affiliateSection":"java-courses","slug":"java-concurrency-patterns","readingTime":"7 min read","excerpt":"Java concurrency has three eras: raw  and  (Java 1-4), the  framework (Java 5+), and the virtual thread/structured concurrency era (Java 21+). Each era's patterns still exist in production codebases. Understanding all th…","contentHtml":"<p>Java concurrency has three eras: raw <code>Thread</code> and <code>synchronized</code> (Java 1-4), the <code>java.util.concurrent</code> framework (Java 5+), and the virtual thread/structured concurrency era (Java 21+). Each era's patterns still exist in production codebases. Understanding all three — and knowing which to use when — separates engineers who write concurrent code from engineers who write correct concurrent code.</p>\n<h2>CompletableFuture: Composing Async Operations</h2>\n<p><code>CompletableFuture</code> is the fundamental async primitive since Java 8. It represents a future value and provides a fluent API for transforming and combining async results.</p>\n<pre><code class=\"language-java\">// Parallel data fetching with CompletableFuture:\npublic OrderSummary buildOrderSummary(String orderId) {\n    Executor executor = ForkJoinPool.commonPool(); // Or custom executor\n\n    CompletableFuture&#x3C;Order> orderFuture = CompletableFuture\n        .supplyAsync(() -> orderRepo.findById(orderId), executor);\n\n    CompletableFuture&#x3C;Customer> customerFuture = orderFuture\n        .thenApplyAsync(order -> customerRepo.findById(order.getCustomerId()), executor);\n\n    CompletableFuture&#x3C;List&#x3C;Product>> productsFuture = orderFuture\n        .thenApplyAsync(order ->\n            productRepo.findAllById(order.getProductIds()), executor);\n\n    CompletableFuture&#x3C;ShippingStatus> shippingFuture = orderFuture\n        .thenApplyAsync(order ->\n            shippingService.getStatus(order.getShipmentId()), executor);\n\n    // Combine results (customer + products + shipping in parallel after order loads):\n    return CompletableFuture.allOf(customerFuture, productsFuture, shippingFuture)\n        .thenApply(v -> OrderSummary.builder()\n            .order(orderFuture.join())\n            .customer(customerFuture.join())\n            .products(productsFuture.join())\n            .shipping(shippingFuture.join())\n            .build())\n        .join();\n}\n</code></pre>\n<p><code>orderFuture</code> runs first; <code>customerFuture</code>, <code>productsFuture</code>, and <code>shippingFuture</code> all start after <code>orderFuture</code> completes but run in parallel with each other. The total time is <code>order_fetch + max(customer, products, shipping)</code> instead of the sum.</p>\n<p><strong>Exception handling in async chains:</strong></p>\n<pre><code class=\"language-java\">CompletableFuture&#x3C;PricingResult> priceFuture = CompletableFuture\n    .supplyAsync(() -> pricingService.calculate(request))\n    .exceptionally(ex -> {\n        log.warn(\"Pricing service failed, using fallback: {}\", ex.getMessage());\n        return PricingResult.fallback(request.getBasePrice()); // Graceful degradation\n    })\n    .thenApply(pricing -> applyDiscounts(pricing))\n    .handle((result, ex) -> {\n        // handle() receives BOTH result and exception (either may be null)\n        if (ex != null) {\n            metrics.recordPricingError(ex);\n            return PricingResult.fallback(request.getBasePrice());\n        }\n        metrics.recordPricingSuccess();\n        return result;\n    });\n</code></pre>\n<p><strong>Critical pitfall: join() blocks — use carefully:</strong></p>\n<pre><code class=\"language-java\">// BAD: Calling join() inside an async chain on ForkJoinPool common pool\nCompletableFuture.supplyAsync(() -> {\n    // This is running on ForkJoinPool.commonPool()\n    String result = anotherFuture.join(); // BLOCKS a ForkJoinPool thread\n    // If all threads are blocked waiting for other futures: DEADLOCK\n    return process(result);\n});\n\n// GOOD: Use thenCompose for chaining async operations:\nCompletableFuture&#x3C;String> result = firstFuture\n    .thenComposeAsync(value -> createSecondFuture(value), customExecutor);\n</code></pre>\n<h2>Custom Executors: Don't Use the Default</h2>\n<p><code>ForkJoinPool.commonPool()</code> is shared across the entire JVM. In a Spring Boot application, Tomcat, Spring's <code>@Async</code>, CompletableFuture defaults, and parallel streams all compete for it. Use dedicated executors:</p>\n<pre><code class=\"language-java\">@Configuration\npublic class ExecutorConfig {\n\n    @Bean(\"ioExecutor\")\n    public ExecutorService ioExecutor() {\n        return new ThreadPoolExecutor(\n            10,           // corePoolSize\n            50,           // maximumPoolSize\n            60, TimeUnit.SECONDS,\n            new LinkedBlockingQueue&#x3C;>(200),  // bounded queue — important!\n            new ThreadFactoryBuilder()\n                .setNameFormat(\"io-worker-%d\")\n                .build(),\n            new ThreadPoolExecutor.CallerRunsPolicy()  // Backpressure: caller thread runs task\n        );\n    }\n\n    @Bean(\"cpuExecutor\")\n    public ExecutorService cpuExecutor() {\n        int cores = Runtime.getRuntime().availableProcessors();\n        return Executors.newFixedThreadPool(cores,\n            new ThreadFactoryBuilder().setNameFormat(\"cpu-worker-%d\").build());\n    }\n}\n\n// Usage:\nCompletableFuture\n    .supplyAsync(() -> fetchFromDatabase(id), ioExecutor)     // I/O bound\n    .thenApplyAsync(data -> processData(data), cpuExecutor)  // CPU bound\n    .thenApplyAsync(result -> saveResult(result), ioExecutor) // I/O bound\n</code></pre>\n<p><strong>Bounded queues are mandatory.</strong> An unbounded queue (<code>LinkedBlockingQueue()</code> with no capacity) allows tasks to queue indefinitely, consuming memory and masking backpressure problems. A bounded queue with <code>CallerRunsPolicy</code> provides natural backpressure: when the executor is full, the calling thread executes the task directly — slowing the producer.</p>\n<h2>Java 21 Structured Concurrency</h2>\n<p>Structured concurrency (JEP 453, finalized in Java 21) makes concurrent task lifetime match lexical scope — no task outlives its parent scope:</p>\n<pre><code class=\"language-java\">// Classic CompletableFuture: tasks can outlive scope, error handling is scattered\n// Structured concurrency: all tasks within try-block, exceptions propagate cleanly\n\npublic OrderSummary buildSummary(String orderId) throws InterruptedException {\n    try (var scope = new StructuredTaskScope.ShutdownOnFailure()) {\n        // Fork concurrent subtasks:\n        Subtask&#x3C;Order> orderTask = scope.fork(() -> orderRepo.findById(orderId));\n        Subtask&#x3C;Inventory> inventoryTask = scope.fork(() -> inventoryService.check(orderId));\n        Subtask&#x3C;PriceResult> priceTask = scope.fork(() -> pricingService.calculate(orderId));\n\n        // Wait for all tasks (or until one fails):\n        scope.join()           // Wait for all\n             .throwIfFailed(); // Throw if any failed (cancels remaining)\n\n        // All tasks succeeded — results are available:\n        return OrderSummary.of(\n            orderTask.get(),\n            inventoryTask.get(),\n            priceTask.get()\n        );\n    }\n    // When try-block exits: ALL forked tasks are guaranteed to have completed\n    // No task leaks, no partial results, clean cancellation\n}\n</code></pre>\n<p><strong>ShutdownOnSuccess:</strong> Return the first successful result, cancel the rest (racing pattern):</p>\n<pre><code class=\"language-java\">public String fetchFromFastestReplica(String key) throws InterruptedException {\n    try (var scope = new StructuredTaskScope.ShutdownOnSuccess&#x3C;String>()) {\n        scope.fork(() -> replicaA.get(key));\n        scope.fork(() -> replicaB.get(key));\n        scope.fork(() -> replicaC.get(key));\n\n        scope.join();\n        return scope.result();  // Returns result of first successful subtask\n    }\n    // The other 2 replicas are automatically cancelled\n}\n</code></pre>\n<h2>Thread-Safe Collection Patterns</h2>\n<p><strong>ConcurrentHashMap vs synchronized HashMap:</strong></p>\n<pre><code class=\"language-java\">// ConcurrentHashMap: lock striping — 16 independent segments, highly concurrent\nConcurrentHashMap&#x3C;String, User> cache = new ConcurrentHashMap&#x3C;>();\n\n// computeIfAbsent is atomic — safe for cache population:\nUser user = cache.computeIfAbsent(userId, id -> userRepo.findById(id));\n\n// NOT atomic: check-then-act on ConcurrentHashMap\nif (!cache.containsKey(key)) {          // Thread A checks: false\n    cache.put(key, computeExpensive());  // Thread B also passes check, both compute!\n}\n// Use computeIfAbsent instead.\n</code></pre>\n<p><strong>CopyOnWriteArrayList:</strong> For read-heavy, write-rare scenarios:</p>\n<pre><code class=\"language-java\">// Good for: event listeners, read-heavy configuration lists\n// Bad for: frequent writes (every write copies the entire array)\nCopyOnWriteArrayList&#x3C;EventListener> listeners = new CopyOnWriteArrayList&#x3C;>();\n// Reads: zero synchronization (reads see a consistent snapshot)\n// Writes: creates a new copy of the underlying array\n</code></pre>\n<p><strong>BlockingQueue for producer-consumer:</strong></p>\n<pre><code class=\"language-java\">BlockingQueue&#x3C;Task> queue = new LinkedBlockingQueue&#x3C;>(1000); // Bounded!\n\n// Producer thread:\nqueue.put(task); // Blocks if queue is full — natural backpressure\n\n// Consumer thread:\nTask task = queue.take(); // Blocks if queue is empty — no busy-waiting\n</code></pre>\n<h2>Common Concurrency Bugs</h2>\n<p><strong>Bug 1: Unsafe lazy initialization (double-checked locking without volatile)</strong></p>\n<pre><code class=\"language-java\">// BROKEN: compilers/CPUs can reorder writes\nprivate static DatabaseConnection instance;\n\npublic static DatabaseConnection getInstance() {\n    if (instance == null) {\n        synchronized (DatabaseConnection.class) {\n            if (instance == null) {\n                instance = new DatabaseConnection(); // 3 operations: alloc, init, assign\n                // CPU can reorder: assign before init → other threads see half-initialized object\n            }\n        }\n    }\n    return instance;\n}\n\n// FIXED: volatile ensures visibility ordering\nprivate static volatile DatabaseConnection instance;\n// Or better: use initialization-on-demand holder:\nprivate static class Holder {\n    static final DatabaseConnection INSTANCE = new DatabaseConnection();\n}\npublic static DatabaseConnection getInstance() { return Holder.INSTANCE; }\n</code></pre>\n<p><strong>Bug 2: Lost updates with compound operations</strong></p>\n<pre><code class=\"language-java\">// BROKEN: read-modify-write is not atomic\nprivate int counter = 0;\npublic void increment() { counter++; } // Actually: temp=counter; temp+1; counter=temp\n// Two threads: both read 5, both write 6. Count is 6 not 7.\n\n// FIXED:\nprivate AtomicInteger counter = new AtomicInteger(0);\npublic void increment() { counter.incrementAndGet(); } // CAS — atomic\n\n// Or for complex state:\nprivate final Object lock = new Object();\nprivate int counter = 0;\npublic synchronized void increment() { counter++; }\n</code></pre>\n<p><strong>Bug 3: Publishing objects before initialization completes</strong></p>\n<pre><code class=\"language-java\">// BROKEN: 'this' escapes constructor before fully initialized\npublic class EventProcessor {\n    private final List&#x3C;String> processors;\n\n    public EventProcessor(EventBus bus) {\n        bus.register(this); // 'this' is published here...\n        this.processors = new ArrayList&#x3C;>(); // ...but this runs AFTER\n        // Another thread calls handle() before processors is initialized → NPE\n    }\n\n    public void handle(Event e) {\n        processors.add(e.toString()); // NullPointerException\n    }\n}\n\n// FIXED: use factory method\npublic static EventProcessor create(EventBus bus) {\n    EventProcessor ep = new EventProcessor();\n    bus.register(ep); // Register after fully constructed\n    return ep;\n}\n</code></pre>\n<h2>AtomicReference for Lock-Free Updates</h2>\n<pre><code class=\"language-java\">// Thread-safe config hot-reload without locking:\nprivate final AtomicReference&#x3C;FeatureFlags> config =\n    new AtomicReference&#x3C;>(FeatureFlags.loadFromFile());\n\n// Background thread refreshes config:\n@Scheduled(fixedDelay = 60_000)\npublic void refreshConfig() {\n    FeatureFlags newFlags = FeatureFlags.loadFromFile();\n    config.set(newFlags); // Atomic swap — readers always see consistent snapshot\n}\n\n// Readers:\npublic boolean isEnabled(String feature) {\n    return config.get().isEnabled(feature); // No locking needed\n}\n\n// CAS for optimistic updates:\npublic boolean tryUpdateFlag(String feature, boolean expected, boolean newValue) {\n    FeatureFlags current = config.get();\n    FeatureFlags updated = current.withFlag(feature, newValue);\n    return config.compareAndSet(current, updated); // Succeeds only if unchanged\n}\n</code></pre>\n<p>The rule for Java concurrency in 2025: prefer virtual threads + structured concurrency for I/O-bound concurrent work; use <code>CompletableFuture</code> when you need fine-grained composition; reach for <code>AtomicReference</code>/<code>ConcurrentHashMap</code> for shared mutable state; avoid raw <code>synchronized</code> blocks except for simple critical sections. The concurrency primitives introduced in Java 21 make the \"correct by construction\" approach significantly easier than it was five years ago.</p>\n","tableOfContents":[{"id":"completablefuture-composing-async-operations","text":"CompletableFuture: Composing Async Operations","level":2},{"id":"custom-executors-dont-use-the-default","text":"Custom Executors: Don't Use the Default","level":2},{"id":"java-21-structured-concurrency","text":"Java 21 Structured Concurrency","level":2},{"id":"thread-safe-collection-patterns","text":"Thread-Safe Collection Patterns","level":2},{"id":"common-concurrency-bugs","text":"Common Concurrency Bugs","level":2},{"id":"atomicreference-for-lock-free-updates","text":"AtomicReference for Lock-Free Updates","level":2}]},"relatedPosts":[{"title":"Java Memory Management Deep Dive: Heap, GC, and Production Tuning","description":"How the JVM allocates memory, how G1GC and ZGC work under the hood, heap analysis with JVM tools, and the GC tuning decisions that eliminate latency spikes in production Java services.","date":"2025-06-13","category":"Java","tags":["java","jvm","garbage collection","g1gc","zgc","heap","memory management","performance"],"featured":false,"affiliateSection":"java-courses","slug":"java-memory-management-deep-dive","readingTime":"7 min read","excerpt":"Java's garbage collector is the single biggest source of unexplained latency spikes in production services. A GC pause of 2 seconds is invisible in most logs but visible to every user who happened to make a request durin…"},{"title":"Spring Security OAuth2 and JWT: Production Implementation Guide","description":"Complete Spring Security OAuth2 implementation: JWT token validation, Resource Server configuration, method-level security, custom UserDetailsService, refresh token rotation, and the security pitfalls that lead to authentication bypasses.","date":"2025-06-03","category":"Java","tags":["spring security","oauth2","jwt","spring boot","authentication","authorization","java","security"],"featured":false,"affiliateSection":"java-courses","slug":"spring-security-oauth2-jwt","readingTime":"7 min read","excerpt":"Spring Security is one of the most powerful and most misunderstood frameworks in the Java ecosystem. Its flexibility is its strength — and its complexity. Misconfigured security is worse than no security, because it give…"},{"title":"Scaling Spring Boot Applications to Handle 10 Million Daily Active Users","description":"A practical performance engineering guide: load balancing, horizontal scaling, database tuning, JVM optimization, autoscaling, and the observability stack to find and fix bottlenecks before they page you.","date":"2025-05-28","category":"Java","tags":["spring boot","java","scaling","performance","jvm","kubernetes","prometheus","grafana"],"featured":false,"affiliateSection":"java-courses","slug":"scaling-spring-boot-10m-dau","readingTime":"10 min read","excerpt":"10 million daily active users is not an exotic scale — it's where a successful mid-stage startup or a growing enterprise service lands. At this scale, the things that worked for 100,000 users start breaking in interestin…"}]},"__N_SSG":true}