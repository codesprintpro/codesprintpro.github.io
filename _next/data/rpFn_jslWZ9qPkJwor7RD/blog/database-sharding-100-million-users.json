{"pageProps":{"post":{"title":"Designing a Database Sharding Strategy for 100 Million Users","description":"A practical guide to horizontal sharding at scale: shard key selection, hot shard prevention, consistent hashing, cross-shard queries, and zero-downtime data migration with real fintech architecture examples.","date":"2025-04-14","category":"Databases","tags":["databases","sharding","postgresql","system design","distributed systems","scaling"],"featured":false,"affiliateSection":"database-resources","slug":"database-sharding-100-million-users","readingTime":"9 min read","excerpt":"Vertical scaling has a ceiling. For most applications, that ceiling arrives somewhere between 1 million and 10 million users, depending on write patterns and data size. At 100 million users, the question is not whether t…","contentHtml":"<p>Vertical scaling has a ceiling. For most applications, that ceiling arrives somewhere between 1 million and 10 million users, depending on write patterns and data size. At 100 million users, the question is not whether to shard — it's how to shard without destroying query capabilities, operational sanity, and transactional guarantees.</p>\n<p>This article is a complete playbook for database sharding at fintech scale.</p>\n<h2>Horizontal vs Vertical Sharding</h2>\n<p><strong>Vertical sharding</strong> (functional partitioning) splits tables across databases by domain: users database, orders database, payments database. Each service owns its database. This is what microservices architecture gives you naturally.</p>\n<pre><code>Vertical Sharding:\n┌─────────────────────┐  ┌─────────────────────┐  ┌─────────────────────┐\n│   Users DB          │  │   Orders DB          │  │   Payments DB       │\n│   users table       │  │   orders table       │  │   payments table    │\n│   profiles table    │  │   order_items table  │  │   ledger table      │\n└─────────────────────┘  └─────────────────────┘  └─────────────────────┘\n</code></pre>\n<p><strong>Horizontal sharding</strong> splits a single large table across multiple database instances by row. Each shard holds a subset of rows.</p>\n<pre><code>Horizontal Sharding:\nusers table → split by user_id range\n\nShard 0: user_id 0–24,999,999         (Shard DB 0)\nShard 1: user_id 25,000,000–49,999,999 (Shard DB 1)\nShard 2: user_id 50,000,000–74,999,999 (Shard DB 2)\nShard 3: user_id 75,000,000–99,999,999 (Shard DB 3)\n</code></pre>\n<p>Vertical sharding should always come first. It's operationally simpler, enables independent scaling per domain, and avoids distributed transactions within a service. Horizontal sharding is the next step when a single domain's write volume exceeds what one machine can handle.</p>\n<h2>Shard Key Selection Strategy</h2>\n<p>The shard key is the most consequential decision in your sharding design. Getting it wrong means data hotspots, expensive cross-shard joins, or re-sharding after launch.</p>\n<p><strong>Rule 1: High cardinality.</strong> The shard key must have enough distinct values to distribute data evenly. <code>user_id</code> (UUID or integer) works. <code>country_code</code> does not — if 40% of your users are in the US, one shard gets 40% of the load.</p>\n<p><strong>Rule 2: Even access distribution.</strong> The key should distribute both read and write load evenly. Timestamp-based keys (<code>created_at</code>) often create write hotspots — all new records hit the latest shard.</p>\n<p><strong>Rule 3: Co-locate related data.</strong> Queries that need to be fast should touch one shard. For a payment system, sharding payments by <code>user_id</code> means all of a user's payment history is on one shard, enabling efficient account statements without cross-shard queries.</p>\n<p><strong>Rule 4: Immutable.</strong> Changing the shard key value means moving the row to a different shard — an expensive operation. Use IDs that never change.</p>\n<p>For a fintech platform at 100M users:</p>\n<pre><code class=\"language-sql\">-- Schema design: payments table\nCREATE TABLE payments (\n    payment_id      UUID DEFAULT gen_random_uuid(),\n    user_id         BIGINT NOT NULL,          -- Shard key\n    merchant_id     BIGINT NOT NULL,\n    amount          DECIMAL(19,4) NOT NULL,\n    currency        CHAR(3) NOT NULL,\n    status          VARCHAR(20) NOT NULL,\n    idempotency_key VARCHAR(255) UNIQUE,\n    created_at      TIMESTAMPTZ DEFAULT NOW(),\n    updated_at      TIMESTAMPTZ DEFAULT NOW(),\n    PRIMARY KEY (user_id, payment_id)         -- Shard key first in PK\n);\n\n-- Shard key determines physical location\n-- All rows for user_id 12345678 are on Shard (12345678 % 64)\n</code></pre>\n<h2>Consistent Hashing</h2>\n<p>Naive hash-based sharding uses <code>shard_id = hash(user_id) % num_shards</code>. The problem: adding a shard changes the modulus, requiring almost all data to move.</p>\n<p>Consistent hashing solves this with a ring:</p>\n<pre><code>Consistent Hashing Ring (0 to 2^32):\n\n              0 / 2^32\n                  │\n       ┌──────────┴──────────┐\n  Shard 0               Shard 1\n  (0 - 2^30)        (2^30 - 2^31)\n                │\n           Shard 2\n        (2^31 - 3·2^30)\n                │\n           Shard 3\n      (3·2^30 - 2^32)\n</code></pre>\n<p>Each shard owns a range on the ring. A user's shard is determined by where <code>hash(user_id)</code> lands. When you add a fourth shard, only the users whose hash falls between the new shard's range boundaries need to move — roughly 1/N of data, not all of it.</p>\n<p>Virtual nodes (vnodes) improve distribution: each physical shard has multiple positions on the ring (typically 150–300 vnodes). This smooths uneven distributions caused by non-uniform hash outputs.</p>\n<h2>Hot Shard Problem</h2>\n<p>Even with good key selection, certain shards can become disproportionately busy:</p>\n<ul>\n<li>A viral merchant has 10M transactions, all landing on Shard 4</li>\n<li>A batch job processes all users in <code>user_id</code> range 0–1M sequentially</li>\n<li>A celebrity user account is read millions of times per day</li>\n</ul>\n<p><strong>Detection:</strong> Monitor per-shard QPS, CPU, and I/O independently. A shard running at 80% CPU while others run at 20% is a hot shard.</p>\n<p><strong>Mitigation strategies:</strong></p>\n<ol>\n<li>\n<p><strong>Key-based hot shard splitting:</strong> Split the hot shard into two, re-hashing the subset. Requires migration.</p>\n</li>\n<li>\n<p><strong>Read replicas for read-heavy hot shards:</strong> Add read replicas to the hot shard. Route reads there, writes to the primary.</p>\n</li>\n<li>\n<p><strong>Application-layer caching for celebrity objects:</strong> Cache the hot user/merchant data in Redis. This solves read hotspots without re-sharding.</p>\n</li>\n<li>\n<p><strong>Secondary shard key for compound hotness:</strong> If merchant_id causes hotspots, shard the <code>merchant_payments</code> aggregate table by <code>merchant_id</code> separately from the main <code>payments</code> table sharded by <code>user_id</code>.</p>\n</li>\n</ol>\n<h2>Cross-Shard Query Challenges</h2>\n<p>The most painful limitation of horizontal sharding: queries spanning multiple shards require scatter-gather.</p>\n<pre><code>SELECT amount, currency, merchant_id\nFROM payments\nWHERE created_at BETWEEN '2025-01-01' AND '2025-01-31'\n  AND status = 'completed'\nORDER BY created_at DESC\nLIMIT 100;\n</code></pre>\n<p>This query has no <code>user_id</code> predicate, so it must run on all 64 shards and results must be merged. Approaches:</p>\n<p><strong>1. Application-layer scatter-gather:</strong></p>\n<pre><code class=\"language-java\">List&#x3C;CompletableFuture&#x3C;List&#x3C;Payment>>> futures = shards.stream()\n    .map(shard -> CompletableFuture.supplyAsync(\n        () -> shard.query(sql, startDate, endDate), executor))\n    .collect(toList());\n\nList&#x3C;Payment> allResults = futures.stream()\n    .flatMap(f -> f.join().stream())\n    .sorted(Comparator.comparing(Payment::getCreatedAt).reversed())\n    .limit(100)\n    .collect(toList());\n</code></pre>\n<p>For N shards, you retrieve <code>N × 100</code> rows and discard <code>(N-1) × 100</code>. At 64 shards, you're fetching 6,400 rows to return 100.</p>\n<p><strong>2. Denormalized query tables in a separate unsharded database:</strong>\nFor analytics and reporting queries, maintain a denormalized table in a single reporting database (or data warehouse) that aggregates across shards. ETL runs periodically (or via CDC) to populate it.</p>\n<p><strong>3. Elasticsearch or ClickHouse as query layer:</strong>\nIndex payment data into Elasticsearch or ClickHouse for flexible querying without shard boundaries. The source of truth stays in sharded PostgreSQL; the query engine handles aggregation.</p>\n<h2>Transaction Management Across Shards</h2>\n<p>Distributed transactions across shards require either 2-Phase Commit (2PC) or Saga pattern. 2PC is slow and blocking; Saga is complex but resilient.</p>\n<p>For a payment that debits <code>user_id=A</code> (Shard 12) and credits <code>user_id=B</code> (Shard 47), the Saga pattern:</p>\n<pre><code>Saga: Cross-Shard Payment Transfer\n\nStep 1: Debit user A on Shard 12\n        → Write debit record, set status=PENDING\n        → Publish event: MoneyDebited(txn_id, user_A, amount)\n\nStep 2: Credit user B on Shard 47 (on event receipt)\n        → Write credit record\n        → Publish event: MoneyCredited(txn_id, user_B, amount)\n\nStep 3: Confirm debit on Shard 12 (on event receipt)\n        → Set debit status=COMPLETED\n\nCompensating transactions (on failure):\nStep 2 fails → Publish event: CreditFailed(txn_id)\nStep 1 compensation → Reverse debit on Shard 12, set status=REVERSED\n</code></pre>\n<p>The transaction coordinator is event-driven. Each step is locally atomic on its shard. The saga state machine tracks overall progress.</p>\n<h2>Rebalancing Shards</h2>\n<p>When you add shards, data must be re-distributed. The naive approach (stop world, migrate, restart) is unacceptable at scale. Use live migration:</p>\n<pre><code>Zero-Downtime Rebalancing (Double-Write Pattern):\n\nPhase 1: Add new shard. Start double-writing to old and new shard.\n         Read from old shard only.\n\nPhase 2: Backfill historical data from old shard to new shard.\n         Verify row counts and checksums.\n\nPhase 3: Switch reads to new shard. Continue double-writing.\n         Verify reads are correct on new shard.\n\nPhase 4: Stop writing to old shard. New shard is authoritative.\n\nPhase 5: After validation window, decommission old shard data.\n</code></pre>\n<pre><code>Architecture During Migration:\n\nApplication Server\n        │\n        ▼\n┌───────────────────┐\n│  Shard Router     │  (reads routing table from config store)\n└───┬───────────────┘\n    │\n    ├──► Old Shard (reads + writes during phase 1-3)\n    │\n    └──► New Shard (writes only in phase 1, reads+writes in phase 3+)\n</code></pre>\n<h2>Failure Recovery Strategy</h2>\n<p>Each shard should be a primary-replica pair:</p>\n<pre><code>Shard 12 Architecture:\n┌─────────────────────┐\n│  Shard 12 Primary   │  RDS PostgreSQL, Multi-AZ\n│  (us-east-1a)       │◄─── Writes\n└──────────┬──────────┘\n           │ Synchronous replication (&#x3C; 5ms lag)\n           ▼\n┌─────────────────────┐\n│  Shard 12 Replica   │\n│  (us-east-1b)       │◄─── Reads (optional)\n└─────────────────────┘\n</code></pre>\n<p>Shard failure handling: The shard router maintains a health map. When a shard's health check fails, the router returns a 503 for requests targeting that shard rather than routing to a degraded node. Partial service availability (63/64 shards healthy) is better than full outage.</p>\n<h2>Monitoring Shard Health</h2>\n<pre><code class=\"language-sql\">-- Per-shard monitoring query (run on each shard):\nSELECT\n    schemaname,\n    tablename,\n    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size,\n    n_live_tup AS row_count,\n    n_dead_tup AS dead_rows,\n    last_autovacuum,\n    last_autoanalyze\nFROM pg_stat_user_tables\nWHERE tablename = 'payments'\nORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;\n</code></pre>\n<p>Prometheus metrics to expose per shard:</p>\n<ul>\n<li><code>db_shard_connections_active</code> — active connections</li>\n<li><code>db_shard_query_latency_p99</code> — per-shard P99 query latency</li>\n<li><code>db_shard_row_count</code> — total rows (detects uneven distribution)</li>\n<li><code>db_shard_replication_lag_seconds</code> — replica lag</li>\n<li><code>db_shard_disk_usage_bytes</code> — storage growth rate</li>\n</ul>\n<p>Alert when any shard's P99 latency is 2× the median shard latency — early indicator of a hot shard.</p>\n<h2>Real Fintech-Scale Example</h2>\n<p>A payment processor handling 100M registered users, 5M daily active, 2M payments per day (23 payments/second average, 200 peak):</p>\n<p><strong>Schema design:</strong></p>\n<pre><code class=\"language-sql\">-- 64 shards, keyed by user_id % 64\n-- Each shard: ~1.5M users, ~31K payments/day\n\nCREATE TABLE payments (\n    payment_id      UUID DEFAULT gen_random_uuid(),\n    user_id         BIGINT NOT NULL,\n    merchant_id     BIGINT NOT NULL,\n    amount          DECIMAL(19,4) NOT NULL,\n    currency        CHAR(3) NOT NULL,\n    payment_method  JSONB NOT NULL,\n    status          VARCHAR(20) NOT NULL,\n    failure_code    VARCHAR(50),\n    idempotency_key VARCHAR(255) NOT NULL,\n    metadata        JSONB,\n    created_at      TIMESTAMPTZ DEFAULT NOW(),\n    PRIMARY KEY (user_id, payment_id),\n    UNIQUE (idempotency_key)\n);\n\nCREATE INDEX idx_payments_user_created ON payments (user_id, created_at DESC);\nCREATE INDEX idx_payments_merchant ON payments (merchant_id, created_at DESC);\nCREATE INDEX idx_payments_status ON payments (status) WHERE status IN ('pending', 'processing');\n</code></pre>\n<p><strong>Infrastructure:</strong> 64 RDS PostgreSQL Multi-AZ instances (<code>db.r6g.xlarge</code>), plus 64 read replicas for reporting queries. A separate ClickHouse cluster for analytics.</p>\n<p><strong>Shard router:</strong> A thin Spring Boot service with routing table in Redis. Routing table maps <code>shard_id → jdbc_url</code>. Changing routing table in Redis propagates to all router instances within 5 seconds.</p>\n<h2>Anti-Patterns</h2>\n<p><strong>Anti-pattern 1: Using a monotonically increasing integer as shard key.</strong> New users always go to the latest shard. Use UUID or hash-based IDs.</p>\n<p><strong>Anti-pattern 2: Sharding too early.</strong> Sharding adds enormous operational complexity. Shard at 10M users, not 10K.</p>\n<p><strong>Anti-pattern 3: Cross-shard foreign keys.</strong> They don't exist in a sharded system. Denormalize aggressively; join at the application layer.</p>\n<p><strong>Anti-pattern 4: Shard count that's not a power of 2.</strong> Start with 16 or 32 shards. Re-sharding from 16 to 32 means each shard splits cleanly in two. Re-sharding from 15 to 30 requires moving data across almost every shard boundary.</p>\n<p><strong>Anti-pattern 5: Global auto-increment IDs.</strong> Auto-increment across shards requires a centralized sequence, which becomes a bottleneck. Use UUIDs or distributed ID generation (Snowflake-style).</p>\n<p>Sharding is not a technology problem — it's a data modeling problem. The shard key shapes every query pattern, every operational procedure, and every failure mode for the life of the system. Get it right upfront.</p>\n","tableOfContents":[{"id":"horizontal-vs-vertical-sharding","text":"Horizontal vs Vertical Sharding","level":2},{"id":"shard-key-selection-strategy","text":"Shard Key Selection Strategy","level":2},{"id":"consistent-hashing","text":"Consistent Hashing","level":2},{"id":"hot-shard-problem","text":"Hot Shard Problem","level":2},{"id":"cross-shard-query-challenges","text":"Cross-Shard Query Challenges","level":2},{"id":"transaction-management-across-shards","text":"Transaction Management Across Shards","level":2},{"id":"rebalancing-shards","text":"Rebalancing Shards","level":2},{"id":"failure-recovery-strategy","text":"Failure Recovery Strategy","level":2},{"id":"monitoring-shard-health","text":"Monitoring Shard Health","level":2},{"id":"real-fintech-scale-example","text":"Real Fintech-Scale Example","level":2},{"id":"anti-patterns","text":"Anti-Patterns","level":2}]},"relatedPosts":[{"title":"Cassandra Data Modeling: Design for Queries, Not Entities","description":"Apache Cassandra data modeling from first principles: partition key design, clustering columns, denormalization strategies, avoiding hot partitions, materialized views vs. manual duplication, and the anti-patterns that kill Cassandra performance.","date":"2025-06-18","category":"Databases","tags":["cassandra","nosql","data modeling","distributed databases","partition key","cql","time series"],"featured":false,"affiliateSection":"database-resources","slug":"cassandra-data-modeling","readingTime":"9 min read","excerpt":"Cassandra is a write-optimized distributed database built for linear horizontal scalability. It stores data in a distributed hash ring — every node is equal, there's no primary, and data placement is determined by partit…"},{"title":"DynamoDB Advanced Patterns: Single-Table Design and Beyond","description":"Production DynamoDB: single-table design with access pattern mapping, GSI overloading, sparse indexes, adjacency lists for graph relationships, DynamoDB Streams for event-driven architectures, and the read/write capacity math that prevents bill shock.","date":"2025-06-13","category":"Databases","tags":["dynamodb","aws","nosql","single-table design","gsi","dynamodb streams","serverless"],"featured":false,"affiliateSection":"database-resources","slug":"dynamodb-advanced-patterns","readingTime":"9 min read","excerpt":"DynamoDB is a fully managed key-value and document database that delivers single-digit millisecond performance at any scale. It achieves this with a fundamental constraint: you must define your access patterns before you…"},{"title":"Zero-Downtime Database Migrations: Patterns for Production","description":"How to safely migrate production databases without downtime: expand-contract pattern, backward-compatible schema changes, rolling deployments with dual-write, column renaming strategies, and the PostgreSQL-specific techniques for large table alterations.","date":"2025-06-08","category":"Databases","tags":["database","migrations","postgresql","zero downtime","devops","schema evolution","flyway","liquibase"],"featured":false,"affiliateSection":"database-resources","slug":"zero-downtime-database-migrations","readingTime":"8 min read","excerpt":"Database migrations are the most dangerous part of a deployment. Application code changes are stateless and reversible — rollback a bad deploy and your code is back to the previous version. Database schema changes are st…"}]},"__N_SSG":true}