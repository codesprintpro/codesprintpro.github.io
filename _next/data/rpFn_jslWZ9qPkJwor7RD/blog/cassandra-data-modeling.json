{"pageProps":{"post":{"title":"Cassandra Data Modeling: Design for Queries, Not Entities","description":"Apache Cassandra data modeling from first principles: partition key design, clustering columns, denormalization strategies, avoiding hot partitions, materialized views vs. manual duplication, and the anti-patterns that kill Cassandra performance.","date":"2025-06-18","category":"Databases","tags":["cassandra","nosql","data modeling","distributed databases","partition key","cql","time series"],"featured":false,"affiliateSection":"database-resources","slug":"cassandra-data-modeling","readingTime":"9 min read","excerpt":"Cassandra is a write-optimized distributed database built for linear horizontal scalability. It stores data in a distributed hash ring — every node is equal, there's no primary, and data placement is determined by partit…","contentHtml":"<p>Cassandra is a write-optimized distributed database built for linear horizontal scalability. It stores data in a distributed hash ring — every node is equal, there's no primary, and data placement is determined by partition key hashing. Understanding this architecture is not optional; it directly determines your data model choices.</p>\n<p>The cardinal rule of Cassandra modeling: <strong>design your tables around your queries, not your entities</strong>. In relational databases, you normalize data and let the query planner figure out joins. In Cassandra, there is no query planner that helps you. Joins don't exist. <code>ALLOW FILTERING</code> exists but bypasses the index and performs full-table scans. Your schema must anticipate every query pattern in advance.</p>\n<h2>The Storage Model</h2>\n<p>Before modeling, understand how Cassandra stores data:</p>\n<pre><code>Cassandra Storage Architecture:\n\nPartition Key (PK):\n  → Determines which node stores the data (via consistent hashing)\n  → ALL data with the same partition key lives on the same node\n  → One partition key = one \"row\" in Cassandra's storage engine\n\nClustering Columns (CC):\n  → Sort key WITHIN a partition\n  → Data is physically stored sorted by CC on disk\n  → Range queries (WHERE cc > x AND cc &#x3C; y) are efficient\n\nRegular Columns:\n  → Just values, no ordering significance\n\nPhysical storage (simplified):\nPartition: user_id=1001\n  [name=\"Alice\", email=\"alice@example.com\"] ← static columns (once per partition)\n  [ts=2025-01-01, event=\"login\"]            ← clustering row 1\n  [ts=2025-01-02, event=\"purchase\"]          ← clustering row 2\n  [ts=2025-01-03, event=\"logout\"]            ← clustering row 3\n  (sorted by ts ascending)\n</code></pre>\n<p>A CQL <code>SELECT</code> that specifies the full partition key reads from one node — O(1) lookup. A query that doesn't specify the partition key fans out to every node — O(n) cluster-wide scan.</p>\n<h2>Pattern 1: Query-First Modeling</h2>\n<p><strong>Use case: Build a social media activity feed — \"show user's recent activity, paginated\"</strong></p>\n<p>Relational model (what you'd do in PostgreSQL):</p>\n<pre><code class=\"language-sql\">-- Normalized: store users and events separately\nCREATE TABLE users (id UUID PRIMARY KEY, name TEXT);\nCREATE TABLE events (id UUID, user_id UUID, type TEXT, created_at TIMESTAMP);\n-- Join at query time, ORDER BY created_at\n</code></pre>\n<p>Cassandra model (design for the query):</p>\n<pre><code class=\"language-sql\">-- Table is named for the query it answers\nCREATE TABLE user_activity_by_user (\n    user_id     UUID,\n    occurred_at TIMESTAMP,\n    event_type  TEXT,\n    payload     TEXT,\n    PRIMARY KEY (user_id, occurred_at)  -- PK: user_id | CC: occurred_at\n) WITH CLUSTERING ORDER BY (occurred_at DESC);  -- Most recent first\n\n-- Query (efficient — hits one partition, reads sequentially):\nSELECT * FROM user_activity_by_user\nWHERE user_id = ?\nORDER BY occurred_at DESC\nLIMIT 20;\n\n-- Pagination: use occurred_at of last seen row as cursor\nSELECT * FROM user_activity_by_user\nWHERE user_id = ? AND occurred_at &#x3C; ?  -- \"before this timestamp\"\nORDER BY occurred_at DESC\nLIMIT 20;\n</code></pre>\n<p>Why this works: <code>user_id</code> is the partition key — all of a user's events live on the same node, sorted by <code>occurred_at</code> DESC on disk. The query reads a contiguous range of sorted data — no scatter, no sort.</p>\n<p><strong>Anti-pattern:</strong> <code>SELECT * FROM user_activity WHERE type = 'purchase'</code> — no partition key specified. Cassandra must scan every partition on every node. Never do this in production.</p>\n<h2>Pattern 2: Compound Partition Keys for Distributed Writes</h2>\n<p><strong>Problem: Storing IoT sensor readings</strong></p>\n<p>Naive model:</p>\n<pre><code class=\"language-sql\">CREATE TABLE sensor_readings (\n    sensor_id   UUID,\n    recorded_at TIMESTAMP,\n    value       DOUBLE,\n    PRIMARY KEY (sensor_id, recorded_at)\n);\n</code></pre>\n<p>This works for queries (<code>WHERE sensor_id = ?</code>). But what if you have one sensor generating 10,000 writes/second? All writes for that sensor go to a single partition on a single node. That's a <strong>hot partition</strong> — you've created a bottleneck in a supposedly distributed system.</p>\n<p>Fix with compound partition key (time bucketing):</p>\n<pre><code class=\"language-sql\">CREATE TABLE sensor_readings_v2 (\n    sensor_id   UUID,\n    bucket      TEXT,        -- 'YYYY-MM-DD' — one bucket per day\n    recorded_at TIMESTAMP,\n    value       DOUBLE,\n    PRIMARY KEY ((sensor_id, bucket), recorded_at)  -- compound PK\n) WITH CLUSTERING ORDER BY (recorded_at ASC);\n\n-- Write:\nINSERT INTO sensor_readings_v2 (sensor_id, bucket, recorded_at, value)\nVALUES (?, '2025-01-15', ?, ?);\n\n-- Query (must know the bucket):\nSELECT * FROM sensor_readings_v2\nWHERE sensor_id = ? AND bucket = '2025-01-15'\nAND recorded_at >= '2025-01-15 00:00:00'\nAND recorded_at &#x3C; '2025-01-16 00:00:00';\n\n-- Multi-day query (application-level loop):\n// Fetch each bucket separately and merge client-side\nfor (String bucket : getDateRange(startDate, endDate)) {\n    results.addAll(query(sensorId, bucket));\n}\n</code></pre>\n<p>The compound partition key <code>(sensor_id, bucket)</code> spreads writes for the same sensor across different partitions (different days hash to different nodes). The tradeoff: your application must know the bucket to query, and cross-bucket queries require multiple round trips.</p>\n<p><strong>Partition size guidance:</strong> Keep partitions under 100MB (soft) or 1GB (hard Cassandra limit). For time-series data, choose a bucket size where <code>writes_per_second × row_size × seconds_in_bucket &#x3C; 100MB</code>. Daily buckets work for most IoT data.</p>\n<h2>Pattern 3: Denormalization — Duplicate for Query Patterns</h2>\n<p>If you need to query the same data in two different ways, you need two tables:</p>\n<p><strong>Use case: E-commerce orders — query by customer AND by product</strong></p>\n<pre><code class=\"language-sql\">-- Table 1: orders by customer (primary access pattern)\nCREATE TABLE orders_by_customer (\n    customer_id UUID,\n    order_id    UUID,\n    order_date  TIMESTAMP,\n    total_cents BIGINT,\n    status      TEXT,\n    PRIMARY KEY (customer_id, order_date, order_id)\n) WITH CLUSTERING ORDER BY (order_date DESC, order_id ASC);\n\n-- Table 2: orders by product (secondary access pattern)\nCREATE TABLE orders_by_product (\n    product_id  UUID,\n    order_date  TIMESTAMP,\n    order_id    UUID,\n    customer_id UUID,\n    quantity    INT,\n    PRIMARY KEY (product_id, order_date, order_id)\n) WITH CLUSTERING ORDER BY (order_date DESC, order_id ASC);\n\n-- Application writes to BOTH tables (usually via batch):\nBEGIN BATCH\n  INSERT INTO orders_by_customer (customer_id, order_id, order_date, total_cents, status)\n    VALUES (?, ?, ?, ?, ?);\n  INSERT INTO orders_by_product (product_id, order_date, order_id, customer_id, quantity)\n    VALUES (?, ?, ?, ?, ?);\nAPPLY BATCH;\n</code></pre>\n<p>Cassandra logged batches guarantee atomicity (either both writes succeed or neither does). Use them for maintaining consistency across denormalized tables representing the same logical event.</p>\n<p><strong>Storage cost:</strong> You're duplicating data. For most workloads, disk is cheap; latency and availability are expensive. Cassandra clusters typically run with a replication factor of 3, so data is already 3× replicated. Duplicating for a query pattern is not a major cost concern.</p>\n<h2>Pattern 4: Materialized Views vs. Manual Duplication</h2>\n<p>Cassandra offers Materialized Views (MV) — automatically maintained denormalized tables:</p>\n<pre><code class=\"language-sql\">-- Base table:\nCREATE TABLE users (\n    user_id   UUID PRIMARY KEY,\n    email     TEXT,\n    username  TEXT,\n    country   TEXT\n);\n\n-- Materialized View: query users by email\nCREATE MATERIALIZED VIEW users_by_email AS\n    SELECT * FROM users\n    WHERE email IS NOT NULL AND user_id IS NOT NULL\n    PRIMARY KEY (email, user_id);\n\n-- Query:\nSELECT * FROM users_by_email WHERE email = 'alice@example.com';\n</code></pre>\n<p>Cassandra maintains <code>users_by_email</code> automatically on every write to <code>users</code>. No application-level dual-write needed.</p>\n<p><strong>Why production teams avoid MVs:</strong></p>\n<ul>\n<li>MV writes are asynchronous — a base table write returns before the MV is updated. Brief inconsistency windows exist.</li>\n<li>MV maintenance adds write amplification and coordination overhead — increasing latency on the base table.</li>\n<li>MV bugs existed in earlier Cassandra versions; some teams distrust them.</li>\n</ul>\n<p><strong>Production recommendation:</strong> Use manual dual-write (via application code or Kafka + CDC) for critical query patterns. Use MVs only for non-critical secondary indexes where brief staleness is acceptable.</p>\n<h2>Pattern 5: Secondary Indexes — When and When Not To</h2>\n<p>Cassandra's secondary index (<code>CREATE INDEX ON table(column)</code>) enables queries on non-partition-key columns:</p>\n<pre><code class=\"language-sql\">CREATE INDEX ON users (country);\n\n-- Now this works:\nSELECT * FROM users WHERE country = 'US';\n</code></pre>\n<p><strong>The hidden danger:</strong> This query fans out to every node. Each node checks its local index, returns matching rows. For high-cardinality columns (many distinct values) this is inefficient but tolerable. For low-cardinality columns on large datasets (e.g., <code>status IN ('active', 'inactive')</code> on 100M users), every node returns millions of rows — catastrophic.</p>\n<p><strong>Safe secondary index use cases:</strong></p>\n<ul>\n<li>Low-cardinality columns on small datasets (&#x3C; 1M rows per query result)</li>\n<li>Rarely-executed admin queries where full-node-fan-out is acceptable</li>\n<li>Columns where you always also filter on the partition key (making it a single-node lookup)</li>\n</ul>\n<p><strong>For anything else:</strong> Denormalize into a separate table.</p>\n<h2>Cassandra Anti-Patterns to Avoid</h2>\n<p><strong>1. Large partitions (the tombstone problem)</strong></p>\n<p>Deletes in Cassandra write tombstones — markers that say \"this data was deleted.\" Tombstones are compacted away during compaction, but until then, they accumulate. Reading a partition requires scanning all tombstones for it.</p>\n<pre><code class=\"language-sql\">-- DANGEROUS: Storing all events for a user in one partition\nCREATE TABLE user_events (\n    user_id UUID,\n    event_id UUID,\n    data TEXT,\n    PRIMARY KEY (user_id, event_id)\n);\n-- Deleting old events creates tombstones\n-- If users have millions of events + deletions: partition becomes unreadable\n-- (coordinator times out scanning tombstones, gc_grace_seconds doesn't help)\n</code></pre>\n<p>Fix: Use time-bucketed partitions. Delete whole partitions (less tombstones) instead of individual rows.</p>\n<p><strong>2. Using Cassandra like a relational database</strong></p>\n<pre><code class=\"language-sql\">-- BROKEN: This causes a full cluster scan\nSELECT * FROM orders WHERE status = 'pending';\n\n-- BROKEN: UPDATE requires partition key\nUPDATE orders SET status = 'shipped' WHERE status = 'pending'; -- Not how CQL works\n\n-- BROKEN: Aggregations without partition key\nSELECT COUNT(*) FROM orders WHERE created_at > '2025-01-01'; -- Full scan\n</code></pre>\n<p><strong>3. Unbounded partition growth</strong></p>\n<pre><code class=\"language-sql\">-- DANGEROUS: \"All events for order 1234\" in one partition\n-- If an order accumulates 10,000+ events, partition exceeds 100MB limit\nPRIMARY KEY (order_id, event_timestamp)\n\n-- FIX: Bucket by time period\nPRIMARY KEY ((order_id, week_bucket), event_timestamp)\n</code></pre>\n<h2>Lightweight Transactions (LWT) and Why to Avoid Them</h2>\n<pre><code class=\"language-sql\">-- LWT: Compare-and-set operations using Paxos\nINSERT INTO user_sessions (session_id, user_id, created_at)\nVALUES (?, ?, ?)\nIF NOT EXISTS;  -- Only insert if no row exists with this session_id\n\nUPDATE inventory SET quantity = quantity - 1\nWHERE product_id = ?\nIF quantity > 0;  -- Only update if condition is true\n</code></pre>\n<p>LWTs guarantee linearizability — exactly one write wins among concurrent writers. This sounds great. The cost:</p>\n<ul>\n<li>LWT requires 4 round trips (Paxos phases: Prepare, Promise, Propose, Accept)</li>\n<li>LWT is 4-10× slower than regular writes</li>\n<li>LWT reduces throughput by up to 40% under contention</li>\n</ul>\n<p><strong>Use LWT only for:</strong> Uniqueness constraints (usernames, emails) and inventory reservation. For everything else, design around eventual consistency or use optimistic concurrency at the application layer.</p>\n<h2>Choosing Cassandra</h2>\n<p>Cassandra is the right tool when:</p>\n<ul>\n<li>Write throughput is the primary concern (millions of writes/second, linearly scalable)</li>\n<li>Time-series or event data with known access patterns</li>\n<li>No joins required, query patterns are defined upfront</li>\n<li>Multi-region active-active replication is required (no single master)</li>\n<li>Availability > consistency (AP system in CAP theorem)</li>\n</ul>\n<p>Cassandra is the wrong tool when:</p>\n<ul>\n<li>You need ad-hoc queries or reporting (use PostgreSQL/Elasticsearch)</li>\n<li>Complex transactions spanning multiple entities</li>\n<li>Unknown query patterns that will evolve (schema changes are expensive)</li>\n<li>Small dataset where Cassandra's operational overhead isn't justified</li>\n</ul>\n<p>The investment in Cassandra pays off at scale — the same cluster that handles 10,000 writes/second handles 100,000 writes/second with added nodes, no schema changes, no query rewrites. That linear scalability is why teams adopt it, and why getting the data model right from the start is non-negotiable.</p>\n","tableOfContents":[{"id":"the-storage-model","text":"The Storage Model","level":2},{"id":"pattern-1-query-first-modeling","text":"Pattern 1: Query-First Modeling","level":2},{"id":"pattern-2-compound-partition-keys-for-distributed-writes","text":"Pattern 2: Compound Partition Keys for Distributed Writes","level":2},{"id":"pattern-3-denormalization-duplicate-for-query-patterns","text":"Pattern 3: Denormalization — Duplicate for Query Patterns","level":2},{"id":"pattern-4-materialized-views-vs-manual-duplication","text":"Pattern 4: Materialized Views vs. Manual Duplication","level":2},{"id":"pattern-5-secondary-indexes-when-and-when-not-to","text":"Pattern 5: Secondary Indexes — When and When Not To","level":2},{"id":"cassandra-anti-patterns-to-avoid","text":"Cassandra Anti-Patterns to Avoid","level":2},{"id":"lightweight-transactions-lwt-and-why-to-avoid-them","text":"Lightweight Transactions (LWT) and Why to Avoid Them","level":2},{"id":"choosing-cassandra","text":"Choosing Cassandra","level":2}]},"relatedPosts":[{"title":"DynamoDB Advanced Patterns: Single-Table Design and Beyond","description":"Production DynamoDB: single-table design with access pattern mapping, GSI overloading, sparse indexes, adjacency lists for graph relationships, DynamoDB Streams for event-driven architectures, and the read/write capacity math that prevents bill shock.","date":"2025-06-13","category":"Databases","tags":["dynamodb","aws","nosql","single-table design","gsi","dynamodb streams","serverless"],"featured":false,"affiliateSection":"database-resources","slug":"dynamodb-advanced-patterns","readingTime":"9 min read","excerpt":"DynamoDB is a fully managed key-value and document database that delivers single-digit millisecond performance at any scale. It achieves this with a fundamental constraint: you must define your access patterns before you…"},{"title":"Zero-Downtime Database Migrations: Patterns for Production","description":"How to safely migrate production databases without downtime: expand-contract pattern, backward-compatible schema changes, rolling deployments with dual-write, column renaming strategies, and the PostgreSQL-specific techniques for large table alterations.","date":"2025-06-08","category":"Databases","tags":["database","migrations","postgresql","zero downtime","devops","schema evolution","flyway","liquibase"],"featured":false,"affiliateSection":"database-resources","slug":"zero-downtime-database-migrations","readingTime":"8 min read","excerpt":"Database migrations are the most dangerous part of a deployment. Application code changes are stateless and reversible — rollback a bad deploy and your code is back to the previous version. Database schema changes are st…"},{"title":"PostgreSQL Performance Tuning: From Slow Queries to Sub-Millisecond Reads","description":"A production guide to PostgreSQL query optimization: EXPLAIN ANALYZE, index design, VACUUM tuning, connection pooling with PgBouncer, partitioning, and the configuration changes that actually move the needle.","date":"2025-06-03","category":"Databases","tags":["postgresql","databases","performance","sql","indexing","query optimization"],"featured":false,"affiliateSection":"database-resources","slug":"postgresql-performance-tuning","readingTime":"9 min read","excerpt":"PostgreSQL ships with defaults tuned for a 512MB machine from 2005. Every production deployment needs to be re-tuned. Beyond that, most slow queries are not a PostgreSQL problem — they're a query design problem that Post…"}]},"__N_SSG":true}