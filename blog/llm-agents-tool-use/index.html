<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8" data-next-head=""/><meta name="viewport" content="width=device-width" data-next-head=""/><title data-next-head="">Building AI Agents with Tool Use: From Chatbot to Autonomous Agent<!-- --> | CodeSprintPro</title><meta name="description" content="Build production AI agents using Claude&#x27;s tool use API. Learn the agentic loop, error handling, multi-step reasoning, human-in-the-loop patterns, and how to build reliable autonomous systems." data-next-head=""/><meta name="author" content="Sachin Sarawgi" data-next-head=""/><link rel="canonical" href="https://codesprintpro.com/blog/llm-agents-tool-use/" data-next-head=""/><meta property="og:type" content="article" data-next-head=""/><meta property="og:title" content="Building AI Agents with Tool Use: From Chatbot to Autonomous Agent" data-next-head=""/><meta property="og:description" content="Build production AI agents using Claude&#x27;s tool use API. Learn the agentic loop, error handling, multi-step reasoning, human-in-the-loop patterns, and how to build reliable autonomous systems." data-next-head=""/><meta property="og:url" content="https://codesprintpro.com/blog/llm-agents-tool-use/" data-next-head=""/><meta property="og:image" content="https://codesprintpro.com/images/og-default.jpg" data-next-head=""/><meta property="og:site_name" content="CodeSprintPro" data-next-head=""/><meta property="article:published_time" content="2025-03-23" data-next-head=""/><meta property="article:author" content="Sachin Sarawgi" data-next-head=""/><meta property="article:section" content="AI/ML" data-next-head=""/><meta property="article:tag" content="ai" data-next-head=""/><meta property="article:tag" content="agents" data-next-head=""/><meta property="article:tag" content="claude" data-next-head=""/><meta property="article:tag" content="tool use" data-next-head=""/><meta property="article:tag" content="llm" data-next-head=""/><meta property="article:tag" content="autonomous systems" data-next-head=""/><meta property="article:tag" content="python" data-next-head=""/><meta name="twitter:card" content="summary_large_image" data-next-head=""/><meta name="twitter:title" content="Building AI Agents with Tool Use: From Chatbot to Autonomous Agent" data-next-head=""/><meta name="twitter:description" content="Build production AI agents using Claude&#x27;s tool use API. Learn the agentic loop, error handling, multi-step reasoning, human-in-the-loop patterns, and how to build reliable autonomous systems." data-next-head=""/><meta name="twitter:image" content="https://codesprintpro.com/images/og-default.jpg" data-next-head=""/><script type="application/ld+json" data-next-head="">{"@context":"https://schema.org","@type":"BlogPosting","headline":"Building AI Agents with Tool Use: From Chatbot to Autonomous Agent","description":"Build production AI agents using Claude's tool use API. Learn the agentic loop, error handling, multi-step reasoning, human-in-the-loop patterns, and how to build reliable autonomous systems.","image":"https://codesprintpro.com/images/og-default.jpg","datePublished":"2025-03-23","dateModified":"2025-03-23","author":{"@type":"Person","name":"Sachin Sarawgi","url":"https://codesprintpro.com","sameAs":["https://www.linkedin.com/in/sachin-sarawgi/","https://github.com/codesprintpro","https://medium.com/@codesprintpro"]},"publisher":{"@type":"Organization","name":"CodeSprintPro","url":"https://codesprintpro.com","logo":{"@type":"ImageObject","url":"https://codesprintpro.com/favicon/favicon-96x96.png"}},"mainEntityOfPage":{"@type":"WebPage","@id":"https://codesprintpro.com/blog/llm-agents-tool-use/"},"keywords":"ai, agents, claude, tool use, llm, autonomous systems, python","articleSection":"AI/ML"}</script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" integrity="sha512-9usAa10IRO0HhonpyAIVpjrylPvoDwiPUiKdWk5t3PyolY1cOd4DSE0Ga+ri4AuTroPR5aQvXU9xC6qOPnzFeg==" crossorigin="anonymous" referrerPolicy="no-referrer"/><script async="" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-XXXXXXXXXXXXXXXX" crossorigin="anonymous"></script><link rel="preload" href="/_next/static/media/e4af272ccee01ff0-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/css/735d4373f93910ca.css" as="style"/><link rel="stylesheet" href="/_next/static/css/735d4373f93910ca.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-11a4a2dad04962bb.js" defer=""></script><script src="/_next/static/chunks/framework-1ce91eb6f9ecda85.js" defer=""></script><script src="/_next/static/chunks/main-c7f4109f032d7b6e.js" defer=""></script><script src="/_next/static/chunks/pages/_app-1a852bd9e38c70ab.js" defer=""></script><script src="/_next/static/chunks/730-db7827467817f501.js" defer=""></script><script src="/_next/static/chunks/90-1cd4611704c3dbe0.js" defer=""></script><script src="/_next/static/chunks/440-29f4b99a44e744b5.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-0c1b14a33d5e05ee.js" defer=""></script><script src="/_next/static/rpFn_jslWZ9qPkJwor7RD/_buildManifest.js" defer=""></script><script src="/_next/static/rpFn_jslWZ9qPkJwor7RD/_ssgManifest.js" defer=""></script></head><body><div id="__next"><main class="__className_f367f3"><div class="min-h-screen bg-white"><nav class="fixed w-full z-50 transition-all duration-300 bg-white shadow-md" style="transform:translateY(-100px) translateZ(0)"><div class="container mx-auto px-4 sm:px-6 lg:px-8"><div class="flex items-center justify-between h-16"><a class="text-xl font-bold transition-colors text-blue-600" href="/">CodeSprintPro</a><div class="hidden md:flex items-center space-x-8"><a class="text-sm font-medium transition-colors text-blue-600" href="/blog/">Blog</a><a class="text-sm font-medium transition-colors text-gray-600 hover:text-blue-600" href="/#about">About</a><a class="text-sm font-medium transition-colors text-gray-600 hover:text-blue-600" href="/#portfolio">Portfolio</a><a class="text-sm font-medium transition-colors text-gray-600 hover:text-blue-600" href="/#contact">Contact</a></div><button class="md:hidden p-2 rounded-lg transition-colors hover:bg-gray-100 text-gray-600" aria-label="Toggle mobile menu"><svg class="w-6 h-6" fill="none" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" stroke="currentColor"><path d="M4 6h16M4 12h16M4 18h16"></path></svg></button></div></div></nav><div class="pt-20"><div class="bg-gradient-to-br from-gray-900 to-blue-950 py-16"><div class="container mx-auto px-4 sm:px-6 lg:px-8 max-w-5xl"><nav class="flex items-center gap-2 text-sm text-gray-400 mb-6"><a class="hover:text-white transition-colors" href="/">Home</a><span>/</span><a class="hover:text-white transition-colors" href="/blog/">Blog</a><span>/</span><span class="text-gray-300 truncate max-w-xs">Building AI Agents with Tool Use: From Chatbot to Autonomous Agent</span></nav><span class="inline-block text-xs font-semibold px-3 py-1 rounded-full bg-blue-100 text-blue-700 mb-4">AI/ML</span><h1 class="text-3xl md:text-5xl font-bold text-white mb-4 leading-tight">Building AI Agents with Tool Use: From Chatbot to Autonomous Agent</h1><p class="text-gray-300 text-lg mb-6 max-w-3xl">Build production AI agents using Claude&#x27;s tool use API. Learn the agentic loop, error handling, multi-step reasoning, human-in-the-loop patterns, and how to build reliable autonomous systems.</p><div class="flex flex-wrap items-center gap-4 text-gray-400 text-sm"><span class="flex items-center gap-1.5"><svg class="w-4 h-4" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M16 7a4 4 0 11-8 0 4 4 0 018 0zM12 14a7 7 0 00-7 7h14a7 7 0 00-7-7z"></path></svg>Sachin Sarawgi</span><span>¬∑</span><span>March 23, 2025</span><span>¬∑</span><span class="flex items-center gap-1"><svg class="w-4 h-4" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>10 min read</span></div><div class="flex flex-wrap gap-2 mt-4"><span class="text-xs text-gray-400 bg-gray-800 px-2 py-1 rounded">#<!-- -->ai</span><span class="text-xs text-gray-400 bg-gray-800 px-2 py-1 rounded">#<!-- -->agents</span><span class="text-xs text-gray-400 bg-gray-800 px-2 py-1 rounded">#<!-- -->claude</span><span class="text-xs text-gray-400 bg-gray-800 px-2 py-1 rounded">#<!-- -->tool use</span><span class="text-xs text-gray-400 bg-gray-800 px-2 py-1 rounded">#<!-- -->llm</span><span class="text-xs text-gray-400 bg-gray-800 px-2 py-1 rounded">#<!-- -->autonomous systems</span><span class="text-xs text-gray-400 bg-gray-800 px-2 py-1 rounded">#<!-- -->python</span></div></div></div><div class="container mx-auto px-4 sm:px-6 lg:px-8 max-w-5xl py-12"><div class="flex gap-12"><div class="flex-1 min-w-0"><article class="prose prose-lg max-w-none prose-headings:text-gray-900 prose-headings:font-bold prose-h2:text-2xl prose-h2:mt-10 prose-h2:mb-4 prose-h3:text-xl prose-h3:mt-8 prose-h3:mb-3 prose-p:text-gray-700 prose-p:leading-relaxed prose-a:text-blue-600 prose-a:no-underline hover:prose-a:underline prose-strong:text-gray-900 prose-blockquote:border-blue-600 prose-blockquote:text-gray-600 prose-code:text-blue-700 prose-code:bg-blue-50 prose-code:px-1.5 prose-code:py-0.5 prose-code:rounded prose-code:text-sm prose-code:before:content-none prose-code:after:content-none prose-pre:rounded-xl prose-img:rounded-xl prose-img:shadow-md prose-table:text-sm prose-th:bg-gray-100 prose-th:text-gray-700"><p>A chatbot answers questions. An agent takes actions. The difference is tool use: the ability to call functions, search databases, execute code, and interact with external systems. When a model can look up real information, run calculations, and modify state, it transforms from a text generator into a capable assistant. This article builds production-grade agents that actually work.</p>
<h2>The Agentic Loop</h2>
<p>Before writing any code, it helps to see the agentic loop in action at the conceptual level. The model does not have all the information it needs to answer a question ‚Äî instead, it decides what information to fetch, fetches it, and then decides whether it knows enough or needs to take another step. This trace shows that exact reasoning process for a two-step stock comparison question.</p>
<pre><code>User request ‚Üí LLM ‚Üí Tool call ‚Üí Execute ‚Üí Result ‚Üí LLM ‚Üí ... ‚Üí Final answer

Example: "What's the current price of AAPL and how does it compare to last month?"

Turn 1:
  LLM thinks: "I need to get the current AAPL price"
  LLM calls: get_stock_price(ticker="AAPL")
  Tool returns: {"price": 195.42, "timestamp": "2025-03-23T14:30:00Z"}

Turn 2:
  LLM thinks: "Now I need last month's price"
  LLM calls: get_stock_price(ticker="AAPL", date="2025-02-23")
  Tool returns: {"price": 182.15, "timestamp": "2025-02-23T21:00:00Z"}

Turn 3:
  LLM has both values, computes: (195.42 - 182.15) / 182.15 = +7.3%
  LLM answers: "AAPL is currently $195.42, up 7.3% from $182.15 a month ago."
</code></pre>
<h2>Defining Tools for Claude</h2>
<p>The quality of your tool descriptions is just as important as the quality of the tool implementations. The model uses the <code>description</code> and <code>input_schema</code> fields to decide when and how to call each tool ‚Äî vague or incomplete descriptions lead to incorrect or missing tool calls. Think of writing a tool definition as writing documentation for a junior developer who can only read the docstring, never the source code.</p>
<pre><code class="language-python">from anthropic import Anthropic

client = Anthropic()

# Tool definitions: describe capabilities to the model
tools = [
    {
        "name": "get_stock_price",
        "description": "Get the current or historical price of a stock ticker. "
                       "Returns price and timestamp.",
        "input_schema": {
            "type": "object",
            "properties": {
                "ticker": {
                    "type": "string",
                    "description": "Stock ticker symbol (e.g., AAPL, GOOGL, MSFT)"
                },
                "date": {
                    "type": "string",
                    "description": "Date in YYYY-MM-DD format for historical price. "
                                   "Omit for current price."
                }
            },
            "required": ["ticker"]
        }
    },
    {
        "name": "search_web",
        "description": "Search the web for current information. Use when you need "
                       "facts that might be recent or time-sensitive.",
        "input_schema": {
            "type": "object",
            "properties": {
                "query": {
                    "type": "string",
                    "description": "Search query"
                },
                "num_results": {
                    "type": "integer",
                    "description": "Number of results to return (1-10, default 3)"
                }
            },
            "required": ["query"]
        }
    },
    {
        "name": "execute_python",
        "description": "Execute Python code and return the output. "
                       "Use for calculations, data processing, or analysis.",
        "input_schema": {
            "type": "object",
            "properties": {
                "code": {
                    "type": "string",
                    "description": "Python code to execute"
                }
            },
            "required": ["code"]
        }
    }
]
</code></pre>
<h2>Tool Execution Layer</h2>
<p>With tools defined, you need a layer that routes tool calls to real implementations and handles errors gracefully. Notice the try/except wrapper in <code>execute</code> ‚Äî when a tool fails, you want to return a descriptive error string rather than crash the whole agent. The model will receive that error as the tool result and can decide to retry with different parameters or explain the failure to the user.</p>
<pre><code class="language-python">import yfinance as yf
import subprocess
import json
from datetime import datetime

class ToolExecutor:
    """Execute tool calls from the model."""

    def execute(self, tool_name: str, tool_input: dict) -> str:
        """Route tool call to the appropriate handler."""
        handlers = {
            "get_stock_price": self._get_stock_price,
            "search_web": self._search_web,
            "execute_python": self._execute_python,
        }

        handler = handlers.get(tool_name)
        if not handler:
            return f"Error: Unknown tool '{tool_name}'"

        try:
            return handler(**tool_input)
        except Exception as e:
            return f"Error executing {tool_name}: {str(e)}"

    def _get_stock_price(self, ticker: str, date: str | None = None) -> str:
        ticker_obj = yf.Ticker(ticker)

        if date:
            hist = ticker_obj.history(start=date, end=date, interval="1d")
            if hist.empty:
                return f"No data found for {ticker} on {date}"
            price = hist["Close"].iloc[-1]
            return json.dumps({"ticker": ticker, "price": round(price, 2), "date": date})
        else:
            info = ticker_obj.info
            price = info.get("currentPrice") or info.get("regularMarketPrice")
            return json.dumps({
                "ticker": ticker,
                "price": price,
                "timestamp": datetime.now().isoformat()
            })

    def _execute_python(self, code: str) -> str:
        """Execute Python in a sandboxed subprocess."""
        # IMPORTANT: In production, use a proper sandbox (Docker, Firecracker)
        # This is a simplified example
        try:
            result = subprocess.run(
                ["python3", "-c", code],
                capture_output=True, text=True, timeout=30,
                # Restrict network access in production
            )
            if result.returncode != 0:
                return f"Error: {result.stderr}"
            return result.stdout.strip()
        except subprocess.TimeoutExpired:
            return "Error: Code execution timed out (30s limit)"
</code></pre>
<h2>The Agentic Loop Implementation</h2>
<p>This is the core of every agent: a loop that calls the model, checks whether it wants to use a tool or give a final answer, executes tools if requested, and feeds results back into the conversation. The <code>max_turns</code> guard is not optional ‚Äî without it, a confused model can loop indefinitely and exhaust your API budget. Every production agent needs a hard ceiling on iterations.</p>
<pre><code class="language-python">def run_agent(user_message: str, max_turns: int = 10) -> str:
    """
    Run the agentic loop until the model returns a final answer
    or max_turns is reached.
    """
    executor = ToolExecutor()
    messages = [{"role": "user", "content": user_message}]

    for turn in range(max_turns):
        response = client.messages.create(
            model="claude-opus-4-6",
            max_tokens=4096,
            tools=tools,
            messages=messages
        )

        # Append assistant's response to conversation
        messages.append({"role": "assistant", "content": response.content})

        # Check stop reason
        if response.stop_reason == "end_turn":
            # Model is done ‚Äî extract and return the text response
            for block in response.content:
                if hasattr(block, "text"):
                    return block.text
            return "No response generated"

        elif response.stop_reason == "tool_use":
            # Model wants to call tools ‚Äî execute them all
            tool_results = []

            for block in response.content:
                if block.type == "tool_use":
                    print(f"  ‚Üí Calling {block.name}({block.input})")
                    result = executor.execute(block.name, block.input)
                    print(f"  ‚Üê Result: {result[:100]}...")

                    tool_results.append({
                        "type": "tool_result",
                        "tool_use_id": block.id,
                        "content": result
                    })

            # Return tool results to the model
            messages.append({"role": "user", "content": tool_results})

        else:
            return f"Unexpected stop reason: {response.stop_reason}"

    return "Max turns reached without a final answer"


# Test it
answer = run_agent("What's the market cap of Apple and how does it compare to Microsoft?")
print(answer)
</code></pre>
<p>The <code>stop_reason == "tool_use"</code> branch is where the magic happens: the model pauses its response mid-generation, your code executes the real tool, and the result is injected back into the conversation as if the model had looked it up itself. The model never hallucinates the answer because it never has to ‚Äî it just asks for what it needs.</p>
<h2>Human-in-the-Loop: Approving Actions</h2>
<p>For agents that take real-world actions (send emails, delete files, charge payments), add confirmation steps.</p>
<p>Before you give an agent the ability to take irreversible actions, you need a way to gate those actions behind human approval. The pattern below classifies tools by risk level and automatically approves low-risk reads while requiring explicit confirmation for anything that modifies state or has external effects.</p>
<pre><code class="language-python">from enum import Enum

class ActionRisk(Enum):
    LOW = "low"       # Read-only, reversible
    MEDIUM = "medium" # Reversible with effort
    HIGH = "high"     # Irreversible, external effects

# Annotate tools with their risk level
TOOL_RISK = {
    "search_web": ActionRisk.LOW,
    "get_stock_price": ActionRisk.LOW,
    "execute_python": ActionRisk.MEDIUM,
    "send_email": ActionRisk.HIGH,
    "delete_file": ActionRisk.HIGH,
    "charge_payment": ActionRisk.HIGH,
}

class SafeToolExecutor:

    def __init__(self, auto_approve_threshold: ActionRisk = ActionRisk.LOW):
        self.auto_approve_threshold = auto_approve_threshold
        self.base_executor = ToolExecutor()

    def execute(self, tool_name: str, tool_input: dict) -> str:
        risk = TOOL_RISK.get(tool_name, ActionRisk.HIGH)

        # Auto-approve low-risk actions
        if risk.value &#x3C;= self.auto_approve_threshold.value:
            return self.base_executor.execute(tool_name, tool_input)

        # Require human approval for high-risk actions
        approved = self._request_approval(tool_name, tool_input, risk)
        if not approved:
            return f"Action declined by user: {tool_name}"

        return self.base_executor.execute(tool_name, tool_input)

    def _request_approval(self, tool_name: str, tool_input: dict,
                          risk: ActionRisk) -> bool:
        print(f"\n‚ö†Ô∏è  [{risk.value.upper()} RISK] Agent wants to: {tool_name}")
        print(f"   Parameters: {json.dumps(tool_input, indent=2)}")
        response = input("Approve? [y/N]: ").strip().lower()
        return response == 'y'
</code></pre>
<p>The default of <code>auto_approve_threshold = ActionRisk.LOW</code> means only reads are automatic ‚Äî the agent has to ask permission before it executes code or sends anything. In a web application, you would replace the <code>input()</code> call with a UI prompt that surfaces in the user's chat window.</p>
<h2>Multi-Agent Orchestration</h2>
<p>Complex tasks benefit from specialized sub-agents.</p>
<p>Once your single-agent loop is working, you can compose multiple agents together where each one is focused on a narrow capability. The pattern below separates research (web search) from analysis (computation), with an orchestrator that coordinates the two. This separation means each sub-agent's tool list is small and its instructions are focused, which leads to fewer mistakes than giving one agent every possible tool at once.</p>
<pre><code class="language-python">class ResearchAgent:
    """Specialized agent for information gathering."""

    def research(self, topic: str) -> str:
        return run_agent(
            f"Research this topic comprehensively: {topic}. "
            "Use web search to find current information. "
            "Return a structured summary with key facts.",
            tools=[web_search_tool]  # Only search tools
        )

class AnalysisAgent:
    """Specialized agent for data analysis."""

    def analyze(self, data: str, question: str) -> str:
        return run_agent(
            f"Analyze this data and answer: {question}\n\nData:\n{data}",
            tools=[execute_python_tool]  # Only computation tools
        )

class OrchestratorAgent:
    """Coordinates research and analysis sub-agents."""

    def __init__(self):
        self.researcher = ResearchAgent()
        self.analyst = AnalysisAgent()

    def answer_complex_question(self, question: str) -> str:
        # Step 1: Research
        print("Phase 1: Researching...")
        research_data = self.researcher.research(question)

        # Step 2: Analyze
        print("Phase 2: Analyzing...")
        analysis = self.analyst.analyze(research_data, question)

        # Step 3: Synthesize
        print("Phase 3: Synthesizing...")
        return client.messages.create(
            model="claude-opus-4-6",
            max_tokens=2048,
            messages=[{
                "role": "user",
                "content": f"Question: {question}\n\n"
                          f"Research findings:\n{research_data}\n\n"
                          f"Analysis:\n{analysis}\n\n"
                          "Provide a comprehensive, well-structured final answer."
            }]
        ).content[0].text
</code></pre>
<h2>Production Considerations</h2>
<p>A working agent in a notebook is very different from a reliable agent in production. You need to handle API failures with retry logic, track costs before they surprise you, and monitor for the failure modes that only appear under real-world usage patterns.</p>
<pre><code class="language-python"># Error handling and retries
import time

def run_agent_with_retry(user_message: str, max_retries: int = 3) -> str:
    for attempt in range(max_retries):
        try:
            return run_agent(user_message)
        except anthropic.APIStatusError as e:
            if e.status_code == 529 and attempt &#x3C; max_retries - 1:
                time.sleep(2 ** attempt)  # Exponential backoff
            else:
                raise

# Cost tracking
class CostTrackingAgent:

    def __init__(self):
        self.total_input_tokens = 0
        self.total_output_tokens = 0

    def run(self, message: str) -> str:
        # claude-opus-4-6: $15/MTok input, $75/MTok output
        INPUT_COST_PER_MILLION = 15.0
        OUTPUT_COST_PER_MILLION = 75.0

        result, usage = run_agent_with_usage(message)

        self.total_input_tokens += usage.input_tokens
        self.total_output_tokens += usage.output_tokens

        cost = (usage.input_tokens * INPUT_COST_PER_MILLION / 1_000_000 +
                usage.output_tokens * OUTPUT_COST_PER_MILLION / 1_000_000)

        print(f"Cost: ${cost:.4f} | Total: ${self.total_cost:.4f}")
        return result
</code></pre>
<p>The exponential backoff in <code>run_agent_with_retry</code> is important: <code>time.sleep(2 ** attempt)</code> waits 1s, then 2s, then 4s on successive failures. This gives the API time to recover from transient overload without hammering it with immediate retries. The cost tracker is equally important ‚Äî agentic tasks can consume surprisingly many tokens per turn, and running hundreds of tasks without tracking will produce an unexpected bill.</p>
<p>The key insight for building reliable agents: <strong>the model is not magic</strong>. It will misuse tools, make reasoning errors, and get stuck in loops. Robust agents have: clear tool descriptions (garbage in ‚Üí garbage out), tool output validation, max turn limits (prevent infinite loops), error handling that feeds back to the model, and human checkpoints for irreversible actions. Build the safeguards before the features.</p>
</article><div class="my-10 rounded-xl border border-yellow-200 bg-yellow-50 p-6"><div class="flex items-center gap-2 mb-1"><span class="text-lg">üìö</span><h3 class="text-base font-bold text-gray-900">Recommended Resources</h3></div><div class="space-y-4"><div class="flex items-start gap-3 bg-white rounded-lg p-4 border border-yellow-100"><div class="flex-1 min-w-0"><div class="flex items-center gap-2 flex-wrap mb-1"><span class="font-semibold text-gray-900 text-sm">Building LLM Apps with LangChain ‚Äî Udemy</span><span class="text-xs bg-blue-100 text-blue-700 px-2 py-0.5 rounded-full font-medium">Hot</span></div><p class="text-xs text-gray-600">Build RAG systems, agents, and LLM-powered apps with Python and LangChain.</p></div><a href="https://www.udemy.com/course/langchain/" target="_blank" rel="noopener noreferrer" class="flex-shrink-0 text-xs bg-blue-600 text-white px-3 py-2 rounded-lg hover:bg-blue-700 transition-colors font-medium whitespace-nowrap">View Course<!-- --> ‚Üí</a></div><div class="flex items-start gap-3 bg-white rounded-lg p-4 border border-yellow-100"><div class="flex-1 min-w-0"><div class="flex items-center gap-2 flex-wrap mb-1"><span class="font-semibold text-gray-900 text-sm">Hands-On Large Language Models</span><span class="text-xs bg-blue-100 text-blue-700 px-2 py-0.5 rounded-full font-medium">New</span></div><p class="text-xs text-gray-600">Practical guide to training, fine-tuning, and deploying LLMs.</p></div><a href="https://amzn.to/3Vpd8h5" target="_blank" rel="noopener noreferrer" class="flex-shrink-0 text-xs bg-blue-600 text-white px-3 py-2 rounded-lg hover:bg-blue-700 transition-colors font-medium whitespace-nowrap">View on Amazon<!-- --> ‚Üí</a></div><div class="flex items-start gap-3 bg-white rounded-lg p-4 border border-yellow-100"><div class="flex-1 min-w-0"><div class="flex items-center gap-2 flex-wrap mb-1"><span class="font-semibold text-gray-900 text-sm">AI Engineering by Chip Huyen</span></div><p class="text-xs text-gray-600">Building intelligent systems with foundation models ‚Äî from retrieval to agents.</p></div><a href="https://amzn.to/3Vrd1Rd" target="_blank" rel="noopener noreferrer" class="flex-shrink-0 text-xs bg-blue-600 text-white px-3 py-2 rounded-lg hover:bg-blue-700 transition-colors font-medium whitespace-nowrap">View on Amazon<!-- --> ‚Üí</a></div></div></div><div class="mt-10 pt-8 border-t border-gray-100"><p class="text-sm text-gray-500 mb-3">Found this useful? Share it:</p><div class="flex gap-3"><a href="https://twitter.com/intent/tweet?text=Building%20AI%20Agents%20with%20Tool%20Use%3A%20From%20Chatbot%20to%20Autonomous%20Agent&amp;url=https%3A%2F%2Fcodesprintpro.com%2Fblog%2Fllm-agents-tool-use%2F" target="_blank" rel="noopener noreferrer" class="text-xs bg-gray-900 text-white px-4 py-2 rounded-lg hover:bg-gray-700 transition-colors">Share on X/Twitter</a><a href="https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fcodesprintpro.com%2Fblog%2Fllm-agents-tool-use%2F" target="_blank" rel="noopener noreferrer" class="text-xs bg-blue-600 text-white px-4 py-2 rounded-lg hover:bg-blue-700 transition-colors">Share on LinkedIn</a></div></div></div><aside class="hidden lg:block w-64 flex-shrink-0"><nav class="hidden lg:block sticky top-24"><h4 class="text-xs font-semibold uppercase tracking-widest text-gray-400 mb-3">On This Page</h4><ul class="space-y-1"><li class=""><a href="#the-agentic-loop" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">The Agentic Loop</a></li><li class=""><a href="#defining-tools-for-claude" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Defining Tools for Claude</a></li><li class=""><a href="#tool-execution-layer" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Tool Execution Layer</a></li><li class=""><a href="#the-agentic-loop-implementation" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">The Agentic Loop Implementation</a></li><li class=""><a href="#human-in-the-loop-approving-actions" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Human-in-the-Loop: Approving Actions</a></li><li class=""><a href="#multi-agent-orchestration" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Multi-Agent Orchestration</a></li><li class=""><a href="#production-considerations" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Production Considerations</a></li></ul></nav></aside></div><div class="mt-16 pt-10 border-t border-gray-100"><h2 class="text-2xl font-bold text-gray-900 mb-6">Related Articles</h2><div class="grid grid-cols-1 md:grid-cols-3 gap-6"><a href="/blog/fine-tuning-llms/"><article class="group bg-white rounded-xl border border-gray-200 p-6 h-full cursor-pointer hover:border-blue-300 hover:shadow-lg transition-all"><span class="inline-block text-xs font-semibold px-3 py-1 rounded-full mb-3 bg-purple-100 text-purple-700">AI/ML</span><h3 class="text-lg font-bold text-gray-900 mb-2 group-hover:text-blue-600 transition-colors leading-snug">Fine-Tuning LLMs: When to Fine-Tune, When to Prompt</h3><p class="text-gray-600 text-sm mb-4 line-clamp-3">Fine-tuning is often the wrong choice. Most problems that engineers reach for fine-tuning to solve are better solved with better prompt engineering, few-shot examples, or RAG. But when you genuinely need fine-tuning ‚Äî fo‚Ä¶</p><div class="flex items-center justify-between text-xs text-gray-400"><span>Mar 27, 2025</span><span class="flex items-center gap-1"><svg class="w-3 h-3" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>10 min read</span></div><div class="mt-3 flex flex-wrap gap-1"><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->ai</span><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->llm</span><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->fine-tuning</span></div></article></a><a href="/blog/vector-embeddings-deep-dive/"><article class="group bg-white rounded-xl border border-gray-200 p-6 h-full cursor-pointer hover:border-blue-300 hover:shadow-lg transition-all"><span class="inline-block text-xs font-semibold px-3 py-1 rounded-full mb-3 bg-purple-100 text-purple-700">AI/ML</span><h3 class="text-lg font-bold text-gray-900 mb-2 group-hover:text-blue-600 transition-colors leading-snug">Vector Embeddings: The Foundation of Modern AI Applications</h3><p class="text-gray-600 text-sm mb-4 line-clamp-3">Every modern AI application ‚Äî semantic search, RAG, recommendations, duplicate detection ‚Äî is built on vector embeddings. An embedding converts text, images, or audio into a point in high-dimensional space where semantic‚Ä¶</p><div class="flex items-center justify-between text-xs text-gray-400"><span>Mar 11, 2025</span><span class="flex items-center gap-1"><svg class="w-3 h-3" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>11 min read</span></div><div class="mt-3 flex flex-wrap gap-1"><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->ai</span><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->embeddings</span><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->vector database</span></div></article></a><a href="/blog/prompt-engineering-production/"><article class="group bg-white rounded-xl border border-gray-200 p-6 h-full cursor-pointer hover:border-blue-300 hover:shadow-lg transition-all"><span class="inline-block text-xs font-semibold px-3 py-1 rounded-full mb-3 bg-purple-100 text-purple-700">AI/ML</span><h3 class="text-lg font-bold text-gray-900 mb-2 group-hover:text-blue-600 transition-colors leading-snug">Prompt Engineering: Advanced Techniques for Production LLMs</h3><p class="text-gray-600 text-sm mb-4 line-clamp-3">Most prompt engineering tutorials stop at &quot;be specific and provide context.&quot; That&#x27;s necessary but not sufficient for production systems. This article covers the advanced techniques that separate demos from production-gra‚Ä¶</p><div class="flex items-center justify-between text-xs text-gray-400"><span>Feb 26, 2025</span><span class="flex items-center gap-1"><svg class="w-3 h-3" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>11 min read</span></div><div class="mt-3 flex flex-wrap gap-1"><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->ai</span><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->llm</span><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->prompt engineering</span></div></article></a></div></div><div class="mt-12 text-center"><a class="inline-flex items-center gap-2 text-blue-600 hover:text-blue-700 font-medium transition-colors" href="/blog/">‚Üê Back to all articles</a></div></div></div><footer class="bg-gray-900 text-white py-12"><div class="container mx-auto px-4 sm:px-6 lg:px-8"><div class="grid grid-cols-1 md:grid-cols-4 gap-8 mb-8"><div class="col-span-1 md:col-span-1"><div><a class="text-xl font-bold block mb-3 text-white hover:text-blue-400 transition-colors" href="/">CodeSprintPro</a></div><p class="text-gray-400 text-sm mb-4 leading-relaxed">Deep-dive technical content on System Design, Java, Databases, AI/ML, and AWS ‚Äî by Sachin Sarawgi.</p><div class="flex space-x-4"><a href="https://github.com/codesprintpro" target="_blank" rel="noopener noreferrer" class="text-gray-400 hover:text-white transition-colors" aria-label="Visit GitHub profile"><i class="fab fa-github text-xl"></i></a><a href="https://www.linkedin.com/in/sachin-sarawgi/" target="_blank" rel="noopener noreferrer" class="text-gray-400 hover:text-white transition-colors" aria-label="Visit LinkedIn profile"><i class="fab fa-linkedin text-xl"></i></a><a href="https://medium.com/@codesprintpro" target="_blank" rel="noopener noreferrer" class="text-gray-400 hover:text-white transition-colors" aria-label="Visit Medium profile"><i class="fab fa-medium text-xl"></i></a></div></div><div><h3 class="text-sm font-semibold uppercase tracking-widest text-gray-400 mb-4">Quick Links</h3><ul class="space-y-2"><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">Blog</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/#about">About</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/#portfolio">Portfolio</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/#contact">Contact</a></div></li></ul></div><div><h3 class="text-sm font-semibold uppercase tracking-widest text-gray-400 mb-4">Categories</h3><ul class="space-y-2"><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">System Design</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">Java</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">Databases</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">AI/ML</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">AWS</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">Messaging</a></div></li></ul></div><div><h3 class="text-sm font-semibold uppercase tracking-widest text-gray-400 mb-4">Contact</h3><ul class="space-y-2 text-gray-400 text-sm"><li><a href="mailto:sachinsarawgi201143@gmail.com" class="hover:text-white transition-colors flex items-center gap-2"><i class="fas fa-envelope"></i> Email</a></li><li><a href="https://www.linkedin.com/in/sachin-sarawgi/" target="_blank" rel="noopener noreferrer" class="hover:text-white transition-colors flex items-center gap-2"><i class="fab fa-linkedin"></i> LinkedIn</a></li><li><a href="https://github.com/codesprintpro" target="_blank" rel="noopener noreferrer" class="hover:text-white transition-colors flex items-center gap-2"><i class="fab fa-github"></i> GitHub</a></li></ul></div></div><div class="border-t border-gray-800 pt-6 flex flex-col md:flex-row justify-between items-center gap-2"><p class="text-gray-500 text-sm">¬© <!-- -->2026<!-- --> CodeSprintPro ¬∑ Sachin Sarawgi. All rights reserved.</p><p class="text-gray-600 text-xs">Built with Next.js ¬∑ TailwindCSS ¬∑ Deployed on GitHub Pages</p></div></div></footer></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"Building AI Agents with Tool Use: From Chatbot to Autonomous Agent","description":"Build production AI agents using Claude's tool use API. Learn the agentic loop, error handling, multi-step reasoning, human-in-the-loop patterns, and how to build reliable autonomous systems.","date":"2025-03-23","category":"AI/ML","tags":["ai","agents","claude","tool use","llm","autonomous systems","python"],"featured":false,"affiliateSection":"ai-ml-books","slug":"llm-agents-tool-use","readingTime":"10 min read","excerpt":"A chatbot answers questions. An agent takes actions. The difference is tool use: the ability to call functions, search databases, execute code, and interact with external systems. When a model can look up real informatio‚Ä¶","contentHtml":"\u003cp\u003eA chatbot answers questions. An agent takes actions. The difference is tool use: the ability to call functions, search databases, execute code, and interact with external systems. When a model can look up real information, run calculations, and modify state, it transforms from a text generator into a capable assistant. This article builds production-grade agents that actually work.\u003c/p\u003e\n\u003ch2\u003eThe Agentic Loop\u003c/h2\u003e\n\u003cp\u003eBefore writing any code, it helps to see the agentic loop in action at the conceptual level. The model does not have all the information it needs to answer a question ‚Äî instead, it decides what information to fetch, fetches it, and then decides whether it knows enough or needs to take another step. This trace shows that exact reasoning process for a two-step stock comparison question.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eUser request ‚Üí LLM ‚Üí Tool call ‚Üí Execute ‚Üí Result ‚Üí LLM ‚Üí ... ‚Üí Final answer\n\nExample: \"What's the current price of AAPL and how does it compare to last month?\"\n\nTurn 1:\n  LLM thinks: \"I need to get the current AAPL price\"\n  LLM calls: get_stock_price(ticker=\"AAPL\")\n  Tool returns: {\"price\": 195.42, \"timestamp\": \"2025-03-23T14:30:00Z\"}\n\nTurn 2:\n  LLM thinks: \"Now I need last month's price\"\n  LLM calls: get_stock_price(ticker=\"AAPL\", date=\"2025-02-23\")\n  Tool returns: {\"price\": 182.15, \"timestamp\": \"2025-02-23T21:00:00Z\"}\n\nTurn 3:\n  LLM has both values, computes: (195.42 - 182.15) / 182.15 = +7.3%\n  LLM answers: \"AAPL is currently $195.42, up 7.3% from $182.15 a month ago.\"\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eDefining Tools for Claude\u003c/h2\u003e\n\u003cp\u003eThe quality of your tool descriptions is just as important as the quality of the tool implementations. The model uses the \u003ccode\u003edescription\u003c/code\u003e and \u003ccode\u003einput_schema\u003c/code\u003e fields to decide when and how to call each tool ‚Äî vague or incomplete descriptions lead to incorrect or missing tool calls. Think of writing a tool definition as writing documentation for a junior developer who can only read the docstring, never the source code.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom anthropic import Anthropic\n\nclient = Anthropic()\n\n# Tool definitions: describe capabilities to the model\ntools = [\n    {\n        \"name\": \"get_stock_price\",\n        \"description\": \"Get the current or historical price of a stock ticker. \"\n                       \"Returns price and timestamp.\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"ticker\": {\n                    \"type\": \"string\",\n                    \"description\": \"Stock ticker symbol (e.g., AAPL, GOOGL, MSFT)\"\n                },\n                \"date\": {\n                    \"type\": \"string\",\n                    \"description\": \"Date in YYYY-MM-DD format for historical price. \"\n                                   \"Omit for current price.\"\n                }\n            },\n            \"required\": [\"ticker\"]\n        }\n    },\n    {\n        \"name\": \"search_web\",\n        \"description\": \"Search the web for current information. Use when you need \"\n                       \"facts that might be recent or time-sensitive.\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"query\": {\n                    \"type\": \"string\",\n                    \"description\": \"Search query\"\n                },\n                \"num_results\": {\n                    \"type\": \"integer\",\n                    \"description\": \"Number of results to return (1-10, default 3)\"\n                }\n            },\n            \"required\": [\"query\"]\n        }\n    },\n    {\n        \"name\": \"execute_python\",\n        \"description\": \"Execute Python code and return the output. \"\n                       \"Use for calculations, data processing, or analysis.\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"code\": {\n                    \"type\": \"string\",\n                    \"description\": \"Python code to execute\"\n                }\n            },\n            \"required\": [\"code\"]\n        }\n    }\n]\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eTool Execution Layer\u003c/h2\u003e\n\u003cp\u003eWith tools defined, you need a layer that routes tool calls to real implementations and handles errors gracefully. Notice the try/except wrapper in \u003ccode\u003eexecute\u003c/code\u003e ‚Äî when a tool fails, you want to return a descriptive error string rather than crash the whole agent. The model will receive that error as the tool result and can decide to retry with different parameters or explain the failure to the user.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eimport yfinance as yf\nimport subprocess\nimport json\nfrom datetime import datetime\n\nclass ToolExecutor:\n    \"\"\"Execute tool calls from the model.\"\"\"\n\n    def execute(self, tool_name: str, tool_input: dict) -\u003e str:\n        \"\"\"Route tool call to the appropriate handler.\"\"\"\n        handlers = {\n            \"get_stock_price\": self._get_stock_price,\n            \"search_web\": self._search_web,\n            \"execute_python\": self._execute_python,\n        }\n\n        handler = handlers.get(tool_name)\n        if not handler:\n            return f\"Error: Unknown tool '{tool_name}'\"\n\n        try:\n            return handler(**tool_input)\n        except Exception as e:\n            return f\"Error executing {tool_name}: {str(e)}\"\n\n    def _get_stock_price(self, ticker: str, date: str | None = None) -\u003e str:\n        ticker_obj = yf.Ticker(ticker)\n\n        if date:\n            hist = ticker_obj.history(start=date, end=date, interval=\"1d\")\n            if hist.empty:\n                return f\"No data found for {ticker} on {date}\"\n            price = hist[\"Close\"].iloc[-1]\n            return json.dumps({\"ticker\": ticker, \"price\": round(price, 2), \"date\": date})\n        else:\n            info = ticker_obj.info\n            price = info.get(\"currentPrice\") or info.get(\"regularMarketPrice\")\n            return json.dumps({\n                \"ticker\": ticker,\n                \"price\": price,\n                \"timestamp\": datetime.now().isoformat()\n            })\n\n    def _execute_python(self, code: str) -\u003e str:\n        \"\"\"Execute Python in a sandboxed subprocess.\"\"\"\n        # IMPORTANT: In production, use a proper sandbox (Docker, Firecracker)\n        # This is a simplified example\n        try:\n            result = subprocess.run(\n                [\"python3\", \"-c\", code],\n                capture_output=True, text=True, timeout=30,\n                # Restrict network access in production\n            )\n            if result.returncode != 0:\n                return f\"Error: {result.stderr}\"\n            return result.stdout.strip()\n        except subprocess.TimeoutExpired:\n            return \"Error: Code execution timed out (30s limit)\"\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eThe Agentic Loop Implementation\u003c/h2\u003e\n\u003cp\u003eThis is the core of every agent: a loop that calls the model, checks whether it wants to use a tool or give a final answer, executes tools if requested, and feeds results back into the conversation. The \u003ccode\u003emax_turns\u003c/code\u003e guard is not optional ‚Äî without it, a confused model can loop indefinitely and exhaust your API budget. Every production agent needs a hard ceiling on iterations.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef run_agent(user_message: str, max_turns: int = 10) -\u003e str:\n    \"\"\"\n    Run the agentic loop until the model returns a final answer\n    or max_turns is reached.\n    \"\"\"\n    executor = ToolExecutor()\n    messages = [{\"role\": \"user\", \"content\": user_message}]\n\n    for turn in range(max_turns):\n        response = client.messages.create(\n            model=\"claude-opus-4-6\",\n            max_tokens=4096,\n            tools=tools,\n            messages=messages\n        )\n\n        # Append assistant's response to conversation\n        messages.append({\"role\": \"assistant\", \"content\": response.content})\n\n        # Check stop reason\n        if response.stop_reason == \"end_turn\":\n            # Model is done ‚Äî extract and return the text response\n            for block in response.content:\n                if hasattr(block, \"text\"):\n                    return block.text\n            return \"No response generated\"\n\n        elif response.stop_reason == \"tool_use\":\n            # Model wants to call tools ‚Äî execute them all\n            tool_results = []\n\n            for block in response.content:\n                if block.type == \"tool_use\":\n                    print(f\"  ‚Üí Calling {block.name}({block.input})\")\n                    result = executor.execute(block.name, block.input)\n                    print(f\"  ‚Üê Result: {result[:100]}...\")\n\n                    tool_results.append({\n                        \"type\": \"tool_result\",\n                        \"tool_use_id\": block.id,\n                        \"content\": result\n                    })\n\n            # Return tool results to the model\n            messages.append({\"role\": \"user\", \"content\": tool_results})\n\n        else:\n            return f\"Unexpected stop reason: {response.stop_reason}\"\n\n    return \"Max turns reached without a final answer\"\n\n\n# Test it\nanswer = run_agent(\"What's the market cap of Apple and how does it compare to Microsoft?\")\nprint(answer)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe \u003ccode\u003estop_reason == \"tool_use\"\u003c/code\u003e branch is where the magic happens: the model pauses its response mid-generation, your code executes the real tool, and the result is injected back into the conversation as if the model had looked it up itself. The model never hallucinates the answer because it never has to ‚Äî it just asks for what it needs.\u003c/p\u003e\n\u003ch2\u003eHuman-in-the-Loop: Approving Actions\u003c/h2\u003e\n\u003cp\u003eFor agents that take real-world actions (send emails, delete files, charge payments), add confirmation steps.\u003c/p\u003e\n\u003cp\u003eBefore you give an agent the ability to take irreversible actions, you need a way to gate those actions behind human approval. The pattern below classifies tools by risk level and automatically approves low-risk reads while requiring explicit confirmation for anything that modifies state or has external effects.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom enum import Enum\n\nclass ActionRisk(Enum):\n    LOW = \"low\"       # Read-only, reversible\n    MEDIUM = \"medium\" # Reversible with effort\n    HIGH = \"high\"     # Irreversible, external effects\n\n# Annotate tools with their risk level\nTOOL_RISK = {\n    \"search_web\": ActionRisk.LOW,\n    \"get_stock_price\": ActionRisk.LOW,\n    \"execute_python\": ActionRisk.MEDIUM,\n    \"send_email\": ActionRisk.HIGH,\n    \"delete_file\": ActionRisk.HIGH,\n    \"charge_payment\": ActionRisk.HIGH,\n}\n\nclass SafeToolExecutor:\n\n    def __init__(self, auto_approve_threshold: ActionRisk = ActionRisk.LOW):\n        self.auto_approve_threshold = auto_approve_threshold\n        self.base_executor = ToolExecutor()\n\n    def execute(self, tool_name: str, tool_input: dict) -\u003e str:\n        risk = TOOL_RISK.get(tool_name, ActionRisk.HIGH)\n\n        # Auto-approve low-risk actions\n        if risk.value \u0026#x3C;= self.auto_approve_threshold.value:\n            return self.base_executor.execute(tool_name, tool_input)\n\n        # Require human approval for high-risk actions\n        approved = self._request_approval(tool_name, tool_input, risk)\n        if not approved:\n            return f\"Action declined by user: {tool_name}\"\n\n        return self.base_executor.execute(tool_name, tool_input)\n\n    def _request_approval(self, tool_name: str, tool_input: dict,\n                          risk: ActionRisk) -\u003e bool:\n        print(f\"\\n‚ö†Ô∏è  [{risk.value.upper()} RISK] Agent wants to: {tool_name}\")\n        print(f\"   Parameters: {json.dumps(tool_input, indent=2)}\")\n        response = input(\"Approve? [y/N]: \").strip().lower()\n        return response == 'y'\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe default of \u003ccode\u003eauto_approve_threshold = ActionRisk.LOW\u003c/code\u003e means only reads are automatic ‚Äî the agent has to ask permission before it executes code or sends anything. In a web application, you would replace the \u003ccode\u003einput()\u003c/code\u003e call with a UI prompt that surfaces in the user's chat window.\u003c/p\u003e\n\u003ch2\u003eMulti-Agent Orchestration\u003c/h2\u003e\n\u003cp\u003eComplex tasks benefit from specialized sub-agents.\u003c/p\u003e\n\u003cp\u003eOnce your single-agent loop is working, you can compose multiple agents together where each one is focused on a narrow capability. The pattern below separates research (web search) from analysis (computation), with an orchestrator that coordinates the two. This separation means each sub-agent's tool list is small and its instructions are focused, which leads to fewer mistakes than giving one agent every possible tool at once.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eclass ResearchAgent:\n    \"\"\"Specialized agent for information gathering.\"\"\"\n\n    def research(self, topic: str) -\u003e str:\n        return run_agent(\n            f\"Research this topic comprehensively: {topic}. \"\n            \"Use web search to find current information. \"\n            \"Return a structured summary with key facts.\",\n            tools=[web_search_tool]  # Only search tools\n        )\n\nclass AnalysisAgent:\n    \"\"\"Specialized agent for data analysis.\"\"\"\n\n    def analyze(self, data: str, question: str) -\u003e str:\n        return run_agent(\n            f\"Analyze this data and answer: {question}\\n\\nData:\\n{data}\",\n            tools=[execute_python_tool]  # Only computation tools\n        )\n\nclass OrchestratorAgent:\n    \"\"\"Coordinates research and analysis sub-agents.\"\"\"\n\n    def __init__(self):\n        self.researcher = ResearchAgent()\n        self.analyst = AnalysisAgent()\n\n    def answer_complex_question(self, question: str) -\u003e str:\n        # Step 1: Research\n        print(\"Phase 1: Researching...\")\n        research_data = self.researcher.research(question)\n\n        # Step 2: Analyze\n        print(\"Phase 2: Analyzing...\")\n        analysis = self.analyst.analyze(research_data, question)\n\n        # Step 3: Synthesize\n        print(\"Phase 3: Synthesizing...\")\n        return client.messages.create(\n            model=\"claude-opus-4-6\",\n            max_tokens=2048,\n            messages=[{\n                \"role\": \"user\",\n                \"content\": f\"Question: {question}\\n\\n\"\n                          f\"Research findings:\\n{research_data}\\n\\n\"\n                          f\"Analysis:\\n{analysis}\\n\\n\"\n                          \"Provide a comprehensive, well-structured final answer.\"\n            }]\n        ).content[0].text\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eProduction Considerations\u003c/h2\u003e\n\u003cp\u003eA working agent in a notebook is very different from a reliable agent in production. You need to handle API failures with retry logic, track costs before they surprise you, and monitor for the failure modes that only appear under real-world usage patterns.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# Error handling and retries\nimport time\n\ndef run_agent_with_retry(user_message: str, max_retries: int = 3) -\u003e str:\n    for attempt in range(max_retries):\n        try:\n            return run_agent(user_message)\n        except anthropic.APIStatusError as e:\n            if e.status_code == 529 and attempt \u0026#x3C; max_retries - 1:\n                time.sleep(2 ** attempt)  # Exponential backoff\n            else:\n                raise\n\n# Cost tracking\nclass CostTrackingAgent:\n\n    def __init__(self):\n        self.total_input_tokens = 0\n        self.total_output_tokens = 0\n\n    def run(self, message: str) -\u003e str:\n        # claude-opus-4-6: $15/MTok input, $75/MTok output\n        INPUT_COST_PER_MILLION = 15.0\n        OUTPUT_COST_PER_MILLION = 75.0\n\n        result, usage = run_agent_with_usage(message)\n\n        self.total_input_tokens += usage.input_tokens\n        self.total_output_tokens += usage.output_tokens\n\n        cost = (usage.input_tokens * INPUT_COST_PER_MILLION / 1_000_000 +\n                usage.output_tokens * OUTPUT_COST_PER_MILLION / 1_000_000)\n\n        print(f\"Cost: ${cost:.4f} | Total: ${self.total_cost:.4f}\")\n        return result\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe exponential backoff in \u003ccode\u003erun_agent_with_retry\u003c/code\u003e is important: \u003ccode\u003etime.sleep(2 ** attempt)\u003c/code\u003e waits 1s, then 2s, then 4s on successive failures. This gives the API time to recover from transient overload without hammering it with immediate retries. The cost tracker is equally important ‚Äî agentic tasks can consume surprisingly many tokens per turn, and running hundreds of tasks without tracking will produce an unexpected bill.\u003c/p\u003e\n\u003cp\u003eThe key insight for building reliable agents: \u003cstrong\u003ethe model is not magic\u003c/strong\u003e. It will misuse tools, make reasoning errors, and get stuck in loops. Robust agents have: clear tool descriptions (garbage in ‚Üí garbage out), tool output validation, max turn limits (prevent infinite loops), error handling that feeds back to the model, and human checkpoints for irreversible actions. Build the safeguards before the features.\u003c/p\u003e\n","tableOfContents":[{"id":"the-agentic-loop","text":"The Agentic Loop","level":2},{"id":"defining-tools-for-claude","text":"Defining Tools for Claude","level":2},{"id":"tool-execution-layer","text":"Tool Execution Layer","level":2},{"id":"the-agentic-loop-implementation","text":"The Agentic Loop Implementation","level":2},{"id":"human-in-the-loop-approving-actions","text":"Human-in-the-Loop: Approving Actions","level":2},{"id":"multi-agent-orchestration","text":"Multi-Agent Orchestration","level":2},{"id":"production-considerations","text":"Production Considerations","level":2}]},"relatedPosts":[{"title":"Fine-Tuning LLMs: When to Fine-Tune, When to Prompt","description":"Decide when fine-tuning beats prompt engineering, how to prepare training data, run LoRA fine-tuning efficiently, and evaluate model quality. Covers OpenAI fine-tuning and open-source with Hugging Face.","date":"2025-03-27","category":"AI/ML","tags":["ai","llm","fine-tuning","lora","hugging face","openai","machine learning"],"featured":false,"affiliateSection":"ai-ml-books","slug":"fine-tuning-llms","readingTime":"10 min read","excerpt":"Fine-tuning is often the wrong choice. Most problems that engineers reach for fine-tuning to solve are better solved with better prompt engineering, few-shot examples, or RAG. But when you genuinely need fine-tuning ‚Äî fo‚Ä¶"},{"title":"Vector Embeddings: The Foundation of Modern AI Applications","description":"Understand vector embeddings, similarity search, and vector databases. Build semantic search, recommendation systems, and RAG pipelines using pgvector, Pinecone, and OpenAI embeddings.","date":"2025-03-11","category":"AI/ML","tags":["ai","embeddings","vector database","semantic search","rag","pgvector","pinecone"],"featured":false,"affiliateSection":"ai-ml-books","slug":"vector-embeddings-deep-dive","readingTime":"11 min read","excerpt":"Every modern AI application ‚Äî semantic search, RAG, recommendations, duplicate detection ‚Äî is built on vector embeddings. An embedding converts text, images, or audio into a point in high-dimensional space where semantic‚Ä¶"},{"title":"Prompt Engineering: Advanced Techniques for Production LLMs","description":"Go beyond basic prompting. Learn chain-of-thought reasoning, few-shot examples, structured output, self-consistency, ReAct agents, and evaluation techniques for production LLM applications.","date":"2025-02-26","category":"AI/ML","tags":["ai","llm","prompt engineering","gpt","claude","production"],"featured":false,"affiliateSection":"ai-ml-books","slug":"prompt-engineering-production","readingTime":"11 min read","excerpt":"Most prompt engineering tutorials stop at \"be specific and provide context.\" That's necessary but not sufficient for production systems. This article covers the advanced techniques that separate demos from production-gra‚Ä¶"}]},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"llm-agents-tool-use"},"buildId":"rpFn_jslWZ9qPkJwor7RD","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>