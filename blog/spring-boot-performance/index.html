<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8" data-next-head=""/><meta name="viewport" content="width=device-width" data-next-head=""/><title data-next-head="">Spring Boot Performance Tuning: From 200 to 2000 RPS<!-- --> | CodeSprintPro</title><meta name="description" content="Systematic approach to Spring Boot performance tuning. Covers connection pooling, N+1 query elimination, caching strategies, async processing, and JVM tuning to multiply throughput." data-next-head=""/><meta name="author" content="Sachin Sarawgi" data-next-head=""/><link rel="canonical" href="https://codesprintpro.com/blog/spring-boot-performance/" data-next-head=""/><meta property="og:type" content="article" data-next-head=""/><meta property="og:title" content="Spring Boot Performance Tuning: From 200 to 2000 RPS" data-next-head=""/><meta property="og:description" content="Systematic approach to Spring Boot performance tuning. Covers connection pooling, N+1 query elimination, caching strategies, async processing, and JVM tuning to multiply throughput." data-next-head=""/><meta property="og:url" content="https://codesprintpro.com/blog/spring-boot-performance/" data-next-head=""/><meta property="og:image" content="https://codesprintpro.com/images/og-default.jpg" data-next-head=""/><meta property="og:site_name" content="CodeSprintPro" data-next-head=""/><meta property="article:published_time" content="2025-03-13" data-next-head=""/><meta property="article:author" content="Sachin Sarawgi" data-next-head=""/><meta property="article:section" content="Java" data-next-head=""/><meta property="article:tag" content="spring boot" data-next-head=""/><meta property="article:tag" content="java" data-next-head=""/><meta property="article:tag" content="performance" data-next-head=""/><meta property="article:tag" content="hikaricp" data-next-head=""/><meta property="article:tag" content="redis" data-next-head=""/><meta property="article:tag" content="jpa" data-next-head=""/><meta property="article:tag" content="tuning" data-next-head=""/><meta name="twitter:card" content="summary_large_image" data-next-head=""/><meta name="twitter:title" content="Spring Boot Performance Tuning: From 200 to 2000 RPS" data-next-head=""/><meta name="twitter:description" content="Systematic approach to Spring Boot performance tuning. Covers connection pooling, N+1 query elimination, caching strategies, async processing, and JVM tuning to multiply throughput." data-next-head=""/><meta name="twitter:image" content="https://codesprintpro.com/images/og-default.jpg" data-next-head=""/><script type="application/ld+json" data-next-head="">{"@context":"https://schema.org","@type":"BlogPosting","headline":"Spring Boot Performance Tuning: From 200 to 2000 RPS","description":"Systematic approach to Spring Boot performance tuning. Covers connection pooling, N+1 query elimination, caching strategies, async processing, and JVM tuning to multiply throughput.","image":"https://codesprintpro.com/images/og-default.jpg","datePublished":"2025-03-13","dateModified":"2025-03-13","author":{"@type":"Person","name":"Sachin Sarawgi","url":"https://codesprintpro.com","sameAs":["https://www.linkedin.com/in/sachin-sarawgi/","https://github.com/codesprintpro","https://medium.com/@codesprintpro"]},"publisher":{"@type":"Organization","name":"CodeSprintPro","url":"https://codesprintpro.com","logo":{"@type":"ImageObject","url":"https://codesprintpro.com/favicon/favicon-96x96.png"}},"mainEntityOfPage":{"@type":"WebPage","@id":"https://codesprintpro.com/blog/spring-boot-performance/"},"keywords":"spring boot, java, performance, hikaricp, redis, jpa, tuning","articleSection":"Java"}</script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" integrity="sha512-9usAa10IRO0HhonpyAIVpjrylPvoDwiPUiKdWk5t3PyolY1cOd4DSE0Ga+ri4AuTroPR5aQvXU9xC6qOPnzFeg==" crossorigin="anonymous" referrerPolicy="no-referrer"/><script async="" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-XXXXXXXXXXXXXXXX" crossorigin="anonymous"></script><link rel="preload" href="/_next/static/media/e4af272ccee01ff0-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/css/735d4373f93910ca.css" as="style"/><link rel="stylesheet" href="/_next/static/css/735d4373f93910ca.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-11a4a2dad04962bb.js" defer=""></script><script src="/_next/static/chunks/framework-1ce91eb6f9ecda85.js" defer=""></script><script src="/_next/static/chunks/main-c7f4109f032d7b6e.js" defer=""></script><script src="/_next/static/chunks/pages/_app-1a852bd9e38c70ab.js" defer=""></script><script src="/_next/static/chunks/730-db7827467817f501.js" defer=""></script><script src="/_next/static/chunks/90-1cd4611704c3dbe0.js" defer=""></script><script src="/_next/static/chunks/440-29f4b99a44e744b5.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-0c1b14a33d5e05ee.js" defer=""></script><script src="/_next/static/rpFn_jslWZ9qPkJwor7RD/_buildManifest.js" defer=""></script><script src="/_next/static/rpFn_jslWZ9qPkJwor7RD/_ssgManifest.js" defer=""></script></head><body><div id="__next"><main class="__className_f367f3"><div class="min-h-screen bg-white"><nav class="fixed w-full z-50 transition-all duration-300 bg-white shadow-md" style="transform:translateY(-100px) translateZ(0)"><div class="container mx-auto px-4 sm:px-6 lg:px-8"><div class="flex items-center justify-between h-16"><a class="text-xl font-bold transition-colors text-blue-600" href="/">CodeSprintPro</a><div class="hidden md:flex items-center space-x-8"><a class="text-sm font-medium transition-colors text-blue-600" href="/blog/">Blog</a><a class="text-sm font-medium transition-colors text-gray-600 hover:text-blue-600" href="/#about">About</a><a class="text-sm font-medium transition-colors text-gray-600 hover:text-blue-600" href="/#portfolio">Portfolio</a><a class="text-sm font-medium transition-colors text-gray-600 hover:text-blue-600" href="/#contact">Contact</a></div><button class="md:hidden p-2 rounded-lg transition-colors hover:bg-gray-100 text-gray-600" aria-label="Toggle mobile menu"><svg class="w-6 h-6" fill="none" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" stroke="currentColor"><path d="M4 6h16M4 12h16M4 18h16"></path></svg></button></div></div></nav><div class="pt-20"><div class="bg-gradient-to-br from-gray-900 to-blue-950 py-16"><div class="container mx-auto px-4 sm:px-6 lg:px-8 max-w-5xl"><nav class="flex items-center gap-2 text-sm text-gray-400 mb-6"><a class="hover:text-white transition-colors" href="/">Home</a><span>/</span><a class="hover:text-white transition-colors" href="/blog/">Blog</a><span>/</span><span class="text-gray-300 truncate max-w-xs">Spring Boot Performance Tuning: From 200 to 2000 RPS</span></nav><span class="inline-block text-xs font-semibold px-3 py-1 rounded-full bg-blue-100 text-blue-700 mb-4">Java</span><h1 class="text-3xl md:text-5xl font-bold text-white mb-4 leading-tight">Spring Boot Performance Tuning: From 200 to 2000 RPS</h1><p class="text-gray-300 text-lg mb-6 max-w-3xl">Systematic approach to Spring Boot performance tuning. Covers connection pooling, N+1 query elimination, caching strategies, async processing, and JVM tuning to multiply throughput.</p><div class="flex flex-wrap items-center gap-4 text-gray-400 text-sm"><span class="flex items-center gap-1.5"><svg class="w-4 h-4" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M16 7a4 4 0 11-8 0 4 4 0 018 0zM12 14a7 7 0 00-7 7h14a7 7 0 00-7-7z"></path></svg>Sachin Sarawgi</span><span>¬∑</span><span>March 13, 2025</span><span>¬∑</span><span class="flex items-center gap-1"><svg class="w-4 h-4" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>13 min read</span></div><div class="flex flex-wrap gap-2 mt-4"><span class="text-xs text-gray-400 bg-gray-800 px-2 py-1 rounded">#<!-- -->spring boot</span><span class="text-xs text-gray-400 bg-gray-800 px-2 py-1 rounded">#<!-- -->java</span><span class="text-xs text-gray-400 bg-gray-800 px-2 py-1 rounded">#<!-- -->performance</span><span class="text-xs text-gray-400 bg-gray-800 px-2 py-1 rounded">#<!-- -->hikaricp</span><span class="text-xs text-gray-400 bg-gray-800 px-2 py-1 rounded">#<!-- -->redis</span><span class="text-xs text-gray-400 bg-gray-800 px-2 py-1 rounded">#<!-- -->jpa</span><span class="text-xs text-gray-400 bg-gray-800 px-2 py-1 rounded">#<!-- -->tuning</span></div></div></div><div class="container mx-auto px-4 sm:px-6 lg:px-8 max-w-5xl py-12"><div class="flex gap-12"><div class="flex-1 min-w-0"><article class="prose prose-lg max-w-none prose-headings:text-gray-900 prose-headings:font-bold prose-h2:text-2xl prose-h2:mt-10 prose-h2:mb-4 prose-h3:text-xl prose-h3:mt-8 prose-h3:mb-3 prose-p:text-gray-700 prose-p:leading-relaxed prose-a:text-blue-600 prose-a:no-underline hover:prose-a:underline prose-strong:text-gray-900 prose-blockquote:border-blue-600 prose-blockquote:text-gray-600 prose-code:text-blue-700 prose-code:bg-blue-50 prose-code:px-1.5 prose-code:py-0.5 prose-code:rounded prose-code:text-sm prose-code:before:content-none prose-code:after:content-none prose-pre:rounded-xl prose-img:rounded-xl prose-img:shadow-md prose-table:text-sm prose-th:bg-gray-100 prose-th:text-gray-700"><p>A Spring Boot application that handles 200 RPS on Day 1 often has the same underlying hardware capacity to handle 2000 RPS ‚Äî the gap is how you use it. Most performance bottlenecks in Java web services follow predictable patterns: the database is waiting, threads are blocking, results are recomputed on every request. This guide walks through a systematic process to find and fix each category.</p>
<h2>Step 1: Measure Before Tuning</h2>
<p>The single most important rule: <strong>profile first, optimize second</strong>. Optimizing what you think is slow is almost always wrong.</p>
<p>Before touching a single line of code, you need hard data. The tools below let you generate realistic load and identify exactly where your application spends its time ‚Äî whether that's CPU computation, memory allocation, or waiting on I/O. Think of this step as the doctor ordering tests before prescribing medicine.</p>
<pre><code class="language-bash"># Generate production-like load
# Apache Bench: 10,000 requests, 50 concurrent
ab -n 10000 -c 50 http://localhost:8080/api/orders

# k6: more realistic load simulation
k6 run --vus 50 --duration 60s - &#x3C;&#x3C;'EOF'
import http from 'k6/http';
import { check } from 'k6';

export default function() {
  const res = http.get('http://localhost:8080/api/orders');
  check(res, { 'status is 200': (r) => r.status === 200 });
}
EOF

# JVM metrics: CPU profiling with async-profiler (production-safe)
./profiler.sh -d 30 -e cpu -f cpu_profile.html &#x3C;pid>
# Opens as HTML: shows exact methods consuming CPU

# Memory allocation profiling
./profiler.sh -d 30 -e alloc -f alloc_profile.html &#x3C;pid>
# Shows what code is creating the most garbage
</code></pre>
<p>The <code>async-profiler</code> output will produce a flame graph ‚Äî the widest bars at the top are your real bottlenecks. Run this against your staging environment under load before deciding where to spend your optimization effort.</p>
<h2>Fix 1: Connection Pool Tuning (HikariCP)</h2>
<p>The most common Spring Boot performance problem: too few database connections, or too many.</p>
<p>Your database connection pool is like the number of checkout lanes at a supermarket. Too few lanes and customers queue up. Too many lanes and you waste staff who spend time idle. HikariCP is Spring Boot's default pool, and its defaults are conservative ‚Äî you almost always need to tune it for your workload.</p>
<pre><code class="language-yaml"># application.yml
spring:
  datasource:
    hikari:
      # Formula: (core_count √ó 2) + effective_spindle_count
      # For 8-core server with SSD: (8 √ó 2) + 1 = 17 ‚Üí use 20
      # Counter-intuitive: more than ~20 connections slows things down (DB queuing)
      maximum-pool-size: 20
      minimum-idle: 5
      connection-timeout: 3000        # Fail fast: 3s max wait for connection
      idle-timeout: 600000            # 10 minutes ‚Äî release idle connections
      max-lifetime: 1800000           # 30 minutes ‚Äî recycle connections (avoid stale)
      keepalive-time: 30000           # 30s keepalive pings
      pool-name: OrderServicePool
      # Validate connection before use (PostgreSQL)
      connection-test-query: SELECT 1
</code></pre>
<p>Notice that <code>max-lifetime</code> recycles connections every 30 minutes ‚Äî this prevents stale connections that can silently fail after your database or network firewall drops them. Once you've set the pool size, you need visibility into whether it's working correctly.</p>
<pre><code class="language-java">// Monitor pool health
@Component
public class HikariPoolMonitor {

    @Autowired
    private HikariDataSource dataSource;

    @Scheduled(fixedDelay = 60000)
    public void logPoolStats() {
        HikariPoolMXBean pool = dataSource.getHikariPoolMXBean();
        log.info("Hikari pool - active: {}, idle: {}, waiting: {}, total: {}",
            pool.getActiveConnections(),
            pool.getIdleConnections(),
            pool.getThreadsAwaitingConnection(),
            pool.getTotalConnections());

        // Alert if waiting > 0 consistently (pool starvation)
        if (pool.getThreadsAwaitingConnection() > 5) {
            log.warn("POOL STARVATION: {} threads waiting ‚Äî increase maximum-pool-size",
                pool.getThreadsAwaitingConnection());
        }
    }
}
</code></pre>
<p>The key metric to watch is <code>threadsAwaitingConnection</code> ‚Äî if this is consistently above zero, your pool is too small and requests are queuing. Expose this to your monitoring dashboard so you catch pool starvation before users do.</p>
<h2>Fix 2: Eliminate N+1 Queries</h2>
<p>N+1 is the most common JPA performance killer. One query fetches N entities, then N queries fetch their relationships ‚Äî total: N+1 database round trips.</p>
<p>This is one of those bugs that's invisible in development with small datasets but devastating in production. To understand it, imagine walking into a library and asking for a list of 100 books. The librarian gives you the titles, but then you have to walk back to the desk individually to ask who authored each one ‚Äî 100 extra trips instead of just getting everything upfront.</p>
<pre><code class="language-java">// PROBLEM: N+1 in action
@Entity
public class Order {
    @OneToMany(fetch = FetchType.LAZY)  // Lazy is default and correct
    private List&#x3C;OrderItem> items;

    @ManyToOne(fetch = FetchType.LAZY)
    private Customer customer;
}

@Repository
public interface OrderRepository extends JpaRepository&#x3C;Order, Long> {

    // BAD: This loads N orders, then fires N queries for customer, N for items
    List&#x3C;Order> findByStatus(String status);
}

// In service:
List&#x3C;Order> orders = orderRepo.findByStatus("PENDING");
orders.forEach(o -> {
    log.info("Customer: {}", o.getCustomer().getName()); // N queries
    log.info("Items: {}", o.getItems().size());          // N more queries
});
// Total: 1 + N + N = 201 queries for 100 orders
</code></pre>
<p>The problem above is subtle ‚Äî the code looks innocent, but each property access on a lazy-loaded relationship triggers a separate database round trip. JPA provides three ways to fix this depending on your access pattern.</p>
<pre><code class="language-java">// SOLUTION 1: JOIN FETCH (when you always need the associations)
@Repository
public interface OrderRepository extends JpaRepository&#x3C;Order, Long> {

    @Query("SELECT DISTINCT o FROM Order o " +
           "LEFT JOIN FETCH o.customer " +
           "LEFT JOIN FETCH o.items " +
           "WHERE o.status = :status")
    List&#x3C;Order> findByStatusWithDetails(@Param("status") String status);
    // Total: 1 query
}

// SOLUTION 2: @EntityGraph (cleaner syntax)
@EntityGraph(attributePaths = {"customer", "items"})
List&#x3C;Order> findByStatus(String status);

// SOLUTION 3: Projections (when you only need specific fields ‚Äî fastest)
public interface OrderSummary {
    Long getId();
    String getStatus();
    String getCustomerName();  // Derived from JOIN
}

@Query("SELECT o.id as id, o.status as status, c.name as customerName " +
       "FROM Order o JOIN o.customer c WHERE o.status = :status")
List&#x3C;OrderSummary> findSummaryByStatus(@Param("status") String status);
// Returns a flat projection ‚Äî no entity loading, no lazy initialization
</code></pre>
<p>Projections are often the best solution for list views ‚Äî you skip loading full entity objects entirely and get back only the fields your UI actually needs, which is both faster and lighter on memory. To catch N+1 problems early, add query counting to your development environment.</p>
<pre><code class="language-java">// Detect N+1 in development
// Datasource-proxy: logs every query with stack trace
@Bean
public DataSource dataSource() {
    var realDataSource = actualDataSource();
    return ProxyDataSourceBuilder
        .create(realDataSource)
        .name("DS-Proxy")
        .logQueryBySlf4j(SLF4JLogLevel.DEBUG)
        .countQuery()                   // Count total queries per request
        .build();
}
</code></pre>
<p>With <code>datasource-proxy</code> active, you'll see a total query count logged after every request ‚Äî if a single API call shows 50+ queries, you've found an N+1 problem. This tool pays for itself in the first week.</p>
<h2>Fix 3: Caching with Spring Cache + Redis</h2>
<p>Results that are expensive to compute and change rarely are prime caching candidates.</p>
<p>Caching is the single highest-leverage optimization in most web applications. Think of it like a sticky note on your desk: instead of walking to the file cabinet every time someone asks for the same information, you check the note first. Spring's caching abstraction lets you add this behavior to any method with a single annotation, without changing the method's logic.</p>
<pre><code class="language-java">// Enable Spring Cache
@SpringBootApplication
@EnableCaching
public class Application {}
</code></pre>
<pre><code class="language-yaml">spring:
  cache:
    type: redis
  data:
    redis:
      host: localhost
      port: 6379
      timeout: 200ms
      lettuce:
        pool:
          max-active: 20
          min-idle: 5
</code></pre>
<p>With Redis configured, Spring automatically routes your <code>@Cacheable</code> annotations to store and retrieve from Redis ‚Äî giving you a distributed cache that all your application instances share. Here's how to apply the most common caching patterns to a product service.</p>
<pre><code class="language-java">@Service
public class ProductService {

    // Cache miss: execute method + store result
    // Cache hit: return cached result, skip method
    @Cacheable(
        value = "products",
        key = "#productId",
        condition = "#productId != null",
        unless = "#result == null"  // Don't cache null results
    )
    public Product findById(String productId) {
        return productRepository.findById(productId).orElse(null);
    }

    // Invalidate on update
    @CacheEvict(value = "products", key = "#product.id")
    public Product update(Product product) {
        return productRepository.save(product);
    }

    // Update cache in-place (instead of evict + fetch)
    @CachePut(value = "products", key = "#result.id")
    public Product save(Product product) {
        return productRepository.save(product);
    }

    // Evict entire cache
    @CacheEvict(value = "products", allEntries = true)
    @Scheduled(cron = "0 0 2 * * *")  // Nightly cache clear
    public void clearProductCache() {}
}
</code></pre>
<p>The <code>unless = "#result == null"</code> condition is important ‚Äî without it, cache misses (null results) get stored, and every subsequent request skips the database and returns null even after the product is created. For cases where you need more control than annotations provide, use <code>RedisTemplate</code> directly.</p>
<pre><code class="language-java">// For fine-grained cache control, use RedisTemplate directly
@Service
public class LeaderboardService {

    @Autowired
    private RedisTemplate&#x3C;String, String> redis;

    private static final Duration LEADERBOARD_TTL = Duration.ofMinutes(5);

    public List&#x3C;LeaderboardEntry> getTopUsers(int limit) {
        String key = "leaderboard:top:" + limit;

        // Try cache first
        List&#x3C;String> cached = redis.opsForList().range(key, 0, -1);
        if (cached != null &#x26;&#x26; !cached.isEmpty()) {
            return cached.stream().map(this::deserialize).toList();
        }

        // Cache miss: compute and cache
        List&#x3C;LeaderboardEntry> entries = computeLeaderboard(limit);
        redis.opsForList().rightPushAll(key, entries.stream().map(this::serialize).toList());
        redis.expire(key, LEADERBOARD_TTL);

        return entries;
    }
}
</code></pre>
<p>The leaderboard is a good example of where the annotation-based cache isn't flexible enough ‚Äî you need to store a list and set an explicit TTL based on business logic. With a 5-minute TTL, your leaderboard computation runs at most 12 times per hour instead of thousands of times.</p>
<h2>Fix 4: Async Processing with Virtual Threads (Java 21)</h2>
<p>Blocking I/O (database, HTTP calls) ties up threads. Virtual threads let you run thousands of concurrent I/O operations cheaply.</p>
<p>The traditional thread model is like having a fixed team of workers where each worker can only do one thing at a time ‚Äî if they're waiting on an API response, they're blocked and unavailable for other work. Virtual threads are like workers who can put a task on hold, do something else, and return to it when the response arrives ‚Äî all without creating actual OS threads.</p>
<pre><code class="language-yaml"># Enable virtual threads for Spring MVC (Java 21+)
spring:
  threads:
    virtual:
      enabled: true
# That's it ‚Äî Spring Boot 3.2+ automatically uses virtual threads for Tomcat
# Each request gets its own virtual thread ‚Äî blocking I/O is cheap
</code></pre>
<pre><code class="language-java">// Before virtual threads: thread pool exhaustion
// server.tomcat.max-threads=200 (default)
// At 200 concurrent slow requests ‚Üí all threads blocked ‚Üí new requests queue

// After virtual threads: unlimited concurrency
// Each request has its own virtual thread ‚Äî 10,000 concurrent blocked I/O calls
// cost the same as 200 platform threads

// Async service calls with CompletableFuture
@Service
public class OrderOrchestrationService {

    public OrderSummary getOrderSummary(String orderId) {
        // Fire all fetches concurrently ‚Äî each runs in its own virtual thread
        CompletableFuture&#x3C;Order> orderFuture =
            CompletableFuture.supplyAsync(() -> orderService.findById(orderId));

        CompletableFuture&#x3C;Customer> customerFuture =
            CompletableFuture.supplyAsync(() -> customerService.findById(orderId));

        CompletableFuture&#x3C;List&#x3C;OrderItem>> itemsFuture =
            CompletableFuture.supplyAsync(() -> itemService.findByOrderId(orderId));

        // Wait for all to complete
        CompletableFuture.allOf(orderFuture, customerFuture, itemsFuture).join();

        return buildSummary(orderFuture.join(), customerFuture.join(), itemsFuture.join());
        // Total time: max(order, customer, items) instead of sum
        // If each takes 50ms: 50ms instead of 150ms
    }
}
</code></pre>
<p>The key insight here is the comment at the bottom: instead of paying 150ms for three sequential 50ms calls, you pay only 50ms by running them in parallel. This pattern is especially valuable for dashboard endpoints that aggregate data from multiple sources ‚Äî the user experience improvement is dramatic.</p>
<h2>Fix 5: Efficient Serialization</h2>
<p>ObjectMapper creation is expensive. Reuse it. And choose the right format.</p>
<p>Every time you serialize or deserialize JSON in your application, Jackson uses an <code>ObjectMapper</code>. Creating a new <code>ObjectMapper</code> per request is surprisingly expensive ‚Äî it's like setting up a translation booth from scratch every time someone needs a word translated, rather than keeping a permanent translator on staff. Spring Boot auto-configures one, but customizing it centrally ensures consistent behavior and maximum reuse.</p>
<pre><code class="language-java">@Configuration
public class SerializationConfig {

    @Bean
    @Primary
    public ObjectMapper objectMapper() {
        return JsonMapper.builder()
            // Performance
            .disable(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES)
            .disable(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS)
            .enable(MapperFeature.DEFAULT_VIEW_INCLUSION)
            // Date handling
            .addModule(new JavaTimeModule())
            // Don't serialize null fields (smaller payload)
            .serializationInclusion(JsonInclude.Include.NON_NULL)
            .build();
    }
}

// For internal service-to-service: use MessagePack (binary, 30-50% smaller)
// For high-frequency events: use Avro with schema registry
</code></pre>
<p>The <code>NON_NULL</code> inclusion setting alone can reduce your JSON payload size by 20-40% on entities with optional fields, which directly reduces bandwidth and deserialization time on the client. With serialization handled, you now need to instrument your application so you can see the impact of all these changes in production.</p>
<h2>Production Monitoring Checklist</h2>
<p>Now that you've applied optimizations, you need to know if they're working ‚Äî and catch regressions before users notice. Spring Boot Actuator with Prometheus gives you the metrics backbone to build alerts around the most important performance signals.</p>
<pre><code class="language-yaml">management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics,prometheus
  metrics:
    export:
      prometheus:
        enabled: true
  endpoint:
    health:
      show-details: always

# Key metrics to alert on:
# hikaricp.connections.active > (max_pool * 0.8) ‚Üí pool saturation
# jvm.gc.pause{action="end of major GC"} > 1s ‚Üí GC pressure
# http.server.requests p99 > 2s ‚Üí latency degradation
# http.server.requests error rate > 1% ‚Üí error spike
# system.cpu.usage > 0.8 ‚Üí CPU saturation
</code></pre>
<p>Beyond infrastructure metrics, you want business-level metrics that tie performance directly to outcomes. The following shows how to track order creation latency and volume ‚Äî metrics that let you correlate performance changes with business impact.</p>
<pre><code class="language-java">// Custom business metrics
@Service
public class OrderMetrics {

    private final MeterRegistry registry;

    private final Counter orderCreationTotal;
    private final Timer orderCreationDuration;
    private final Gauge pendingOrdersGauge;

    public OrderMetrics(MeterRegistry registry) {
        this.registry = registry;
        this.orderCreationTotal = Counter.builder("orders.created.total")
            .description("Total orders created")
            .tag("version", "v1")
            .register(registry);

        this.orderCreationDuration = Timer.builder("orders.creation.duration")
            .description("Order creation latency")
            .register(registry);
    }

    public Order createOrder(OrderRequest request) {
        return orderCreationDuration.record(() -> {
            Order order = orderService.create(request);
            orderCreationTotal.increment();
            return order;
        });
    }
}
</code></pre>
<p>Wrapping your business logic in a <code>Timer</code> gives you p50, p95, and p99 latency percentiles automatically ‚Äî this is far more useful than averages because a p99 spike tells you that 1% of your users are having a bad experience even when the average looks fine.</p>
<h2>The Performance Tuning Priority List</h2>
<p>With all the fixes covered, here's how to prioritize your effort. This ordering reflects real-world impact: database problems almost always cost 10x more than JVM tuning, so fix the database layer first.</p>
<pre><code>Impact ‚Üí Fix
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Highest  N+1 queries               ‚Üí @EntityGraph, JOIN FETCH
         Missing database indexes  ‚Üí EXPLAIN ANALYZE + add indexes
         Absent caching            ‚Üí Redis @Cacheable on hot reads
         Small connection pool     ‚Üí Tune HikariCP max-pool-size
         Synchronous fan-out       ‚Üí CompletableFuture.allOf()

Medium   Lazy serialization        ‚Üí Jackson optimization
         Full object load          ‚Üí Projections for list views
         Per-request computation   ‚Üí @Scheduled + cache result

Lower    JVM GC tuning             ‚Üí G1GC MaxGCPauseMillis
         HTTP client timeouts      ‚Üí Prevent thread starvation
         Logging verbosity         ‚Üí INFO in prod, not DEBUG
</code></pre>
<p>Performance optimization is detective work: follow the evidence. Measure, find the bottleneck, fix it, measure again. The common mistakes are optimizing in the wrong layer (tuning JVM when the bottleneck is the database) and premature optimization (spending days on a service that handles 50 RPS). Profile first, fix what the profiler shows, and repeat.</p>
</article><div class="my-10 rounded-xl border border-yellow-200 bg-yellow-50 p-6"><div class="flex items-center gap-2 mb-1"><span class="text-lg">üìö</span><h3 class="text-base font-bold text-gray-900">Recommended Resources</h3></div><div class="space-y-4"><div class="flex items-start gap-3 bg-white rounded-lg p-4 border border-yellow-100"><div class="flex-1 min-w-0"><div class="flex items-center gap-2 flex-wrap mb-1"><span class="font-semibold text-gray-900 text-sm">Java Masterclass ‚Äî Udemy</span><span class="text-xs bg-blue-100 text-blue-700 px-2 py-0.5 rounded-full font-medium">Best Seller</span></div><p class="text-xs text-gray-600">Comprehensive Java course covering Java 17+, OOP, concurrency, and modern APIs.</p></div><a href="https://www.udemy.com/course/java-the-complete-java-developer-course/" target="_blank" rel="noopener noreferrer" class="flex-shrink-0 text-xs bg-blue-600 text-white px-3 py-2 rounded-lg hover:bg-blue-700 transition-colors font-medium whitespace-nowrap">View Course<!-- --> ‚Üí</a></div><div class="flex items-start gap-3 bg-white rounded-lg p-4 border border-yellow-100"><div class="flex-1 min-w-0"><div class="flex items-center gap-2 flex-wrap mb-1"><span class="font-semibold text-gray-900 text-sm">Effective Java, 3rd Edition</span><span class="text-xs bg-blue-100 text-blue-700 px-2 py-0.5 rounded-full font-medium">Must Read</span></div><p class="text-xs text-gray-600">Joshua Bloch&#x27;s classic guide to writing clear, correct, and efficient Java code.</p></div><a href="https://amzn.to/3RxIpuB" target="_blank" rel="noopener noreferrer" class="flex-shrink-0 text-xs bg-blue-600 text-white px-3 py-2 rounded-lg hover:bg-blue-700 transition-colors font-medium whitespace-nowrap">View on Amazon<!-- --> ‚Üí</a></div><div class="flex items-start gap-3 bg-white rounded-lg p-4 border border-yellow-100"><div class="flex-1 min-w-0"><div class="flex items-center gap-2 flex-wrap mb-1"><span class="font-semibold text-gray-900 text-sm">Java Concurrency in Practice</span></div><p class="text-xs text-gray-600">The authoritative book on writing thread-safe, concurrent Java programs.</p></div><a href="https://amzn.to/3Rx3xM4" target="_blank" rel="noopener noreferrer" class="flex-shrink-0 text-xs bg-blue-600 text-white px-3 py-2 rounded-lg hover:bg-blue-700 transition-colors font-medium whitespace-nowrap">View on Amazon<!-- --> ‚Üí</a></div></div></div><div class="mt-10 pt-8 border-t border-gray-100"><p class="text-sm text-gray-500 mb-3">Found this useful? Share it:</p><div class="flex gap-3"><a href="https://twitter.com/intent/tweet?text=Spring%20Boot%20Performance%20Tuning%3A%20From%20200%20to%202000%20RPS&amp;url=https%3A%2F%2Fcodesprintpro.com%2Fblog%2Fspring-boot-performance%2F" target="_blank" rel="noopener noreferrer" class="text-xs bg-gray-900 text-white px-4 py-2 rounded-lg hover:bg-gray-700 transition-colors">Share on X/Twitter</a><a href="https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fcodesprintpro.com%2Fblog%2Fspring-boot-performance%2F" target="_blank" rel="noopener noreferrer" class="text-xs bg-blue-600 text-white px-4 py-2 rounded-lg hover:bg-blue-700 transition-colors">Share on LinkedIn</a></div></div></div><aside class="hidden lg:block w-64 flex-shrink-0"><nav class="hidden lg:block sticky top-24"><h4 class="text-xs font-semibold uppercase tracking-widest text-gray-400 mb-3">On This Page</h4><ul class="space-y-1"><li class=""><a href="#step-1-measure-before-tuning" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Step 1: Measure Before Tuning</a></li><li class=""><a href="#fix-1-connection-pool-tuning-hikaricp" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Fix 1: Connection Pool Tuning (HikariCP)</a></li><li class=""><a href="#fix-2-eliminate-n1-queries" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Fix 2: Eliminate N+1 Queries</a></li><li class=""><a href="#fix-3-caching-with-spring-cache-redis" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Fix 3: Caching with Spring Cache + Redis</a></li><li class=""><a href="#fix-4-async-processing-with-virtual-threads-java-21" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Fix 4: Async Processing with Virtual Threads (Java 21)</a></li><li class=""><a href="#fix-5-efficient-serialization" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Fix 5: Efficient Serialization</a></li><li class=""><a href="#production-monitoring-checklist" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Production Monitoring Checklist</a></li><li class=""><a href="#the-performance-tuning-priority-list" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">The Performance Tuning Priority List</a></li></ul></nav></aside></div><div class="mt-16 pt-10 border-t border-gray-100"><h2 class="text-2xl font-bold text-gray-900 mb-6">Related Articles</h2><div class="grid grid-cols-1 md:grid-cols-3 gap-6"><a href="/blog/java-concurrency-patterns/"><article class="group bg-white rounded-xl border border-gray-200 p-6 h-full cursor-pointer hover:border-blue-300 hover:shadow-lg transition-all"><span class="inline-block text-xs font-semibold px-3 py-1 rounded-full mb-3 bg-orange-100 text-orange-700">Java</span><h3 class="text-lg font-bold text-gray-900 mb-2 group-hover:text-blue-600 transition-colors leading-snug">Java Concurrency Patterns: CompletableFuture, Structured Concurrency, and Thread-Safe Design</h3><p class="text-gray-600 text-sm mb-4 line-clamp-3">Java concurrency has three eras: raw  and  (Java 1-4), the  framework (Java 5+), and the virtual thread/structured concurrency era (Java 21+). Each era&#x27;s patterns still exist in production codebases. Understanding all th‚Ä¶</p><div class="flex items-center justify-between text-xs text-gray-400"><span>Jul 8, 2025</span><span class="flex items-center gap-1"><svg class="w-3 h-3" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>7 min read</span></div><div class="mt-3 flex flex-wrap gap-1"><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->java</span><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->concurrency</span><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->completablefuture</span></div></article></a><a href="/blog/java-memory-management-deep-dive/"><article class="group bg-white rounded-xl border border-gray-200 p-6 h-full cursor-pointer hover:border-blue-300 hover:shadow-lg transition-all"><span class="inline-block text-xs font-semibold px-3 py-1 rounded-full mb-3 bg-orange-100 text-orange-700">Java</span><h3 class="text-lg font-bold text-gray-900 mb-2 group-hover:text-blue-600 transition-colors leading-snug">Java Memory Management Deep Dive: Heap, GC, and Production Tuning</h3><p class="text-gray-600 text-sm mb-4 line-clamp-3">Java&#x27;s garbage collector is the single biggest source of unexplained latency spikes in production services. A GC pause of 2 seconds is invisible in most logs but visible to every user who happened to make a request durin‚Ä¶</p><div class="flex items-center justify-between text-xs text-gray-400"><span>Jun 13, 2025</span><span class="flex items-center gap-1"><svg class="w-3 h-3" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>7 min read</span></div><div class="mt-3 flex flex-wrap gap-1"><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->java</span><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->jvm</span><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->garbage collection</span></div></article></a><a href="/blog/spring-security-oauth2-jwt/"><article class="group bg-white rounded-xl border border-gray-200 p-6 h-full cursor-pointer hover:border-blue-300 hover:shadow-lg transition-all"><span class="inline-block text-xs font-semibold px-3 py-1 rounded-full mb-3 bg-orange-100 text-orange-700">Java</span><h3 class="text-lg font-bold text-gray-900 mb-2 group-hover:text-blue-600 transition-colors leading-snug">Spring Security OAuth2 and JWT: Production Implementation Guide</h3><p class="text-gray-600 text-sm mb-4 line-clamp-3">Spring Security is one of the most powerful and most misunderstood frameworks in the Java ecosystem. Its flexibility is its strength ‚Äî and its complexity. Misconfigured security is worse than no security, because it give‚Ä¶</p><div class="flex items-center justify-between text-xs text-gray-400"><span>Jun 3, 2025</span><span class="flex items-center gap-1"><svg class="w-3 h-3" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>7 min read</span></div><div class="mt-3 flex flex-wrap gap-1"><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->spring security</span><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->oauth2</span><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->jwt</span></div></article></a></div></div><div class="mt-12 text-center"><a class="inline-flex items-center gap-2 text-blue-600 hover:text-blue-700 font-medium transition-colors" href="/blog/">‚Üê Back to all articles</a></div></div></div><footer class="bg-gray-900 text-white py-12"><div class="container mx-auto px-4 sm:px-6 lg:px-8"><div class="grid grid-cols-1 md:grid-cols-4 gap-8 mb-8"><div class="col-span-1 md:col-span-1"><div><a class="text-xl font-bold block mb-3 text-white hover:text-blue-400 transition-colors" href="/">CodeSprintPro</a></div><p class="text-gray-400 text-sm mb-4 leading-relaxed">Deep-dive technical content on System Design, Java, Databases, AI/ML, and AWS ‚Äî by Sachin Sarawgi.</p><div class="flex space-x-4"><a href="https://github.com/codesprintpro" target="_blank" rel="noopener noreferrer" class="text-gray-400 hover:text-white transition-colors" aria-label="Visit GitHub profile"><i class="fab fa-github text-xl"></i></a><a href="https://www.linkedin.com/in/sachin-sarawgi/" target="_blank" rel="noopener noreferrer" class="text-gray-400 hover:text-white transition-colors" aria-label="Visit LinkedIn profile"><i class="fab fa-linkedin text-xl"></i></a><a href="https://medium.com/@codesprintpro" target="_blank" rel="noopener noreferrer" class="text-gray-400 hover:text-white transition-colors" aria-label="Visit Medium profile"><i class="fab fa-medium text-xl"></i></a></div></div><div><h3 class="text-sm font-semibold uppercase tracking-widest text-gray-400 mb-4">Quick Links</h3><ul class="space-y-2"><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">Blog</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/#about">About</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/#portfolio">Portfolio</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/#contact">Contact</a></div></li></ul></div><div><h3 class="text-sm font-semibold uppercase tracking-widest text-gray-400 mb-4">Categories</h3><ul class="space-y-2"><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">System Design</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">Java</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">Databases</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">AI/ML</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">AWS</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">Messaging</a></div></li></ul></div><div><h3 class="text-sm font-semibold uppercase tracking-widest text-gray-400 mb-4">Contact</h3><ul class="space-y-2 text-gray-400 text-sm"><li><a href="mailto:sachinsarawgi201143@gmail.com" class="hover:text-white transition-colors flex items-center gap-2"><i class="fas fa-envelope"></i> Email</a></li><li><a href="https://www.linkedin.com/in/sachin-sarawgi/" target="_blank" rel="noopener noreferrer" class="hover:text-white transition-colors flex items-center gap-2"><i class="fab fa-linkedin"></i> LinkedIn</a></li><li><a href="https://github.com/codesprintpro" target="_blank" rel="noopener noreferrer" class="hover:text-white transition-colors flex items-center gap-2"><i class="fab fa-github"></i> GitHub</a></li></ul></div></div><div class="border-t border-gray-800 pt-6 flex flex-col md:flex-row justify-between items-center gap-2"><p class="text-gray-500 text-sm">¬© <!-- -->2026<!-- --> CodeSprintPro ¬∑ Sachin Sarawgi. All rights reserved.</p><p class="text-gray-600 text-xs">Built with Next.js ¬∑ TailwindCSS ¬∑ Deployed on GitHub Pages</p></div></div></footer></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"Spring Boot Performance Tuning: From 200 to 2000 RPS","description":"Systematic approach to Spring Boot performance tuning. Covers connection pooling, N+1 query elimination, caching strategies, async processing, and JVM tuning to multiply throughput.","date":"2025-03-13","category":"Java","tags":["spring boot","java","performance","hikaricp","redis","jpa","tuning"],"featured":false,"affiliateSection":"java-courses","slug":"spring-boot-performance","readingTime":"13 min read","excerpt":"A Spring Boot application that handles 200 RPS on Day 1 often has the same underlying hardware capacity to handle 2000 RPS ‚Äî the gap is how you use it. Most performance bottlenecks in Java web services follow predictable‚Ä¶","contentHtml":"\u003cp\u003eA Spring Boot application that handles 200 RPS on Day 1 often has the same underlying hardware capacity to handle 2000 RPS ‚Äî the gap is how you use it. Most performance bottlenecks in Java web services follow predictable patterns: the database is waiting, threads are blocking, results are recomputed on every request. This guide walks through a systematic process to find and fix each category.\u003c/p\u003e\n\u003ch2\u003eStep 1: Measure Before Tuning\u003c/h2\u003e\n\u003cp\u003eThe single most important rule: \u003cstrong\u003eprofile first, optimize second\u003c/strong\u003e. Optimizing what you think is slow is almost always wrong.\u003c/p\u003e\n\u003cp\u003eBefore touching a single line of code, you need hard data. The tools below let you generate realistic load and identify exactly where your application spends its time ‚Äî whether that's CPU computation, memory allocation, or waiting on I/O. Think of this step as the doctor ordering tests before prescribing medicine.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e# Generate production-like load\n# Apache Bench: 10,000 requests, 50 concurrent\nab -n 10000 -c 50 http://localhost:8080/api/orders\n\n# k6: more realistic load simulation\nk6 run --vus 50 --duration 60s - \u0026#x3C;\u0026#x3C;'EOF'\nimport http from 'k6/http';\nimport { check } from 'k6';\n\nexport default function() {\n  const res = http.get('http://localhost:8080/api/orders');\n  check(res, { 'status is 200': (r) =\u003e r.status === 200 });\n}\nEOF\n\n# JVM metrics: CPU profiling with async-profiler (production-safe)\n./profiler.sh -d 30 -e cpu -f cpu_profile.html \u0026#x3C;pid\u003e\n# Opens as HTML: shows exact methods consuming CPU\n\n# Memory allocation profiling\n./profiler.sh -d 30 -e alloc -f alloc_profile.html \u0026#x3C;pid\u003e\n# Shows what code is creating the most garbage\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe \u003ccode\u003easync-profiler\u003c/code\u003e output will produce a flame graph ‚Äî the widest bars at the top are your real bottlenecks. Run this against your staging environment under load before deciding where to spend your optimization effort.\u003c/p\u003e\n\u003ch2\u003eFix 1: Connection Pool Tuning (HikariCP)\u003c/h2\u003e\n\u003cp\u003eThe most common Spring Boot performance problem: too few database connections, or too many.\u003c/p\u003e\n\u003cp\u003eYour database connection pool is like the number of checkout lanes at a supermarket. Too few lanes and customers queue up. Too many lanes and you waste staff who spend time idle. HikariCP is Spring Boot's default pool, and its defaults are conservative ‚Äî you almost always need to tune it for your workload.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-yaml\"\u003e# application.yml\nspring:\n  datasource:\n    hikari:\n      # Formula: (core_count √ó 2) + effective_spindle_count\n      # For 8-core server with SSD: (8 √ó 2) + 1 = 17 ‚Üí use 20\n      # Counter-intuitive: more than ~20 connections slows things down (DB queuing)\n      maximum-pool-size: 20\n      minimum-idle: 5\n      connection-timeout: 3000        # Fail fast: 3s max wait for connection\n      idle-timeout: 600000            # 10 minutes ‚Äî release idle connections\n      max-lifetime: 1800000           # 30 minutes ‚Äî recycle connections (avoid stale)\n      keepalive-time: 30000           # 30s keepalive pings\n      pool-name: OrderServicePool\n      # Validate connection before use (PostgreSQL)\n      connection-test-query: SELECT 1\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNotice that \u003ccode\u003emax-lifetime\u003c/code\u003e recycles connections every 30 minutes ‚Äî this prevents stale connections that can silently fail after your database or network firewall drops them. Once you've set the pool size, you need visibility into whether it's working correctly.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003e// Monitor pool health\n@Component\npublic class HikariPoolMonitor {\n\n    @Autowired\n    private HikariDataSource dataSource;\n\n    @Scheduled(fixedDelay = 60000)\n    public void logPoolStats() {\n        HikariPoolMXBean pool = dataSource.getHikariPoolMXBean();\n        log.info(\"Hikari pool - active: {}, idle: {}, waiting: {}, total: {}\",\n            pool.getActiveConnections(),\n            pool.getIdleConnections(),\n            pool.getThreadsAwaitingConnection(),\n            pool.getTotalConnections());\n\n        // Alert if waiting \u003e 0 consistently (pool starvation)\n        if (pool.getThreadsAwaitingConnection() \u003e 5) {\n            log.warn(\"POOL STARVATION: {} threads waiting ‚Äî increase maximum-pool-size\",\n                pool.getThreadsAwaitingConnection());\n        }\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe key metric to watch is \u003ccode\u003ethreadsAwaitingConnection\u003c/code\u003e ‚Äî if this is consistently above zero, your pool is too small and requests are queuing. Expose this to your monitoring dashboard so you catch pool starvation before users do.\u003c/p\u003e\n\u003ch2\u003eFix 2: Eliminate N+1 Queries\u003c/h2\u003e\n\u003cp\u003eN+1 is the most common JPA performance killer. One query fetches N entities, then N queries fetch their relationships ‚Äî total: N+1 database round trips.\u003c/p\u003e\n\u003cp\u003eThis is one of those bugs that's invisible in development with small datasets but devastating in production. To understand it, imagine walking into a library and asking for a list of 100 books. The librarian gives you the titles, but then you have to walk back to the desk individually to ask who authored each one ‚Äî 100 extra trips instead of just getting everything upfront.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003e// PROBLEM: N+1 in action\n@Entity\npublic class Order {\n    @OneToMany(fetch = FetchType.LAZY)  // Lazy is default and correct\n    private List\u0026#x3C;OrderItem\u003e items;\n\n    @ManyToOne(fetch = FetchType.LAZY)\n    private Customer customer;\n}\n\n@Repository\npublic interface OrderRepository extends JpaRepository\u0026#x3C;Order, Long\u003e {\n\n    // BAD: This loads N orders, then fires N queries for customer, N for items\n    List\u0026#x3C;Order\u003e findByStatus(String status);\n}\n\n// In service:\nList\u0026#x3C;Order\u003e orders = orderRepo.findByStatus(\"PENDING\");\norders.forEach(o -\u003e {\n    log.info(\"Customer: {}\", o.getCustomer().getName()); // N queries\n    log.info(\"Items: {}\", o.getItems().size());          // N more queries\n});\n// Total: 1 + N + N = 201 queries for 100 orders\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe problem above is subtle ‚Äî the code looks innocent, but each property access on a lazy-loaded relationship triggers a separate database round trip. JPA provides three ways to fix this depending on your access pattern.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003e// SOLUTION 1: JOIN FETCH (when you always need the associations)\n@Repository\npublic interface OrderRepository extends JpaRepository\u0026#x3C;Order, Long\u003e {\n\n    @Query(\"SELECT DISTINCT o FROM Order o \" +\n           \"LEFT JOIN FETCH o.customer \" +\n           \"LEFT JOIN FETCH o.items \" +\n           \"WHERE o.status = :status\")\n    List\u0026#x3C;Order\u003e findByStatusWithDetails(@Param(\"status\") String status);\n    // Total: 1 query\n}\n\n// SOLUTION 2: @EntityGraph (cleaner syntax)\n@EntityGraph(attributePaths = {\"customer\", \"items\"})\nList\u0026#x3C;Order\u003e findByStatus(String status);\n\n// SOLUTION 3: Projections (when you only need specific fields ‚Äî fastest)\npublic interface OrderSummary {\n    Long getId();\n    String getStatus();\n    String getCustomerName();  // Derived from JOIN\n}\n\n@Query(\"SELECT o.id as id, o.status as status, c.name as customerName \" +\n       \"FROM Order o JOIN o.customer c WHERE o.status = :status\")\nList\u0026#x3C;OrderSummary\u003e findSummaryByStatus(@Param(\"status\") String status);\n// Returns a flat projection ‚Äî no entity loading, no lazy initialization\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eProjections are often the best solution for list views ‚Äî you skip loading full entity objects entirely and get back only the fields your UI actually needs, which is both faster and lighter on memory. To catch N+1 problems early, add query counting to your development environment.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003e// Detect N+1 in development\n// Datasource-proxy: logs every query with stack trace\n@Bean\npublic DataSource dataSource() {\n    var realDataSource = actualDataSource();\n    return ProxyDataSourceBuilder\n        .create(realDataSource)\n        .name(\"DS-Proxy\")\n        .logQueryBySlf4j(SLF4JLogLevel.DEBUG)\n        .countQuery()                   // Count total queries per request\n        .build();\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWith \u003ccode\u003edatasource-proxy\u003c/code\u003e active, you'll see a total query count logged after every request ‚Äî if a single API call shows 50+ queries, you've found an N+1 problem. This tool pays for itself in the first week.\u003c/p\u003e\n\u003ch2\u003eFix 3: Caching with Spring Cache + Redis\u003c/h2\u003e\n\u003cp\u003eResults that are expensive to compute and change rarely are prime caching candidates.\u003c/p\u003e\n\u003cp\u003eCaching is the single highest-leverage optimization in most web applications. Think of it like a sticky note on your desk: instead of walking to the file cabinet every time someone asks for the same information, you check the note first. Spring's caching abstraction lets you add this behavior to any method with a single annotation, without changing the method's logic.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003e// Enable Spring Cache\n@SpringBootApplication\n@EnableCaching\npublic class Application {}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"language-yaml\"\u003espring:\n  cache:\n    type: redis\n  data:\n    redis:\n      host: localhost\n      port: 6379\n      timeout: 200ms\n      lettuce:\n        pool:\n          max-active: 20\n          min-idle: 5\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWith Redis configured, Spring automatically routes your \u003ccode\u003e@Cacheable\u003c/code\u003e annotations to store and retrieve from Redis ‚Äî giving you a distributed cache that all your application instances share. Here's how to apply the most common caching patterns to a product service.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003e@Service\npublic class ProductService {\n\n    // Cache miss: execute method + store result\n    // Cache hit: return cached result, skip method\n    @Cacheable(\n        value = \"products\",\n        key = \"#productId\",\n        condition = \"#productId != null\",\n        unless = \"#result == null\"  // Don't cache null results\n    )\n    public Product findById(String productId) {\n        return productRepository.findById(productId).orElse(null);\n    }\n\n    // Invalidate on update\n    @CacheEvict(value = \"products\", key = \"#product.id\")\n    public Product update(Product product) {\n        return productRepository.save(product);\n    }\n\n    // Update cache in-place (instead of evict + fetch)\n    @CachePut(value = \"products\", key = \"#result.id\")\n    public Product save(Product product) {\n        return productRepository.save(product);\n    }\n\n    // Evict entire cache\n    @CacheEvict(value = \"products\", allEntries = true)\n    @Scheduled(cron = \"0 0 2 * * *\")  // Nightly cache clear\n    public void clearProductCache() {}\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe \u003ccode\u003eunless = \"#result == null\"\u003c/code\u003e condition is important ‚Äî without it, cache misses (null results) get stored, and every subsequent request skips the database and returns null even after the product is created. For cases where you need more control than annotations provide, use \u003ccode\u003eRedisTemplate\u003c/code\u003e directly.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003e// For fine-grained cache control, use RedisTemplate directly\n@Service\npublic class LeaderboardService {\n\n    @Autowired\n    private RedisTemplate\u0026#x3C;String, String\u003e redis;\n\n    private static final Duration LEADERBOARD_TTL = Duration.ofMinutes(5);\n\n    public List\u0026#x3C;LeaderboardEntry\u003e getTopUsers(int limit) {\n        String key = \"leaderboard:top:\" + limit;\n\n        // Try cache first\n        List\u0026#x3C;String\u003e cached = redis.opsForList().range(key, 0, -1);\n        if (cached != null \u0026#x26;\u0026#x26; !cached.isEmpty()) {\n            return cached.stream().map(this::deserialize).toList();\n        }\n\n        // Cache miss: compute and cache\n        List\u0026#x3C;LeaderboardEntry\u003e entries = computeLeaderboard(limit);\n        redis.opsForList().rightPushAll(key, entries.stream().map(this::serialize).toList());\n        redis.expire(key, LEADERBOARD_TTL);\n\n        return entries;\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe leaderboard is a good example of where the annotation-based cache isn't flexible enough ‚Äî you need to store a list and set an explicit TTL based on business logic. With a 5-minute TTL, your leaderboard computation runs at most 12 times per hour instead of thousands of times.\u003c/p\u003e\n\u003ch2\u003eFix 4: Async Processing with Virtual Threads (Java 21)\u003c/h2\u003e\n\u003cp\u003eBlocking I/O (database, HTTP calls) ties up threads. Virtual threads let you run thousands of concurrent I/O operations cheaply.\u003c/p\u003e\n\u003cp\u003eThe traditional thread model is like having a fixed team of workers where each worker can only do one thing at a time ‚Äî if they're waiting on an API response, they're blocked and unavailable for other work. Virtual threads are like workers who can put a task on hold, do something else, and return to it when the response arrives ‚Äî all without creating actual OS threads.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-yaml\"\u003e# Enable virtual threads for Spring MVC (Java 21+)\nspring:\n  threads:\n    virtual:\n      enabled: true\n# That's it ‚Äî Spring Boot 3.2+ automatically uses virtual threads for Tomcat\n# Each request gets its own virtual thread ‚Äî blocking I/O is cheap\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003e// Before virtual threads: thread pool exhaustion\n// server.tomcat.max-threads=200 (default)\n// At 200 concurrent slow requests ‚Üí all threads blocked ‚Üí new requests queue\n\n// After virtual threads: unlimited concurrency\n// Each request has its own virtual thread ‚Äî 10,000 concurrent blocked I/O calls\n// cost the same as 200 platform threads\n\n// Async service calls with CompletableFuture\n@Service\npublic class OrderOrchestrationService {\n\n    public OrderSummary getOrderSummary(String orderId) {\n        // Fire all fetches concurrently ‚Äî each runs in its own virtual thread\n        CompletableFuture\u0026#x3C;Order\u003e orderFuture =\n            CompletableFuture.supplyAsync(() -\u003e orderService.findById(orderId));\n\n        CompletableFuture\u0026#x3C;Customer\u003e customerFuture =\n            CompletableFuture.supplyAsync(() -\u003e customerService.findById(orderId));\n\n        CompletableFuture\u0026#x3C;List\u0026#x3C;OrderItem\u003e\u003e itemsFuture =\n            CompletableFuture.supplyAsync(() -\u003e itemService.findByOrderId(orderId));\n\n        // Wait for all to complete\n        CompletableFuture.allOf(orderFuture, customerFuture, itemsFuture).join();\n\n        return buildSummary(orderFuture.join(), customerFuture.join(), itemsFuture.join());\n        // Total time: max(order, customer, items) instead of sum\n        // If each takes 50ms: 50ms instead of 150ms\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe key insight here is the comment at the bottom: instead of paying 150ms for three sequential 50ms calls, you pay only 50ms by running them in parallel. This pattern is especially valuable for dashboard endpoints that aggregate data from multiple sources ‚Äî the user experience improvement is dramatic.\u003c/p\u003e\n\u003ch2\u003eFix 5: Efficient Serialization\u003c/h2\u003e\n\u003cp\u003eObjectMapper creation is expensive. Reuse it. And choose the right format.\u003c/p\u003e\n\u003cp\u003eEvery time you serialize or deserialize JSON in your application, Jackson uses an \u003ccode\u003eObjectMapper\u003c/code\u003e. Creating a new \u003ccode\u003eObjectMapper\u003c/code\u003e per request is surprisingly expensive ‚Äî it's like setting up a translation booth from scratch every time someone needs a word translated, rather than keeping a permanent translator on staff. Spring Boot auto-configures one, but customizing it centrally ensures consistent behavior and maximum reuse.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003e@Configuration\npublic class SerializationConfig {\n\n    @Bean\n    @Primary\n    public ObjectMapper objectMapper() {\n        return JsonMapper.builder()\n            // Performance\n            .disable(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES)\n            .disable(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS)\n            .enable(MapperFeature.DEFAULT_VIEW_INCLUSION)\n            // Date handling\n            .addModule(new JavaTimeModule())\n            // Don't serialize null fields (smaller payload)\n            .serializationInclusion(JsonInclude.Include.NON_NULL)\n            .build();\n    }\n}\n\n// For internal service-to-service: use MessagePack (binary, 30-50% smaller)\n// For high-frequency events: use Avro with schema registry\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe \u003ccode\u003eNON_NULL\u003c/code\u003e inclusion setting alone can reduce your JSON payload size by 20-40% on entities with optional fields, which directly reduces bandwidth and deserialization time on the client. With serialization handled, you now need to instrument your application so you can see the impact of all these changes in production.\u003c/p\u003e\n\u003ch2\u003eProduction Monitoring Checklist\u003c/h2\u003e\n\u003cp\u003eNow that you've applied optimizations, you need to know if they're working ‚Äî and catch regressions before users notice. Spring Boot Actuator with Prometheus gives you the metrics backbone to build alerts around the most important performance signals.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-yaml\"\u003emanagement:\n  endpoints:\n    web:\n      exposure:\n        include: health,info,metrics,prometheus\n  metrics:\n    export:\n      prometheus:\n        enabled: true\n  endpoint:\n    health:\n      show-details: always\n\n# Key metrics to alert on:\n# hikaricp.connections.active \u003e (max_pool * 0.8) ‚Üí pool saturation\n# jvm.gc.pause{action=\"end of major GC\"} \u003e 1s ‚Üí GC pressure\n# http.server.requests p99 \u003e 2s ‚Üí latency degradation\n# http.server.requests error rate \u003e 1% ‚Üí error spike\n# system.cpu.usage \u003e 0.8 ‚Üí CPU saturation\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eBeyond infrastructure metrics, you want business-level metrics that tie performance directly to outcomes. The following shows how to track order creation latency and volume ‚Äî metrics that let you correlate performance changes with business impact.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003e// Custom business metrics\n@Service\npublic class OrderMetrics {\n\n    private final MeterRegistry registry;\n\n    private final Counter orderCreationTotal;\n    private final Timer orderCreationDuration;\n    private final Gauge pendingOrdersGauge;\n\n    public OrderMetrics(MeterRegistry registry) {\n        this.registry = registry;\n        this.orderCreationTotal = Counter.builder(\"orders.created.total\")\n            .description(\"Total orders created\")\n            .tag(\"version\", \"v1\")\n            .register(registry);\n\n        this.orderCreationDuration = Timer.builder(\"orders.creation.duration\")\n            .description(\"Order creation latency\")\n            .register(registry);\n    }\n\n    public Order createOrder(OrderRequest request) {\n        return orderCreationDuration.record(() -\u003e {\n            Order order = orderService.create(request);\n            orderCreationTotal.increment();\n            return order;\n        });\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWrapping your business logic in a \u003ccode\u003eTimer\u003c/code\u003e gives you p50, p95, and p99 latency percentiles automatically ‚Äî this is far more useful than averages because a p99 spike tells you that 1% of your users are having a bad experience even when the average looks fine.\u003c/p\u003e\n\u003ch2\u003eThe Performance Tuning Priority List\u003c/h2\u003e\n\u003cp\u003eWith all the fixes covered, here's how to prioritize your effort. This ordering reflects real-world impact: database problems almost always cost 10x more than JVM tuning, so fix the database layer first.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eImpact ‚Üí Fix\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nHighest  N+1 queries               ‚Üí @EntityGraph, JOIN FETCH\n         Missing database indexes  ‚Üí EXPLAIN ANALYZE + add indexes\n         Absent caching            ‚Üí Redis @Cacheable on hot reads\n         Small connection pool     ‚Üí Tune HikariCP max-pool-size\n         Synchronous fan-out       ‚Üí CompletableFuture.allOf()\n\nMedium   Lazy serialization        ‚Üí Jackson optimization\n         Full object load          ‚Üí Projections for list views\n         Per-request computation   ‚Üí @Scheduled + cache result\n\nLower    JVM GC tuning             ‚Üí G1GC MaxGCPauseMillis\n         HTTP client timeouts      ‚Üí Prevent thread starvation\n         Logging verbosity         ‚Üí INFO in prod, not DEBUG\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003ePerformance optimization is detective work: follow the evidence. Measure, find the bottleneck, fix it, measure again. The common mistakes are optimizing in the wrong layer (tuning JVM when the bottleneck is the database) and premature optimization (spending days on a service that handles 50 RPS). Profile first, fix what the profiler shows, and repeat.\u003c/p\u003e\n","tableOfContents":[{"id":"step-1-measure-before-tuning","text":"Step 1: Measure Before Tuning","level":2},{"id":"fix-1-connection-pool-tuning-hikaricp","text":"Fix 1: Connection Pool Tuning (HikariCP)","level":2},{"id":"fix-2-eliminate-n1-queries","text":"Fix 2: Eliminate N+1 Queries","level":2},{"id":"fix-3-caching-with-spring-cache-redis","text":"Fix 3: Caching with Spring Cache + Redis","level":2},{"id":"fix-4-async-processing-with-virtual-threads-java-21","text":"Fix 4: Async Processing with Virtual Threads (Java 21)","level":2},{"id":"fix-5-efficient-serialization","text":"Fix 5: Efficient Serialization","level":2},{"id":"production-monitoring-checklist","text":"Production Monitoring Checklist","level":2},{"id":"the-performance-tuning-priority-list","text":"The Performance Tuning Priority List","level":2}]},"relatedPosts":[{"title":"Java Concurrency Patterns: CompletableFuture, Structured Concurrency, and Thread-Safe Design","description":"Production Java concurrency: CompletableFuture pipelines, handling exceptions in async chains, Java 21 structured concurrency, thread-safe collection patterns, and the concurrency bugs that cause data corruption.","date":"2025-07-08","category":"Java","tags":["java","concurrency","completablefuture","virtual threads","java21","thread-safe","async"],"featured":false,"affiliateSection":"java-courses","slug":"java-concurrency-patterns","readingTime":"7 min read","excerpt":"Java concurrency has three eras: raw  and  (Java 1-4), the  framework (Java 5+), and the virtual thread/structured concurrency era (Java 21+). Each era's patterns still exist in production codebases. Understanding all th‚Ä¶"},{"title":"Java Memory Management Deep Dive: Heap, GC, and Production Tuning","description":"How the JVM allocates memory, how G1GC and ZGC work under the hood, heap analysis with JVM tools, and the GC tuning decisions that eliminate latency spikes in production Java services.","date":"2025-06-13","category":"Java","tags":["java","jvm","garbage collection","g1gc","zgc","heap","memory management","performance"],"featured":false,"affiliateSection":"java-courses","slug":"java-memory-management-deep-dive","readingTime":"7 min read","excerpt":"Java's garbage collector is the single biggest source of unexplained latency spikes in production services. A GC pause of 2 seconds is invisible in most logs but visible to every user who happened to make a request durin‚Ä¶"},{"title":"Spring Security OAuth2 and JWT: Production Implementation Guide","description":"Complete Spring Security OAuth2 implementation: JWT token validation, Resource Server configuration, method-level security, custom UserDetailsService, refresh token rotation, and the security pitfalls that lead to authentication bypasses.","date":"2025-06-03","category":"Java","tags":["spring security","oauth2","jwt","spring boot","authentication","authorization","java","security"],"featured":false,"affiliateSection":"java-courses","slug":"spring-security-oauth2-jwt","readingTime":"7 min read","excerpt":"Spring Security is one of the most powerful and most misunderstood frameworks in the Java ecosystem. Its flexibility is its strength ‚Äî and its complexity. Misconfigured security is worse than no security, because it give‚Ä¶"}]},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"spring-boot-performance"},"buildId":"rpFn_jslWZ9qPkJwor7RD","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>