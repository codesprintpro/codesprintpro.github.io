<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8" data-next-head=""/><meta name="viewport" content="width=device-width" data-next-head=""/><title data-next-head="">Kafka Exactly-Once Semantics: Myth vs Production Reality<!-- --> | CodeSprintPro</title><meta name="description" content="What Kafka&#x27;s exactly-once guarantee actually covers, where duplicates still happen in practice, and how to design genuinely idempotent consumers with Spring Kafka. Real production mistakes and their fixes." data-next-head=""/><meta name="author" content="Sachin Sarawgi" data-next-head=""/><link rel="canonical" href="https://codesprintpro.com/blog/kafka-exactly-once-semantics/" data-next-head=""/><meta property="og:type" content="article" data-next-head=""/><meta property="og:title" content="Kafka Exactly-Once Semantics: Myth vs Production Reality" data-next-head=""/><meta property="og:description" content="What Kafka&#x27;s exactly-once guarantee actually covers, where duplicates still happen in practice, and how to design genuinely idempotent consumers with Spring Kafka. Real production mistakes and their fixes." data-next-head=""/><meta property="og:url" content="https://codesprintpro.com/blog/kafka-exactly-once-semantics/" data-next-head=""/><meta property="og:image" content="https://codesprintpro.com/images/og-default.jpg" data-next-head=""/><meta property="og:site_name" content="CodeSprintPro" data-next-head=""/><meta property="article:published_time" content="2025-04-20" data-next-head=""/><meta property="article:author" content="Sachin Sarawgi" data-next-head=""/><meta property="article:section" content="Messaging" data-next-head=""/><meta property="article:tag" content="kafka" data-next-head=""/><meta property="article:tag" content="exactly-once" data-next-head=""/><meta property="article:tag" content="spring kafka" data-next-head=""/><meta property="article:tag" content="distributed systems" data-next-head=""/><meta property="article:tag" content="transactions" data-next-head=""/><meta property="article:tag" content="java" data-next-head=""/><meta name="twitter:card" content="summary_large_image" data-next-head=""/><meta name="twitter:title" content="Kafka Exactly-Once Semantics: Myth vs Production Reality" data-next-head=""/><meta name="twitter:description" content="What Kafka&#x27;s exactly-once guarantee actually covers, where duplicates still happen in practice, and how to design genuinely idempotent consumers with Spring Kafka. Real production mistakes and their fixes." data-next-head=""/><meta name="twitter:image" content="https://codesprintpro.com/images/og-default.jpg" data-next-head=""/><script type="application/ld+json" data-next-head="">{"@context":"https://schema.org","@type":"BlogPosting","headline":"Kafka Exactly-Once Semantics: Myth vs Production Reality","description":"What Kafka's exactly-once guarantee actually covers, where duplicates still happen in practice, and how to design genuinely idempotent consumers with Spring Kafka. Real production mistakes and their fixes.","image":"https://codesprintpro.com/images/og-default.jpg","datePublished":"2025-04-20","dateModified":"2025-04-20","author":{"@type":"Person","name":"Sachin Sarawgi","url":"https://codesprintpro.com","sameAs":["https://www.linkedin.com/in/sachin-sarawgi/","https://github.com/codesprintpro","https://medium.com/@codesprintpro"]},"publisher":{"@type":"Organization","name":"CodeSprintPro","url":"https://codesprintpro.com","logo":{"@type":"ImageObject","url":"https://codesprintpro.com/favicon/favicon-96x96.png"}},"mainEntityOfPage":{"@type":"WebPage","@id":"https://codesprintpro.com/blog/kafka-exactly-once-semantics/"},"keywords":"kafka, exactly-once, spring kafka, distributed systems, transactions, java","articleSection":"Messaging"}</script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" integrity="sha512-9usAa10IRO0HhonpyAIVpjrylPvoDwiPUiKdWk5t3PyolY1cOd4DSE0Ga+ri4AuTroPR5aQvXU9xC6qOPnzFeg==" crossorigin="anonymous" referrerPolicy="no-referrer"/><script async="" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-XXXXXXXXXXXXXXXX" crossorigin="anonymous"></script><link rel="preload" href="/_next/static/media/e4af272ccee01ff0-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/css/735d4373f93910ca.css" as="style"/><link rel="stylesheet" href="/_next/static/css/735d4373f93910ca.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-11a4a2dad04962bb.js" defer=""></script><script src="/_next/static/chunks/framework-1ce91eb6f9ecda85.js" defer=""></script><script src="/_next/static/chunks/main-c7f4109f032d7b6e.js" defer=""></script><script src="/_next/static/chunks/pages/_app-1a852bd9e38c70ab.js" defer=""></script><script src="/_next/static/chunks/730-db7827467817f501.js" defer=""></script><script src="/_next/static/chunks/90-1cd4611704c3dbe0.js" defer=""></script><script src="/_next/static/chunks/440-29f4b99a44e744b5.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-0c1b14a33d5e05ee.js" defer=""></script><script src="/_next/static/rpFn_jslWZ9qPkJwor7RD/_buildManifest.js" defer=""></script><script src="/_next/static/rpFn_jslWZ9qPkJwor7RD/_ssgManifest.js" defer=""></script></head><body><div id="__next"><main class="__className_f367f3"><div class="min-h-screen bg-white"><nav class="fixed w-full z-50 transition-all duration-300 bg-white shadow-md" style="transform:translateY(-100px) translateZ(0)"><div class="container mx-auto px-4 sm:px-6 lg:px-8"><div class="flex items-center justify-between h-16"><a class="text-xl font-bold transition-colors text-blue-600" href="/">CodeSprintPro</a><div class="hidden md:flex items-center space-x-8"><a class="text-sm font-medium transition-colors text-blue-600" href="/blog/">Blog</a><a class="text-sm font-medium transition-colors text-gray-600 hover:text-blue-600" href="/#about">About</a><a class="text-sm font-medium transition-colors text-gray-600 hover:text-blue-600" href="/#portfolio">Portfolio</a><a class="text-sm font-medium transition-colors text-gray-600 hover:text-blue-600" href="/#contact">Contact</a></div><button class="md:hidden p-2 rounded-lg transition-colors hover:bg-gray-100 text-gray-600" aria-label="Toggle mobile menu"><svg class="w-6 h-6" fill="none" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" stroke="currentColor"><path d="M4 6h16M4 12h16M4 18h16"></path></svg></button></div></div></nav><div class="pt-20"><div class="bg-gradient-to-br from-gray-900 to-blue-950 py-16"><div class="container mx-auto px-4 sm:px-6 lg:px-8 max-w-5xl"><nav class="flex items-center gap-2 text-sm text-gray-400 mb-6"><a class="hover:text-white transition-colors" href="/">Home</a><span>/</span><a class="hover:text-white transition-colors" href="/blog/">Blog</a><span>/</span><span class="text-gray-300 truncate max-w-xs">Kafka Exactly-Once Semantics: Myth vs Production Reality</span></nav><span class="inline-block text-xs font-semibold px-3 py-1 rounded-full bg-blue-100 text-blue-700 mb-4">Messaging</span><h1 class="text-3xl md:text-5xl font-bold text-white mb-4 leading-tight">Kafka Exactly-Once Semantics: Myth vs Production Reality</h1><p class="text-gray-300 text-lg mb-6 max-w-3xl">What Kafka&#x27;s exactly-once guarantee actually covers, where duplicates still happen in practice, and how to design genuinely idempotent consumers with Spring Kafka. Real production mistakes and their fixes.</p><div class="flex flex-wrap items-center gap-4 text-gray-400 text-sm"><span class="flex items-center gap-1.5"><svg class="w-4 h-4" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M16 7a4 4 0 11-8 0 4 4 0 018 0zM12 14a7 7 0 00-7 7h14a7 7 0 00-7-7z"></path></svg>Sachin Sarawgi</span><span>Â·</span><span>April 20, 2025</span><span>Â·</span><span class="flex items-center gap-1"><svg class="w-4 h-4" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>9 min read</span></div><div class="flex flex-wrap gap-2 mt-4"><span class="text-xs text-gray-400 bg-gray-800 px-2 py-1 rounded">#<!-- -->kafka</span><span class="text-xs text-gray-400 bg-gray-800 px-2 py-1 rounded">#<!-- -->exactly-once</span><span class="text-xs text-gray-400 bg-gray-800 px-2 py-1 rounded">#<!-- -->spring kafka</span><span class="text-xs text-gray-400 bg-gray-800 px-2 py-1 rounded">#<!-- -->distributed systems</span><span class="text-xs text-gray-400 bg-gray-800 px-2 py-1 rounded">#<!-- -->transactions</span><span class="text-xs text-gray-400 bg-gray-800 px-2 py-1 rounded">#<!-- -->java</span></div></div></div><div class="container mx-auto px-4 sm:px-6 lg:px-8 max-w-5xl py-12"><div class="flex gap-12"><div class="flex-1 min-w-0"><article class="prose prose-lg max-w-none prose-headings:text-gray-900 prose-headings:font-bold prose-h2:text-2xl prose-h2:mt-10 prose-h2:mb-4 prose-h3:text-xl prose-h3:mt-8 prose-h3:mb-3 prose-p:text-gray-700 prose-p:leading-relaxed prose-a:text-blue-600 prose-a:no-underline hover:prose-a:underline prose-strong:text-gray-900 prose-blockquote:border-blue-600 prose-blockquote:text-gray-600 prose-code:text-blue-700 prose-code:bg-blue-50 prose-code:px-1.5 prose-code:py-0.5 prose-code:rounded prose-code:text-sm prose-code:before:content-none prose-code:after:content-none prose-pre:rounded-xl prose-img:rounded-xl prose-img:shadow-md prose-table:text-sm prose-th:bg-gray-100 prose-th:text-gray-700"><p>Kafka 0.11 introduced exactly-once semantics (EOS), and every architecture diagram since then has confidently placed a checkbox next to "exactly once delivery." In practice, most teams deploying Kafka with EOS still see duplicates in production. The issue is that Kafka's exactly-once guarantee is real and precise â€” but it covers a narrower scope than most engineers assume.</p>
<p>This article explains exactly what the guarantee covers, where it breaks, and what you must implement yourself to actually achieve idempotent processing at the system level.</p>
<h2>What Exactly-Once Really Means</h2>
<p>Kafka's exactly-once guarantee applies specifically to the <strong>read-process-write</strong> loop within the Kafka ecosystem:</p>
<pre><code>Exactly-once scope:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                     â”‚
â”‚  Consumer reads from Topic A                        â”‚
â”‚       â”‚                                             â”‚
â”‚       â–¼                                             â”‚
â”‚  Processes message (transforms, aggregates)         â”‚
â”‚       â”‚                                             â”‚
â”‚       â–¼                                             â”‚
â”‚  Writes result to Topic B + commits offset atomicallyâ”‚
â”‚                                                     â”‚
â”‚  â† Kafka guarantees this is atomic and exactly once â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

NOT covered:
- Writing to an external database
- Calling an external API
- Any side effect outside Kafka's transaction coordinator
</code></pre>
<p>If your processing loop writes to PostgreSQL, sends an email, or calls a payment gateway, Kafka's EOS guarantee does not extend to those operations. You must implement idempotency for those side effects yourself.</p>
<h2>Producer Idempotence</h2>
<p>Producer idempotence (<code>enable.idempotence=true</code>) prevents duplicate messages caused by producer retries. Without it:</p>
<pre><code>Producer â†’ Broker: publish(msg1) [network timeout]
Producer â†’ Broker: retry publish(msg1)  â† duplicate!
Broker commits both copies
</code></pre>
<p>With idempotence enabled, each producer instance gets a <code>ProducerID (PID)</code> and each message gets a monotonically increasing sequence number. The broker tracks <code>(PID, partition, sequence_number)</code> tuples and deduplicates retries:</p>
<pre><code class="language-java">Properties props = new Properties();
props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "kafka:9092");
props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, true);
// Implied by idempotence=true:
// acks=all, max.in.flight.requests.per.connection=5, retries=MAX_INT
props.put(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION, 5);

KafkaProducer&#x3C;String, String> producer = new KafkaProducer&#x3C;>(props);
</code></pre>
<p><strong>Important:</strong> Idempotence is per-session. If the producer restarts, it gets a new PID. Messages inflight during the restart can be duplicated â€” there is no deduplication across producer instances.</p>
<h2>Transactional Producers</h2>
<p>Transactions extend idempotence to atomic multi-partition writes and atomic offset commits:</p>
<pre><code class="language-java">@Bean
public ProducerFactory&#x3C;String, PaymentEvent> producerFactory() {
    Map&#x3C;String, Object> config = new HashMap&#x3C;>();
    config.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "kafka:9092");
    config.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, true);
    config.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, "payment-processor-1");
    // transactional.id must be unique per producer instance
    // Use: service-name + partition-id for stable identity
    return new DefaultKafkaProducerFactory&#x3C;>(config);
}

// Transactional send:
@Transactional
public void processAndForward(ConsumerRecord&#x3C;String, PaymentEvent> record) {
    PaymentEvent event = record.value();
    PaymentResult result = paymentService.process(event);

    kafkaTemplate.executeInTransaction(ops -> {
        ops.send("payments-processed", event.getUserId(), result);
        ops.send("audit-log", event.getPaymentId(), AuditEntry.from(result));
        return true;
    });
    // Offset commit and both sends are atomic
    // Either all succeed or none are visible to consumers
}
</code></pre>
<p>The <code>transactional.id</code> must be stable across producer restarts. Kafka uses it to recover the previous producer's pending transactions. If you use random IDs, pending transactions from dead producers never resolve.</p>
<h2>Consumer Offset Management</h2>
<p>Consumer offsets in Kafka are stored in an internal topic (<code>__consumer_offsets</code>). The offset represents the next message to consume, not the last processed message. The danger:</p>
<pre><code>Consumer reads message at offset 100
Consumer processes message (writes to DB)
Consumer commits offset 101
Consumer crashes before commit â†’ next read starts at 100 â†’ DUPLICATE PROCESSING
Consumer crashes after commit â†’ offset is 101, message was processed â†’ OK
</code></pre>
<p>The window between processing and offset commit is the duplicate risk window. Making it smaller reduces exposure but never eliminates it.</p>
<p>With Spring Kafka's <code>@KafkaListener</code>:</p>
<pre><code class="language-java">@KafkaListener(topics = "payments", groupId = "payment-processor")
public void processPayment(ConsumerRecord&#x3C;String, PaymentEvent> record,
                           Acknowledgment ack) {
    try {
        paymentService.process(record.value());
        ack.acknowledge();  // Commit offset after successful processing
    } catch (RetryableException e) {
        // Don't ack â€” message will be redelivered
        throw e;
    } catch (NonRetryableException e) {
        ack.acknowledge();  // Commit offset, send to DLQ
        dlqProducer.send("payments-dlq", record);
    }
}
</code></pre>
<p>Use <code>AckMode.MANUAL_IMMEDIATE</code> for fine-grained control over when offsets are committed.</p>
<h2>Failure Cases Where Duplicates Still Happen</h2>
<h3>Case 1: Consumer Group Rebalance</h3>
<p>During a rebalance, partitions are reassigned. A consumer processing a message when the rebalance triggers may lose its partition assignment:</p>
<pre><code>Timeline:
T=0: Consumer A holds Partition 7, processes message offset 500
T=1: New consumer joins group â†’ rebalance triggered
T=2: Partition 7 reassigned to Consumer B
T=3: Consumer A's processing completes, tries to commit offset 501
T=4: Commit fails (partition not owned by Consumer A)
T=5: Consumer B starts reading from last committed offset: 500
T=6: Duplicate processing of message 500
</code></pre>
<p><strong>Fix:</strong> Use <code>CooperativeStickyAssignor</code> to minimize partition movement during rebalances:</p>
<pre><code class="language-java">props.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG,
    CooperativeStickyAssignor.class.getName());
</code></pre>
<p>And implement idempotent consumers (covered below) so duplicates are harmless.</p>
<h3>Case 2: ISR and Replication Factor Implications</h3>
<p>With <code>acks=all</code> and <code>min.insync.replicas=2</code>, a message is only acknowledged when it's on at least 2 replicas. If the leader fails after acknowledging but before replicas sync, the message is lost â€” but the producer got an <code>ACK</code>. With retries, the producer resends, creating a different kind of inconsistency.</p>
<pre><code>Replication factor: 3, min.insync.replicas: 2

Producer â†’ Broker Leader (ISR: Leader, Replica1, Replica2)
Leader writes â†’ Replica1 writes â†’ ACK sent to producer âœ“
Replica2 hasn't written yet â†’ Leader fails
New leader elected: Replica1 has the message
Replica2 becomes leader after Replica1 also fails
Replica2 doesn't have the message â†’ Message lost
Producer retries â†’ Duplicate (if message was durably committed elsewhere)
</code></pre>
<p>Set <code>min.insync.replicas=2</code> with <code>replication.factor=3</code> for the right balance of durability vs availability. Never set <code>min.insync.replicas = replication.factor</code> â€” one broker failure makes the topic completely unavailable.</p>
<h3>Case 3: Long Processing + Session Timeout</h3>
<p>If message processing takes longer than <code>max.poll.interval.ms</code> (default 5 minutes), Kafka considers the consumer dead and triggers a rebalance:</p>
<pre><code class="language-java">// This is dangerous if processPayment() can take > 5 minutes:
@KafkaListener(topics = "payments")
public void processPayment(PaymentEvent event) {
    processPayment(event); // Could take 10 minutes for complex reconciliation
}

// Fix: Increase max.poll.interval.ms to cover realistic processing time
props.put(ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG, 600000); // 10 minutes
// Or: Move long processing to async and ack quickly
</code></pre>
<h2>Designing Idempotent Consumers</h2>
<p>Since duplicates are unavoidable at the system level, the correct approach is idempotent consumers: processing a message twice produces the same result as processing it once.</p>
<p><strong>Pattern: Idempotency key in the message + deduplication table</strong></p>
<pre><code class="language-java">// Message contains an idempotency key
public record PaymentEvent(
    String paymentId,         // Idempotency key
    String userId,
    BigDecimal amount,
    String currency
) {}

// Deduplication table in PostgreSQL
CREATE TABLE processed_payments (
    payment_id      VARCHAR(255) PRIMARY KEY,
    processed_at    TIMESTAMPTZ DEFAULT NOW(),
    result          JSONB
);

// Consumer checks before processing:
@Service
public class IdempotentPaymentConsumer {

    @Transactional
    public void processPayment(PaymentEvent event) {
        // Attempt insert â€” fails silently on duplicate
        int inserted = jdbcTemplate.update(
            "INSERT INTO processed_payments (payment_id) VALUES (?) ON CONFLICT DO NOTHING",
            event.paymentId()
        );

        if (inserted == 0) {
            log.info("Duplicate payment event, skipping: {}", event.paymentId());
            return;  // Already processed
        }

        // Process only if not already done
        PaymentResult result = paymentGateway.charge(event);
        jdbcTemplate.update(
            "UPDATE processed_payments SET result = ?::jsonb WHERE payment_id = ?",
            objectMapper.writeValueAsString(result), event.paymentId()
        );
    }
}
</code></pre>
<p>The <code>ON CONFLICT DO NOTHING</code> insert is atomic â€” concurrent duplicates resolve correctly without application-level locking.</p>
<h2>Retry Topics and DLQ Strategy</h2>
<pre><code>Retry topic architecture:

payments (main topic)
    â”‚
    â–¼
Consumer Group: payment-processor
    â”‚
    â”œâ”€â”€ Success â†’ payments-processed
    â”‚
    â”œâ”€â”€ Retryable failure
    â”‚       â””â”€â”€ payments-retry-1 (delay: 30s via consumer pause)
    â”‚               â””â”€â”€ payments-retry-2 (delay: 5min)
    â”‚                       â””â”€â”€ payments-retry-3 (delay: 30min)
    â”‚                               â””â”€â”€ payments-dlq
    â”‚
    â””â”€â”€ Non-retryable failure â†’ payments-dlq (immediately)
</code></pre>
<p>Spring Kafka's <code>@RetryableTopic</code>:</p>
<pre><code class="language-java">@RetryableTopic(
    attempts = "4",
    backoff = @Backoff(delay = 30000, multiplier = 5, maxDelay = 1800000),
    dltStrategy = DltStrategy.FAIL_ON_ERROR,
    autoCreateTopics = "false",
    include = {RetryablePaymentException.class}
)
@KafkaListener(topics = "payments", groupId = "payment-processor")
public void processPayment(PaymentEvent event) {
    paymentService.process(event);
}

@DltHandler
public void handleDlt(PaymentEvent event, @Header(KafkaHeaders.RECEIVED_TOPIC) String topic) {
    log.error("Message sent to DLT: topic={}, paymentId={}", topic, event.paymentId());
    alertingService.sendDltAlert(event);
    deadLetterRepository.save(DeadLetterRecord.from(event, topic));
}
</code></pre>
<h2>Handling Poison Messages</h2>
<p>A poison message is a message that consistently fails processing â€” malformed data, schema mismatch, or an edge case that triggers a bug. Without DLQ handling, poison messages block a partition indefinitely.</p>
<p>Indicators:</p>
<ul>
<li>Consumer lag growing on one partition while others are healthy</li>
<li>Same offset appearing repeatedly in error logs</li>
<li>Consumer processing rate drops to 0 on specific partitions</li>
</ul>
<p>Always configure a DLQ (<code>dlt-strategy=FAIL_ON_ERROR</code>) with an alert on DLQ topic lag growth. Poison messages in the DLQ should trigger an on-call page and manual investigation.</p>
<h2>Performance Trade-offs of EOS</h2>
<p>Transactions add overhead:</p>
<table>
<thead>
<tr>
<th>Mode</th>
<th>Throughput (approx)</th>
<th>Latency</th>
</tr>
</thead>
<tbody>
<tr>
<td>No idempotence, acks=1</td>
<td>Baseline 100%</td>
<td>Baseline</td>
</tr>
<tr>
<td>Idempotence only, acks=all</td>
<td>~80%</td>
<td>+10ms</td>
</tr>
<tr>
<td>Transactions (EOS)</td>
<td>~40â€“60%</td>
<td>+20â€“50ms</td>
</tr>
</tbody>
</table>
<p>The overhead comes from:</p>
<ul>
<li><code>beginTransaction()</code>/<code>commitTransaction()</code> calls to the transaction coordinator</li>
<li>Waiting for all ISR replicas to acknowledge (<code>acks=all</code>)</li>
<li>Fencing previous transactions from zombie producers</li>
</ul>
<p>For high-throughput pipelines where the downstream consumer is idempotent anyway, EOS's performance cost often isn't justified. Use idempotent producers + idempotent consumers instead of full EOS transactions.</p>
<h2>Real Production Mistakes</h2>
<p><strong>Mistake 1: Sharing a transactional.id across multiple producer instances.</strong> When two pods start with <code>transactional.id=payment-processor</code>, Kafka fences the older one. Your second pod's transactions are rejected. Use <code>payment-processor-${pod.ip}</code> or <code>payment-processor-${partition.id}</code>.</p>
<p><strong>Mistake 2: Using EOS for Kafka â†’ Database writes and assuming no duplicates.</strong> EOS is Kafka-to-Kafka. The database write is outside the transaction boundary. Always implement idempotency at the database layer regardless of Kafka configuration.</p>
<p><strong>Mistake 3: Not handling <code>ProducerFencedException</code>.</strong> When a producer is fenced by a newer instance with the same <code>transactional.id</code>, it throws <code>ProducerFencedException</code>. This is not retryable â€” the producer must be shut down and restarted. Handling this as a generic exception causes infinite retry loops.</p>
<pre><code class="language-java">try {
    kafkaTemplate.executeInTransaction(ops -> {
        ops.send("topic", record);
        return true;
    });
} catch (ProducerFencedException e) {
    // DO NOT retry â€” shut down and restart the producer
    log.error("Producer fenced, restarting: {}", e.getMessage());
    producerFactory.reset();
}
</code></pre>
<p><strong>Mistake 4: Ignoring rebalance-induced duplicates under load.</strong> Teams test EOS with low throughput where rebalances are rare. Under production load with frequent membership changes (rolling deploys, autoscaling), rebalances happen constantly. Load test with rolling restarts to expose rebalance-induced duplicates.</p>
<h2>Architecture Diagram</h2>
<pre><code>Payments EOS Pipeline:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Payment API â”‚â”€â”€â”€â”€â–ºâ”‚  payments topic  â”‚â”€â”€â”€â”€â–ºâ”‚  EOS Consumer    â”‚
â”‚  (Producer)  â”‚     â”‚  64 partitions   â”‚     â”‚  Group           â”‚
â”‚  idempotent  â”‚     â”‚  RF=3, ISR=2     â”‚     â”‚  Transactional   â”‚
â”‚  acks=all    â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  writes          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                     â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                                â”‚             â”‚
                    â–¼                                â–¼             â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ payments-processedâ”‚           â”‚  PostgreSQL  â”‚  â”‚ payments-dlq â”‚
         â”‚ topic             â”‚           â”‚  (idempotent â”‚  â”‚ (DLQ topic)  â”‚
         â”‚ (Kafka-to-Kafka   â”‚           â”‚  insert)     â”‚  â”‚              â”‚
         â”‚  EOS covered)     â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           (NOT EOS covered â€” must be idempotent)
</code></pre>
<p>Kafka's exactly-once guarantee is genuine and valuable â€” for Kafka-to-Kafka pipelines. For everything beyond that, the responsibility shifts to you. The engineers who understand this distinction build reliable systems; the ones who don't spend weekends investigating duplicate payments.</p>
</article><div class="my-10 rounded-xl border border-yellow-200 bg-yellow-50 p-6"><div class="flex items-center gap-2 mb-1"><span class="text-lg">ğŸ“š</span><h3 class="text-base font-bold text-gray-900">Recommended Resources</h3></div><div class="space-y-4"><div class="flex items-start gap-3 bg-white rounded-lg p-4 border border-yellow-100"><div class="flex-1 min-w-0"><div class="flex items-center gap-2 flex-wrap mb-1"><span class="font-semibold text-gray-900 text-sm">Designing Data-Intensive Applications</span><span class="text-xs bg-blue-100 text-blue-700 px-2 py-0.5 rounded-full font-medium">Best Seller</span></div><p class="text-xs text-gray-600">The definitive guide to building scalable, reliable distributed systems by Martin Kleppmann.</p></div><a href="https://amzn.to/3RyKzOA" target="_blank" rel="noopener noreferrer" class="flex-shrink-0 text-xs bg-blue-600 text-white px-3 py-2 rounded-lg hover:bg-blue-700 transition-colors font-medium whitespace-nowrap">View on Amazon<!-- --> â†’</a></div><div class="flex items-start gap-3 bg-white rounded-lg p-4 border border-yellow-100"><div class="flex-1 min-w-0"><div class="flex items-center gap-2 flex-wrap mb-1"><span class="font-semibold text-gray-900 text-sm">Kafka: The Definitive Guide</span><span class="text-xs bg-blue-100 text-blue-700 px-2 py-0.5 rounded-full font-medium">Editor&#x27;s Pick</span></div><p class="text-xs text-gray-600">Real-time data and stream processing by Confluent engineers.</p></div><a href="https://amzn.to/3TpGKsI" target="_blank" rel="noopener noreferrer" class="flex-shrink-0 text-xs bg-blue-600 text-white px-3 py-2 rounded-lg hover:bg-blue-700 transition-colors font-medium whitespace-nowrap">View on Amazon<!-- --> â†’</a></div><div class="flex items-start gap-3 bg-white rounded-lg p-4 border border-yellow-100"><div class="flex-1 min-w-0"><div class="flex items-center gap-2 flex-wrap mb-1"><span class="font-semibold text-gray-900 text-sm">Apache Kafka Series on Udemy</span></div><p class="text-xs text-gray-600">Hands-on Kafka course covering producers, consumers, Kafka Streams, and Connect.</p></div><a href="https://www.udemy.com/course/apache-kafka/" target="_blank" rel="noopener noreferrer" class="flex-shrink-0 text-xs bg-blue-600 text-white px-3 py-2 rounded-lg hover:bg-blue-700 transition-colors font-medium whitespace-nowrap">View Course<!-- --> â†’</a></div></div></div><div class="mt-10 pt-8 border-t border-gray-100"><p class="text-sm text-gray-500 mb-3">Found this useful? Share it:</p><div class="flex gap-3"><a href="https://twitter.com/intent/tweet?text=Kafka%20Exactly-Once%20Semantics%3A%20Myth%20vs%20Production%20Reality&amp;url=https%3A%2F%2Fcodesprintpro.com%2Fblog%2Fkafka-exactly-once-semantics%2F" target="_blank" rel="noopener noreferrer" class="text-xs bg-gray-900 text-white px-4 py-2 rounded-lg hover:bg-gray-700 transition-colors">Share on X/Twitter</a><a href="https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fcodesprintpro.com%2Fblog%2Fkafka-exactly-once-semantics%2F" target="_blank" rel="noopener noreferrer" class="text-xs bg-blue-600 text-white px-4 py-2 rounded-lg hover:bg-blue-700 transition-colors">Share on LinkedIn</a></div></div></div><aside class="hidden lg:block w-64 flex-shrink-0"><nav class="hidden lg:block sticky top-24"><h4 class="text-xs font-semibold uppercase tracking-widest text-gray-400 mb-3">On This Page</h4><ul class="space-y-1"><li class=""><a href="#what-exactly-once-really-means" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">What Exactly-Once Really Means</a></li><li class=""><a href="#producer-idempotence" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Producer Idempotence</a></li><li class=""><a href="#transactional-producers" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Transactional Producers</a></li><li class=""><a href="#consumer-offset-management" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Consumer Offset Management</a></li><li class=""><a href="#failure-cases-where-duplicates-still-happen" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Failure Cases Where Duplicates Still Happen</a></li><li class="ml-4"><a href="#case-1-consumer-group-rebalance" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 text-xs">Case 1: Consumer Group Rebalance</a></li><li class="ml-4"><a href="#case-2-isr-and-replication-factor-implications" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 text-xs">Case 2: ISR and Replication Factor Implications</a></li><li class="ml-4"><a href="#case-3-long-processing-session-timeout" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 text-xs">Case 3: Long Processing + Session Timeout</a></li><li class=""><a href="#designing-idempotent-consumers" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Designing Idempotent Consumers</a></li><li class=""><a href="#retry-topics-and-dlq-strategy" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Retry Topics and DLQ Strategy</a></li><li class=""><a href="#handling-poison-messages" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Handling Poison Messages</a></li><li class=""><a href="#performance-trade-offs-of-eos" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Performance Trade-offs of EOS</a></li><li class=""><a href="#real-production-mistakes" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Real Production Mistakes</a></li><li class=""><a href="#architecture-diagram" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Architecture Diagram</a></li></ul></nav></aside></div><div class="mt-16 pt-10 border-t border-gray-100"><h2 class="text-2xl font-bold text-gray-900 mb-6">Related Articles</h2><div class="grid grid-cols-1 md:grid-cols-3 gap-6"><a href="/blog/sqs-kafka-eventbridge-aws-comparison/"><article class="group bg-white rounded-xl border border-gray-200 p-6 h-full cursor-pointer hover:border-blue-300 hover:shadow-lg transition-all"><span class="inline-block text-xs font-semibold px-3 py-1 rounded-full mb-3 bg-red-100 text-red-700">Messaging</span><h3 class="text-lg font-bold text-gray-900 mb-2 group-hover:text-blue-600 transition-colors leading-snug">SQS vs Kafka vs EventBridge: Choosing the Right Messaging System on AWS</h3><p class="text-gray-600 text-sm mb-4 line-clamp-3">Every AWS backend team eventually faces the same decision: you need asynchronous messaging. SQS is right there in the console. Your architect says you need Kafka. Someone from DevOps mentions EventBridge. Each option hasâ€¦</p><div class="flex items-center justify-between text-xs text-gray-400"><span>Apr 2, 2025</span><span class="flex items-center gap-1"><svg class="w-3 h-3" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>10 min read</span></div><div class="mt-3 flex flex-wrap gap-1"><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->aws</span><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->sqs</span><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->kafka</span></div></article></a><a href="/blog/kafka-internals-deep-dive/"><article class="group bg-white rounded-xl border border-gray-200 p-6 h-full cursor-pointer hover:border-blue-300 hover:shadow-lg transition-all"><span class="inline-block text-xs font-semibold px-3 py-1 rounded-full mb-3 bg-red-100 text-red-700">Messaging</span><h3 class="text-lg font-bold text-gray-900 mb-2 group-hover:text-blue-600 transition-colors leading-snug">Kafka Internals Deep Dive: Partitions, Offsets, and Consumer Groups</h3><p class="text-gray-600 text-sm mb-4 line-clamp-3">Apache Kafka is the de facto standard for event streaming in distributed systems, but most developers treat it as a black box â€” a durable message queue with a fancy name. Understanding Kafka&#x27;s internals unlocks its true â€¦</p><div class="flex items-center justify-between text-xs text-gray-400"><span>Jan 15, 2025</span><span class="flex items-center gap-1"><svg class="w-3 h-3" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>10 min read</span></div><div class="mt-3 flex flex-wrap gap-1"><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->kafka</span><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->distributed systems</span><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->streaming</span></div></article></a></div></div><div class="mt-12 text-center"><a class="inline-flex items-center gap-2 text-blue-600 hover:text-blue-700 font-medium transition-colors" href="/blog/">â† Back to all articles</a></div></div></div><footer class="bg-gray-900 text-white py-12"><div class="container mx-auto px-4 sm:px-6 lg:px-8"><div class="grid grid-cols-1 md:grid-cols-4 gap-8 mb-8"><div class="col-span-1 md:col-span-1"><div><a class="text-xl font-bold block mb-3 text-white hover:text-blue-400 transition-colors" href="/">CodeSprintPro</a></div><p class="text-gray-400 text-sm mb-4 leading-relaxed">Deep-dive technical content on System Design, Java, Databases, AI/ML, and AWS â€” by Sachin Sarawgi.</p><div class="flex space-x-4"><a href="https://github.com/codesprintpro" target="_blank" rel="noopener noreferrer" class="text-gray-400 hover:text-white transition-colors" aria-label="Visit GitHub profile"><i class="fab fa-github text-xl"></i></a><a href="https://www.linkedin.com/in/sachin-sarawgi/" target="_blank" rel="noopener noreferrer" class="text-gray-400 hover:text-white transition-colors" aria-label="Visit LinkedIn profile"><i class="fab fa-linkedin text-xl"></i></a><a href="https://medium.com/@codesprintpro" target="_blank" rel="noopener noreferrer" class="text-gray-400 hover:text-white transition-colors" aria-label="Visit Medium profile"><i class="fab fa-medium text-xl"></i></a></div></div><div><h3 class="text-sm font-semibold uppercase tracking-widest text-gray-400 mb-4">Quick Links</h3><ul class="space-y-2"><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">Blog</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/#about">About</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/#portfolio">Portfolio</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/#contact">Contact</a></div></li></ul></div><div><h3 class="text-sm font-semibold uppercase tracking-widest text-gray-400 mb-4">Categories</h3><ul class="space-y-2"><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">System Design</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">Java</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">Databases</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">AI/ML</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">AWS</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">Messaging</a></div></li></ul></div><div><h3 class="text-sm font-semibold uppercase tracking-widest text-gray-400 mb-4">Contact</h3><ul class="space-y-2 text-gray-400 text-sm"><li><a href="mailto:sachinsarawgi201143@gmail.com" class="hover:text-white transition-colors flex items-center gap-2"><i class="fas fa-envelope"></i> Email</a></li><li><a href="https://www.linkedin.com/in/sachin-sarawgi/" target="_blank" rel="noopener noreferrer" class="hover:text-white transition-colors flex items-center gap-2"><i class="fab fa-linkedin"></i> LinkedIn</a></li><li><a href="https://github.com/codesprintpro" target="_blank" rel="noopener noreferrer" class="hover:text-white transition-colors flex items-center gap-2"><i class="fab fa-github"></i> GitHub</a></li></ul></div></div><div class="border-t border-gray-800 pt-6 flex flex-col md:flex-row justify-between items-center gap-2"><p class="text-gray-500 text-sm">Â© <!-- -->2026<!-- --> CodeSprintPro Â· Sachin Sarawgi. All rights reserved.</p><p class="text-gray-600 text-xs">Built with Next.js Â· TailwindCSS Â· Deployed on GitHub Pages</p></div></div></footer></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"Kafka Exactly-Once Semantics: Myth vs Production Reality","description":"What Kafka's exactly-once guarantee actually covers, where duplicates still happen in practice, and how to design genuinely idempotent consumers with Spring Kafka. Real production mistakes and their fixes.","date":"2025-04-20","category":"Messaging","tags":["kafka","exactly-once","spring kafka","distributed systems","transactions","java"],"featured":false,"affiliateSection":"distributed-systems-books","slug":"kafka-exactly-once-semantics","readingTime":"9 min read","excerpt":"Kafka 0.11 introduced exactly-once semantics (EOS), and every architecture diagram since then has confidently placed a checkbox next to \"exactly once delivery.\" In practice, most teams deploying Kafka with EOS still see â€¦","contentHtml":"\u003cp\u003eKafka 0.11 introduced exactly-once semantics (EOS), and every architecture diagram since then has confidently placed a checkbox next to \"exactly once delivery.\" In practice, most teams deploying Kafka with EOS still see duplicates in production. The issue is that Kafka's exactly-once guarantee is real and precise â€” but it covers a narrower scope than most engineers assume.\u003c/p\u003e\n\u003cp\u003eThis article explains exactly what the guarantee covers, where it breaks, and what you must implement yourself to actually achieve idempotent processing at the system level.\u003c/p\u003e\n\u003ch2\u003eWhat Exactly-Once Really Means\u003c/h2\u003e\n\u003cp\u003eKafka's exactly-once guarantee applies specifically to the \u003cstrong\u003eread-process-write\u003c/strong\u003e loop within the Kafka ecosystem:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eExactly-once scope:\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                                                     â”‚\nâ”‚  Consumer reads from Topic A                        â”‚\nâ”‚       â”‚                                             â”‚\nâ”‚       â–¼                                             â”‚\nâ”‚  Processes message (transforms, aggregates)         â”‚\nâ”‚       â”‚                                             â”‚\nâ”‚       â–¼                                             â”‚\nâ”‚  Writes result to Topic B + commits offset atomicallyâ”‚\nâ”‚                                                     â”‚\nâ”‚  â† Kafka guarantees this is atomic and exactly once â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nNOT covered:\n- Writing to an external database\n- Calling an external API\n- Any side effect outside Kafka's transaction coordinator\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIf your processing loop writes to PostgreSQL, sends an email, or calls a payment gateway, Kafka's EOS guarantee does not extend to those operations. You must implement idempotency for those side effects yourself.\u003c/p\u003e\n\u003ch2\u003eProducer Idempotence\u003c/h2\u003e\n\u003cp\u003eProducer idempotence (\u003ccode\u003eenable.idempotence=true\u003c/code\u003e) prevents duplicate messages caused by producer retries. Without it:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eProducer â†’ Broker: publish(msg1) [network timeout]\nProducer â†’ Broker: retry publish(msg1)  â† duplicate!\nBroker commits both copies\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWith idempotence enabled, each producer instance gets a \u003ccode\u003eProducerID (PID)\u003c/code\u003e and each message gets a monotonically increasing sequence number. The broker tracks \u003ccode\u003e(PID, partition, sequence_number)\u003c/code\u003e tuples and deduplicates retries:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003eProperties props = new Properties();\nprops.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"kafka:9092\");\nprops.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, true);\n// Implied by idempotence=true:\n// acks=all, max.in.flight.requests.per.connection=5, retries=MAX_INT\nprops.put(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION, 5);\n\nKafkaProducer\u0026#x3C;String, String\u003e producer = new KafkaProducer\u0026#x3C;\u003e(props);\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eImportant:\u003c/strong\u003e Idempotence is per-session. If the producer restarts, it gets a new PID. Messages inflight during the restart can be duplicated â€” there is no deduplication across producer instances.\u003c/p\u003e\n\u003ch2\u003eTransactional Producers\u003c/h2\u003e\n\u003cp\u003eTransactions extend idempotence to atomic multi-partition writes and atomic offset commits:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003e@Bean\npublic ProducerFactory\u0026#x3C;String, PaymentEvent\u003e producerFactory() {\n    Map\u0026#x3C;String, Object\u003e config = new HashMap\u0026#x3C;\u003e();\n    config.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"kafka:9092\");\n    config.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, true);\n    config.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, \"payment-processor-1\");\n    // transactional.id must be unique per producer instance\n    // Use: service-name + partition-id for stable identity\n    return new DefaultKafkaProducerFactory\u0026#x3C;\u003e(config);\n}\n\n// Transactional send:\n@Transactional\npublic void processAndForward(ConsumerRecord\u0026#x3C;String, PaymentEvent\u003e record) {\n    PaymentEvent event = record.value();\n    PaymentResult result = paymentService.process(event);\n\n    kafkaTemplate.executeInTransaction(ops -\u003e {\n        ops.send(\"payments-processed\", event.getUserId(), result);\n        ops.send(\"audit-log\", event.getPaymentId(), AuditEntry.from(result));\n        return true;\n    });\n    // Offset commit and both sends are atomic\n    // Either all succeed or none are visible to consumers\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe \u003ccode\u003etransactional.id\u003c/code\u003e must be stable across producer restarts. Kafka uses it to recover the previous producer's pending transactions. If you use random IDs, pending transactions from dead producers never resolve.\u003c/p\u003e\n\u003ch2\u003eConsumer Offset Management\u003c/h2\u003e\n\u003cp\u003eConsumer offsets in Kafka are stored in an internal topic (\u003ccode\u003e__consumer_offsets\u003c/code\u003e). The offset represents the next message to consume, not the last processed message. The danger:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eConsumer reads message at offset 100\nConsumer processes message (writes to DB)\nConsumer commits offset 101\nConsumer crashes before commit â†’ next read starts at 100 â†’ DUPLICATE PROCESSING\nConsumer crashes after commit â†’ offset is 101, message was processed â†’ OK\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe window between processing and offset commit is the duplicate risk window. Making it smaller reduces exposure but never eliminates it.\u003c/p\u003e\n\u003cp\u003eWith Spring Kafka's \u003ccode\u003e@KafkaListener\u003c/code\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003e@KafkaListener(topics = \"payments\", groupId = \"payment-processor\")\npublic void processPayment(ConsumerRecord\u0026#x3C;String, PaymentEvent\u003e record,\n                           Acknowledgment ack) {\n    try {\n        paymentService.process(record.value());\n        ack.acknowledge();  // Commit offset after successful processing\n    } catch (RetryableException e) {\n        // Don't ack â€” message will be redelivered\n        throw e;\n    } catch (NonRetryableException e) {\n        ack.acknowledge();  // Commit offset, send to DLQ\n        dlqProducer.send(\"payments-dlq\", record);\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eUse \u003ccode\u003eAckMode.MANUAL_IMMEDIATE\u003c/code\u003e for fine-grained control over when offsets are committed.\u003c/p\u003e\n\u003ch2\u003eFailure Cases Where Duplicates Still Happen\u003c/h2\u003e\n\u003ch3\u003eCase 1: Consumer Group Rebalance\u003c/h3\u003e\n\u003cp\u003eDuring a rebalance, partitions are reassigned. A consumer processing a message when the rebalance triggers may lose its partition assignment:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eTimeline:\nT=0: Consumer A holds Partition 7, processes message offset 500\nT=1: New consumer joins group â†’ rebalance triggered\nT=2: Partition 7 reassigned to Consumer B\nT=3: Consumer A's processing completes, tries to commit offset 501\nT=4: Commit fails (partition not owned by Consumer A)\nT=5: Consumer B starts reading from last committed offset: 500\nT=6: Duplicate processing of message 500\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eFix:\u003c/strong\u003e Use \u003ccode\u003eCooperativeStickyAssignor\u003c/code\u003e to minimize partition movement during rebalances:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003eprops.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG,\n    CooperativeStickyAssignor.class.getName());\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAnd implement idempotent consumers (covered below) so duplicates are harmless.\u003c/p\u003e\n\u003ch3\u003eCase 2: ISR and Replication Factor Implications\u003c/h3\u003e\n\u003cp\u003eWith \u003ccode\u003eacks=all\u003c/code\u003e and \u003ccode\u003emin.insync.replicas=2\u003c/code\u003e, a message is only acknowledged when it's on at least 2 replicas. If the leader fails after acknowledging but before replicas sync, the message is lost â€” but the producer got an \u003ccode\u003eACK\u003c/code\u003e. With retries, the producer resends, creating a different kind of inconsistency.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eReplication factor: 3, min.insync.replicas: 2\n\nProducer â†’ Broker Leader (ISR: Leader, Replica1, Replica2)\nLeader writes â†’ Replica1 writes â†’ ACK sent to producer âœ“\nReplica2 hasn't written yet â†’ Leader fails\nNew leader elected: Replica1 has the message\nReplica2 becomes leader after Replica1 also fails\nReplica2 doesn't have the message â†’ Message lost\nProducer retries â†’ Duplicate (if message was durably committed elsewhere)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eSet \u003ccode\u003emin.insync.replicas=2\u003c/code\u003e with \u003ccode\u003ereplication.factor=3\u003c/code\u003e for the right balance of durability vs availability. Never set \u003ccode\u003emin.insync.replicas = replication.factor\u003c/code\u003e â€” one broker failure makes the topic completely unavailable.\u003c/p\u003e\n\u003ch3\u003eCase 3: Long Processing + Session Timeout\u003c/h3\u003e\n\u003cp\u003eIf message processing takes longer than \u003ccode\u003emax.poll.interval.ms\u003c/code\u003e (default 5 minutes), Kafka considers the consumer dead and triggers a rebalance:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003e// This is dangerous if processPayment() can take \u003e 5 minutes:\n@KafkaListener(topics = \"payments\")\npublic void processPayment(PaymentEvent event) {\n    processPayment(event); // Could take 10 minutes for complex reconciliation\n}\n\n// Fix: Increase max.poll.interval.ms to cover realistic processing time\nprops.put(ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG, 600000); // 10 minutes\n// Or: Move long processing to async and ack quickly\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eDesigning Idempotent Consumers\u003c/h2\u003e\n\u003cp\u003eSince duplicates are unavoidable at the system level, the correct approach is idempotent consumers: processing a message twice produces the same result as processing it once.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003ePattern: Idempotency key in the message + deduplication table\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003e// Message contains an idempotency key\npublic record PaymentEvent(\n    String paymentId,         // Idempotency key\n    String userId,\n    BigDecimal amount,\n    String currency\n) {}\n\n// Deduplication table in PostgreSQL\nCREATE TABLE processed_payments (\n    payment_id      VARCHAR(255) PRIMARY KEY,\n    processed_at    TIMESTAMPTZ DEFAULT NOW(),\n    result          JSONB\n);\n\n// Consumer checks before processing:\n@Service\npublic class IdempotentPaymentConsumer {\n\n    @Transactional\n    public void processPayment(PaymentEvent event) {\n        // Attempt insert â€” fails silently on duplicate\n        int inserted = jdbcTemplate.update(\n            \"INSERT INTO processed_payments (payment_id) VALUES (?) ON CONFLICT DO NOTHING\",\n            event.paymentId()\n        );\n\n        if (inserted == 0) {\n            log.info(\"Duplicate payment event, skipping: {}\", event.paymentId());\n            return;  // Already processed\n        }\n\n        // Process only if not already done\n        PaymentResult result = paymentGateway.charge(event);\n        jdbcTemplate.update(\n            \"UPDATE processed_payments SET result = ?::jsonb WHERE payment_id = ?\",\n            objectMapper.writeValueAsString(result), event.paymentId()\n        );\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe \u003ccode\u003eON CONFLICT DO NOTHING\u003c/code\u003e insert is atomic â€” concurrent duplicates resolve correctly without application-level locking.\u003c/p\u003e\n\u003ch2\u003eRetry Topics and DLQ Strategy\u003c/h2\u003e\n\u003cpre\u003e\u003ccode\u003eRetry topic architecture:\n\npayments (main topic)\n    â”‚\n    â–¼\nConsumer Group: payment-processor\n    â”‚\n    â”œâ”€â”€ Success â†’ payments-processed\n    â”‚\n    â”œâ”€â”€ Retryable failure\n    â”‚       â””â”€â”€ payments-retry-1 (delay: 30s via consumer pause)\n    â”‚               â””â”€â”€ payments-retry-2 (delay: 5min)\n    â”‚                       â””â”€â”€ payments-retry-3 (delay: 30min)\n    â”‚                               â””â”€â”€ payments-dlq\n    â”‚\n    â””â”€â”€ Non-retryable failure â†’ payments-dlq (immediately)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eSpring Kafka's \u003ccode\u003e@RetryableTopic\u003c/code\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003e@RetryableTopic(\n    attempts = \"4\",\n    backoff = @Backoff(delay = 30000, multiplier = 5, maxDelay = 1800000),\n    dltStrategy = DltStrategy.FAIL_ON_ERROR,\n    autoCreateTopics = \"false\",\n    include = {RetryablePaymentException.class}\n)\n@KafkaListener(topics = \"payments\", groupId = \"payment-processor\")\npublic void processPayment(PaymentEvent event) {\n    paymentService.process(event);\n}\n\n@DltHandler\npublic void handleDlt(PaymentEvent event, @Header(KafkaHeaders.RECEIVED_TOPIC) String topic) {\n    log.error(\"Message sent to DLT: topic={}, paymentId={}\", topic, event.paymentId());\n    alertingService.sendDltAlert(event);\n    deadLetterRepository.save(DeadLetterRecord.from(event, topic));\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eHandling Poison Messages\u003c/h2\u003e\n\u003cp\u003eA poison message is a message that consistently fails processing â€” malformed data, schema mismatch, or an edge case that triggers a bug. Without DLQ handling, poison messages block a partition indefinitely.\u003c/p\u003e\n\u003cp\u003eIndicators:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eConsumer lag growing on one partition while others are healthy\u003c/li\u003e\n\u003cli\u003eSame offset appearing repeatedly in error logs\u003c/li\u003e\n\u003cli\u003eConsumer processing rate drops to 0 on specific partitions\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAlways configure a DLQ (\u003ccode\u003edlt-strategy=FAIL_ON_ERROR\u003c/code\u003e) with an alert on DLQ topic lag growth. Poison messages in the DLQ should trigger an on-call page and manual investigation.\u003c/p\u003e\n\u003ch2\u003ePerformance Trade-offs of EOS\u003c/h2\u003e\n\u003cp\u003eTransactions add overhead:\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eMode\u003c/th\u003e\n\u003cth\u003eThroughput (approx)\u003c/th\u003e\n\u003cth\u003eLatency\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eNo idempotence, acks=1\u003c/td\u003e\n\u003ctd\u003eBaseline 100%\u003c/td\u003e\n\u003ctd\u003eBaseline\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eIdempotence only, acks=all\u003c/td\u003e\n\u003ctd\u003e~80%\u003c/td\u003e\n\u003ctd\u003e+10ms\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eTransactions (EOS)\u003c/td\u003e\n\u003ctd\u003e~40â€“60%\u003c/td\u003e\n\u003ctd\u003e+20â€“50ms\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003eThe overhead comes from:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003ebeginTransaction()\u003c/code\u003e/\u003ccode\u003ecommitTransaction()\u003c/code\u003e calls to the transaction coordinator\u003c/li\u003e\n\u003cli\u003eWaiting for all ISR replicas to acknowledge (\u003ccode\u003eacks=all\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003eFencing previous transactions from zombie producers\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eFor high-throughput pipelines where the downstream consumer is idempotent anyway, EOS's performance cost often isn't justified. Use idempotent producers + idempotent consumers instead of full EOS transactions.\u003c/p\u003e\n\u003ch2\u003eReal Production Mistakes\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eMistake 1: Sharing a transactional.id across multiple producer instances.\u003c/strong\u003e When two pods start with \u003ccode\u003etransactional.id=payment-processor\u003c/code\u003e, Kafka fences the older one. Your second pod's transactions are rejected. Use \u003ccode\u003epayment-processor-${pod.ip}\u003c/code\u003e or \u003ccode\u003epayment-processor-${partition.id}\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eMistake 2: Using EOS for Kafka â†’ Database writes and assuming no duplicates.\u003c/strong\u003e EOS is Kafka-to-Kafka. The database write is outside the transaction boundary. Always implement idempotency at the database layer regardless of Kafka configuration.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eMistake 3: Not handling \u003ccode\u003eProducerFencedException\u003c/code\u003e.\u003c/strong\u003e When a producer is fenced by a newer instance with the same \u003ccode\u003etransactional.id\u003c/code\u003e, it throws \u003ccode\u003eProducerFencedException\u003c/code\u003e. This is not retryable â€” the producer must be shut down and restarted. Handling this as a generic exception causes infinite retry loops.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003etry {\n    kafkaTemplate.executeInTransaction(ops -\u003e {\n        ops.send(\"topic\", record);\n        return true;\n    });\n} catch (ProducerFencedException e) {\n    // DO NOT retry â€” shut down and restart the producer\n    log.error(\"Producer fenced, restarting: {}\", e.getMessage());\n    producerFactory.reset();\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eMistake 4: Ignoring rebalance-induced duplicates under load.\u003c/strong\u003e Teams test EOS with low throughput where rebalances are rare. Under production load with frequent membership changes (rolling deploys, autoscaling), rebalances happen constantly. Load test with rolling restarts to expose rebalance-induced duplicates.\u003c/p\u003e\n\u003ch2\u003eArchitecture Diagram\u003c/h2\u003e\n\u003cpre\u003e\u003ccode\u003ePayments EOS Pipeline:\n\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Payment API â”‚â”€â”€â”€â”€â–ºâ”‚  payments topic  â”‚â”€â”€â”€â”€â–ºâ”‚  EOS Consumer    â”‚\nâ”‚  (Producer)  â”‚     â”‚  64 partitions   â”‚     â”‚  Group           â”‚\nâ”‚  idempotent  â”‚     â”‚  RF=3, ISR=2     â”‚     â”‚  Transactional   â”‚\nâ”‚  acks=all    â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  writes          â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                                                     â”‚\n                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n                    â”‚                                â”‚             â”‚\n                    â–¼                                â–¼             â–¼\n         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n         â”‚ payments-processedâ”‚           â”‚  PostgreSQL  â”‚  â”‚ payments-dlq â”‚\n         â”‚ topic             â”‚           â”‚  (idempotent â”‚  â”‚ (DLQ topic)  â”‚\n         â”‚ (Kafka-to-Kafka   â”‚           â”‚  insert)     â”‚  â”‚              â”‚\n         â”‚  EOS covered)     â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           (NOT EOS covered â€” must be idempotent)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eKafka's exactly-once guarantee is genuine and valuable â€” for Kafka-to-Kafka pipelines. For everything beyond that, the responsibility shifts to you. The engineers who understand this distinction build reliable systems; the ones who don't spend weekends investigating duplicate payments.\u003c/p\u003e\n","tableOfContents":[{"id":"what-exactly-once-really-means","text":"What Exactly-Once Really Means","level":2},{"id":"producer-idempotence","text":"Producer Idempotence","level":2},{"id":"transactional-producers","text":"Transactional Producers","level":2},{"id":"consumer-offset-management","text":"Consumer Offset Management","level":2},{"id":"failure-cases-where-duplicates-still-happen","text":"Failure Cases Where Duplicates Still Happen","level":2},{"id":"case-1-consumer-group-rebalance","text":"Case 1: Consumer Group Rebalance","level":3},{"id":"case-2-isr-and-replication-factor-implications","text":"Case 2: ISR and Replication Factor Implications","level":3},{"id":"case-3-long-processing-session-timeout","text":"Case 3: Long Processing + Session Timeout","level":3},{"id":"designing-idempotent-consumers","text":"Designing Idempotent Consumers","level":2},{"id":"retry-topics-and-dlq-strategy","text":"Retry Topics and DLQ Strategy","level":2},{"id":"handling-poison-messages","text":"Handling Poison Messages","level":2},{"id":"performance-trade-offs-of-eos","text":"Performance Trade-offs of EOS","level":2},{"id":"real-production-mistakes","text":"Real Production Mistakes","level":2},{"id":"architecture-diagram","text":"Architecture Diagram","level":2}]},"relatedPosts":[{"title":"SQS vs Kafka vs EventBridge: Choosing the Right Messaging System on AWS","description":"A senior engineer's guide to selecting between Amazon SQS, Apache Kafka on AWS, and EventBridge. Throughput benchmarks, cost breakdowns, ordering guarantees, and real production trade-offs.","date":"2025-04-02","category":"Messaging","tags":["aws","sqs","kafka","eventbridge","distributed systems","messaging","msk"],"featured":false,"affiliateSection":"aws-resources","slug":"sqs-kafka-eventbridge-aws-comparison","readingTime":"10 min read","excerpt":"Every AWS backend team eventually faces the same decision: you need asynchronous messaging. SQS is right there in the console. Your architect says you need Kafka. Someone from DevOps mentions EventBridge. Each option hasâ€¦"},{"title":"Kafka Internals Deep Dive: Partitions, Offsets, and Consumer Groups","description":"Understand how Apache Kafka achieves high throughput through log-based storage, how offsets enable reliable consumption, and how consumer groups scale processing horizontally.","date":"2025-01-15","category":"Messaging","tags":["kafka","distributed systems","streaming","java"],"featured":true,"affiliateSection":"distributed-systems-books","slug":"kafka-internals-deep-dive","readingTime":"10 min read","excerpt":"Apache Kafka is the de facto standard for event streaming in distributed systems, but most developers treat it as a black box â€” a durable message queue with a fancy name. Understanding Kafka's internals unlocks its true â€¦"}]},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"kafka-exactly-once-semantics"},"buildId":"rpFn_jslWZ9qPkJwor7RD","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>