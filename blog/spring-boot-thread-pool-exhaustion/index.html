<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8" data-next-head=""/><meta name="viewport" content="width=device-width" data-next-head=""/><title data-next-head="">Thread Pool Exhaustion in Spring Boot: Diagnosis, Prevention, and Recovery<!-- --> | CodeSprintPro</title><meta name="description" content="How Tomcat thread pools work, why blocking I/O kills throughput, and the production patterns that prevent thread pool exhaustion in Spring Boot services. Includes real outage scenario and JVM tuning." data-next-head=""/><meta name="author" content="Sachin Sarawgi" data-next-head=""/><link rel="canonical" href="https://codesprintpro.com/blog/spring-boot-thread-pool-exhaustion/" data-next-head=""/><meta property="og:type" content="article" data-next-head=""/><meta property="og:title" content="Thread Pool Exhaustion in Spring Boot: Diagnosis, Prevention, and Recovery" data-next-head=""/><meta property="og:description" content="How Tomcat thread pools work, why blocking I/O kills throughput, and the production patterns that prevent thread pool exhaustion in Spring Boot services. Includes real outage scenario and JVM tuning." data-next-head=""/><meta property="og:url" content="https://codesprintpro.com/blog/spring-boot-thread-pool-exhaustion/" data-next-head=""/><meta property="og:image" content="https://codesprintpro.com/images/og-default.jpg" data-next-head=""/><meta property="og:site_name" content="CodeSprintPro" data-next-head=""/><meta property="article:published_time" content="2025-04-08" data-next-head=""/><meta property="article:author" content="Sachin Sarawgi" data-next-head=""/><meta property="article:section" content="Java" data-next-head=""/><meta property="article:tag" content="spring boot" data-next-head=""/><meta property="article:tag" content="java" data-next-head=""/><meta property="article:tag" content="tomcat" data-next-head=""/><meta property="article:tag" content="thread pool" data-next-head=""/><meta property="article:tag" content="async" data-next-head=""/><meta property="article:tag" content="performance" data-next-head=""/><meta property="article:tag" content="resilience" data-next-head=""/><meta name="twitter:card" content="summary_large_image" data-next-head=""/><meta name="twitter:title" content="Thread Pool Exhaustion in Spring Boot: Diagnosis, Prevention, and Recovery" data-next-head=""/><meta name="twitter:description" content="How Tomcat thread pools work, why blocking I/O kills throughput, and the production patterns that prevent thread pool exhaustion in Spring Boot services. Includes real outage scenario and JVM tuning." data-next-head=""/><meta name="twitter:image" content="https://codesprintpro.com/images/og-default.jpg" data-next-head=""/><script type="application/ld+json" data-next-head="">{"@context":"https://schema.org","@type":"BlogPosting","headline":"Thread Pool Exhaustion in Spring Boot: Diagnosis, Prevention, and Recovery","description":"How Tomcat thread pools work, why blocking I/O kills throughput, and the production patterns that prevent thread pool exhaustion in Spring Boot services. Includes real outage scenario and JVM tuning.","image":"https://codesprintpro.com/images/og-default.jpg","datePublished":"2025-04-08","dateModified":"2025-04-08","author":{"@type":"Person","name":"Sachin Sarawgi","url":"https://codesprintpro.com","sameAs":["https://www.linkedin.com/in/sachin-sarawgi/","https://github.com/codesprintpro","https://medium.com/@codesprintpro"]},"publisher":{"@type":"Organization","name":"CodeSprintPro","url":"https://codesprintpro.com","logo":{"@type":"ImageObject","url":"https://codesprintpro.com/favicon/favicon-96x96.png"}},"mainEntityOfPage":{"@type":"WebPage","@id":"https://codesprintpro.com/blog/spring-boot-thread-pool-exhaustion/"},"keywords":"spring boot, java, tomcat, thread pool, async, performance, resilience","articleSection":"Java"}</script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" integrity="sha512-9usAa10IRO0HhonpyAIVpjrylPvoDwiPUiKdWk5t3PyolY1cOd4DSE0Ga+ri4AuTroPR5aQvXU9xC6qOPnzFeg==" crossorigin="anonymous" referrerPolicy="no-referrer"/><script async="" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-XXXXXXXXXXXXXXXX" crossorigin="anonymous"></script><link rel="preload" href="/_next/static/media/e4af272ccee01ff0-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/css/735d4373f93910ca.css" as="style"/><link rel="stylesheet" href="/_next/static/css/735d4373f93910ca.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-11a4a2dad04962bb.js" defer=""></script><script src="/_next/static/chunks/framework-1ce91eb6f9ecda85.js" defer=""></script><script src="/_next/static/chunks/main-c7f4109f032d7b6e.js" defer=""></script><script src="/_next/static/chunks/pages/_app-1a852bd9e38c70ab.js" defer=""></script><script src="/_next/static/chunks/730-db7827467817f501.js" defer=""></script><script src="/_next/static/chunks/90-1cd4611704c3dbe0.js" defer=""></script><script src="/_next/static/chunks/440-29f4b99a44e744b5.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-0c1b14a33d5e05ee.js" defer=""></script><script src="/_next/static/rpFn_jslWZ9qPkJwor7RD/_buildManifest.js" defer=""></script><script src="/_next/static/rpFn_jslWZ9qPkJwor7RD/_ssgManifest.js" defer=""></script></head><body><div id="__next"><main class="__className_f367f3"><div class="min-h-screen bg-white"><nav class="fixed w-full z-50 transition-all duration-300 bg-white shadow-md" style="transform:translateY(-100px) translateZ(0)"><div class="container mx-auto px-4 sm:px-6 lg:px-8"><div class="flex items-center justify-between h-16"><a class="text-xl font-bold transition-colors text-blue-600" href="/">CodeSprintPro</a><div class="hidden md:flex items-center space-x-8"><a class="text-sm font-medium transition-colors text-blue-600" href="/blog/">Blog</a><a class="text-sm font-medium transition-colors text-gray-600 hover:text-blue-600" href="/#about">About</a><a class="text-sm font-medium transition-colors text-gray-600 hover:text-blue-600" href="/#portfolio">Portfolio</a><a class="text-sm font-medium transition-colors text-gray-600 hover:text-blue-600" href="/#contact">Contact</a></div><button class="md:hidden p-2 rounded-lg transition-colors hover:bg-gray-100 text-gray-600" aria-label="Toggle mobile menu"><svg class="w-6 h-6" fill="none" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" stroke="currentColor"><path d="M4 6h16M4 12h16M4 18h16"></path></svg></button></div></div></nav><div class="pt-20"><div class="bg-gradient-to-br from-gray-900 to-blue-950 py-16"><div class="container mx-auto px-4 sm:px-6 lg:px-8 max-w-5xl"><nav class="flex items-center gap-2 text-sm text-gray-400 mb-6"><a class="hover:text-white transition-colors" href="/">Home</a><span>/</span><a class="hover:text-white transition-colors" href="/blog/">Blog</a><span>/</span><span class="text-gray-300 truncate max-w-xs">Thread Pool Exhaustion in Spring Boot: Diagnosis, Prevention, and Recovery</span></nav><span class="inline-block text-xs font-semibold px-3 py-1 rounded-full bg-blue-100 text-blue-700 mb-4">Java</span><h1 class="text-3xl md:text-5xl font-bold text-white mb-4 leading-tight">Thread Pool Exhaustion in Spring Boot: Diagnosis, Prevention, and Recovery</h1><p class="text-gray-300 text-lg mb-6 max-w-3xl">How Tomcat thread pools work, why blocking I/O kills throughput, and the production patterns that prevent thread pool exhaustion in Spring Boot services. Includes real outage scenario and JVM tuning.</p><div class="flex flex-wrap items-center gap-4 text-gray-400 text-sm"><span class="flex items-center gap-1.5"><svg class="w-4 h-4" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M16 7a4 4 0 11-8 0 4 4 0 018 0zM12 14a7 7 0 00-7 7h14a7 7 0 00-7-7z"></path></svg>Sachin Sarawgi</span><span>Â·</span><span>April 8, 2025</span><span>Â·</span><span class="flex items-center gap-1"><svg class="w-4 h-4" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>9 min read</span></div><div class="flex flex-wrap gap-2 mt-4"><span class="text-xs text-gray-400 bg-gray-800 px-2 py-1 rounded">#<!-- -->spring boot</span><span class="text-xs text-gray-400 bg-gray-800 px-2 py-1 rounded">#<!-- -->java</span><span class="text-xs text-gray-400 bg-gray-800 px-2 py-1 rounded">#<!-- -->tomcat</span><span class="text-xs text-gray-400 bg-gray-800 px-2 py-1 rounded">#<!-- -->thread pool</span><span class="text-xs text-gray-400 bg-gray-800 px-2 py-1 rounded">#<!-- -->async</span><span class="text-xs text-gray-400 bg-gray-800 px-2 py-1 rounded">#<!-- -->performance</span><span class="text-xs text-gray-400 bg-gray-800 px-2 py-1 rounded">#<!-- -->resilience</span></div></div></div><div class="container mx-auto px-4 sm:px-6 lg:px-8 max-w-5xl py-12"><div class="flex gap-12"><div class="flex-1 min-w-0"><article class="prose prose-lg max-w-none prose-headings:text-gray-900 prose-headings:font-bold prose-h2:text-2xl prose-h2:mt-10 prose-h2:mb-4 prose-h3:text-xl prose-h3:mt-8 prose-h3:mb-3 prose-p:text-gray-700 prose-p:leading-relaxed prose-a:text-blue-600 prose-a:no-underline hover:prose-a:underline prose-strong:text-gray-900 prose-blockquote:border-blue-600 prose-blockquote:text-gray-600 prose-code:text-blue-700 prose-code:bg-blue-50 prose-code:px-1.5 prose-code:py-0.5 prose-code:rounded prose-code:text-sm prose-code:before:content-none prose-code:after:content-none prose-pre:rounded-xl prose-img:rounded-xl prose-img:shadow-md prose-table:text-sm prose-th:bg-gray-100 prose-th:text-gray-700"><p>Thread pool exhaustion is one of the most deceptive production failures in Spring Boot services. The service is technically running â€” JVM process alive, health endpoint returning 200, no OutOfMemoryError in logs â€” but requests pile up, latencies spike to 30 seconds, and then everything times out. On-call gets paged. The fix is usually a restart, which masks the root cause until it happens again.</p>
<p>This article explains the mechanism precisely, shows you the math, and gives you the production patterns to prevent it.</p>
<h2>How Tomcat Thread Pools Work</h2>
<p>Spring Boot's default embedded server is Tomcat. Tomcat uses a fixed thread pool to process HTTP requests.</p>
<pre><code>HTTP Request
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Acceptor Thread   â”‚  (accepts TCP connections, non-blocking)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Connection Queue  â”‚  (bounded, default maxConnections=8192)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Tomcat Thread Pool                â”‚
â”‚  min: 10 threads (minSpareThreads) â”‚
â”‚  max: 200 threads (maxThreads)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
    @Controller method executes on this thread
    (BLOCKS until method returns)
</code></pre>
<p>The critical constraint: <strong>each active HTTP request holds exactly one Tomcat thread</strong>. The thread is occupied for the entire duration of request processing â€” including all database calls, external HTTP calls, and I/O. The default maximum is 200 threads.</p>
<h2>The Blocking I/O Impact: The Math</h2>
<p>Consider a Spring Boot service making a database call. Assume:</p>
<ul>
<li>Database query latency: 100ms average</li>
<li>Tomcat max threads: 200</li>
<li>Incoming request rate: 1,000 requests/second</li>
</ul>
<p>Under steady state, how many threads are occupied?</p>
<pre><code>Threads occupied = Request rate Ã— Average response time
                 = 1,000 req/s Ã— 0.1 s
                 = 100 threads occupied
</code></pre>
<p>100 threads occupied out of 200 â€” we're at 50% capacity with headroom. Now the database slows down to 500ms due to a slow query:</p>
<pre><code>Threads occupied = 1,000 req/s Ã— 0.5 s = 500 threads
</code></pre>
<p>500 threads required, only 200 available. The thread pool exhausts in milliseconds. New requests queue, then time out. This is the cascade.</p>
<p>The dangerous property: <strong>a 5Ã— increase in downstream latency causes a 5Ã— increase in required threads</strong>. Under load, systems don't degrade linearly â€” they collapse.</p>
<h2>Async vs Sync Controller Comparison</h2>
<p>The conventional Spring MVC model is synchronous. Every request blocks a thread:</p>
<pre><code class="language-java">// SYNC - holds Tomcat thread for entire duration
@GetMapping("/order/{id}")
public OrderResponse getOrder(@PathVariable String id) {
    Order order = orderRepository.findById(id).orElseThrow(); // blocks 20ms
    List&#x3C;Item> items = itemService.getItems(order.getId());   // blocks 50ms
    PriceResult price = pricingService.calculate(items);      // blocks 30ms
    return OrderResponse.from(order, items, price);
    // Total: ~100ms holding 1 Tomcat thread
}
</code></pre>
<p>Spring MVC supports <code>DeferredResult</code> and <code>Callable</code> for asynchronous processing, which releases the Tomcat thread while work proceeds on another thread:</p>
<pre><code class="language-java">// ASYNC with DeferredResult - releases Tomcat thread immediately
@GetMapping("/order/{id}")
public DeferredResult&#x3C;OrderResponse> getOrder(@PathVariable String id) {
    DeferredResult&#x3C;OrderResponse> result = new DeferredResult&#x3C;>(5000L);

    CompletableFuture
        .supplyAsync(() -> orderRepository.findById(id).orElseThrow(), asyncExecutor)
        .thenApplyAsync(order -> {
            List&#x3C;Item> items = itemService.getItems(order.getId());
            return Pair.of(order, items);
        }, asyncExecutor)
        .thenAcceptAsync(pair -> {
            PriceResult price = pricingService.calculate(pair.getSecond());
            result.setResult(OrderResponse.from(pair.getFirst(), pair.getSecond(), price));
        }, asyncExecutor)
        .exceptionally(ex -> {
            result.setErrorResult(ex);
            return null;
        });

    return result; // Tomcat thread is FREE after this return
}
</code></pre>
<p>Spring WebFlux (Reactor-based) takes this further with a reactive pipeline that uses a small number of event loop threads to handle many concurrent requests without blocking:</p>
<pre><code class="language-java">// WebFlux - non-blocking from top to bottom
@GetMapping("/order/{id}")
public Mono&#x3C;OrderResponse> getOrder(@PathVariable String id) {
    return orderRepository.findById(id) // reactive repo
        .flatMap(order -> itemService.getItemsReactive(order.getId())
            .flatMap(items -> pricingService.calculateReactive(items)
                .map(price -> OrderResponse.from(order, items, price))
            )
        );
}
</code></pre>
<p>WebFlux can handle 10,000+ concurrent requests with 8 threads â€” but it requires your entire stack to be non-blocking. A single blocking call inside a reactive chain pins an event loop thread and destroys your throughput.</p>
<h2>Connection Pool Exhaustion</h2>
<p>Thread pool exhaustion and database connection pool exhaustion are different problems that often arrive together. HikariCP defaults:</p>
<pre><code class="language-yaml">spring:
  datasource:
    hikari:
      maximum-pool-size: 10      # default - dangerously low
      minimum-idle: 10
      connection-timeout: 30000  # 30s - too high for production
      idle-timeout: 600000
      max-lifetime: 1800000
</code></pre>
<p>The right formula for HikariCP pool size:</p>
<pre><code>pool_size = (core_count * 2) + effective_spindle_count

For a 4-core server with SSD:
pool_size = (4 * 2) + 1 = 9 connections
</code></pre>
<p>This seems counterintuitively small. The reason: more connections than the database can process concurrently causes context switching at the DB server level that makes everything slower. HikariCP's own research shows ~10 connections often outperforms 100.</p>
<p>Set <code>connection-timeout</code> to match your SLA minus overhead â€” if your API must respond in 2 seconds and a query takes up to 1 second, your connection timeout should be under 500ms. A 30-second connection timeout means threads wait 30 seconds for a connection before failing â€” during which they hold Tomcat threads.</p>
<pre><code class="language-java">// Explicit HikariCP config for production
@Bean
public DataSource dataSource() {
    HikariConfig config = new HikariConfig();
    config.setJdbcUrl("jdbc:postgresql://db:5432/mydb");
    config.setMaximumPoolSize(10);
    config.setMinimumIdle(5);
    config.setConnectionTimeout(2000);   // Fail fast: 2s timeout
    config.setIdleTimeout(300000);       // 5 minutes
    config.setMaxLifetime(900000);       // 15 minutes
    config.setValidationTimeout(1000);   // 1s validation
    config.addDataSourceProperty("cachePrepStmts", "true");
    config.addDataSourceProperty("prepStmtCacheSize", "250");
    return new HikariDataSource(config);
}
</code></pre>
<h2>Backpressure Strategy</h2>
<p>When your thread pool is full, Tomcat queues requests in the <code>acceptCount</code> queue (default: 100). When that fills, new TCP connections are refused. This is Tomcat's built-in backpressure â€” it's crude but it works.</p>
<p>You can shape it:</p>
<pre><code class="language-properties">server.tomcat.threads.max=200
server.tomcat.threads.min-spare=20
server.tomcat.accept-count=50       # Keep queue short - fail fast
server.tomcat.max-connections=2000
server.connection-timeout=5000      # 5s connection timeout
</code></pre>
<p>A short <code>accept-count</code> means you fail fast when overloaded â€” clients see a connection refused immediately rather than waiting 30 seconds in queue. Failing fast is almost always better than hanging.</p>
<h2>Circuit Breaker Integration</h2>
<p>Thread pool exhaustion almost always traces to a slow downstream dependency. Wrap external calls with Resilience4j circuit breakers:</p>
<pre><code class="language-java">@Service
public class PaymentGatewayClient {

    private final CircuitBreaker circuitBreaker;
    private final TimeLimiter timeLimiter;

    public PaymentGatewayClient(CircuitBreakerRegistry registry,
                                 TimeLimiterRegistry timeLimiterRegistry) {
        CircuitBreakerConfig config = CircuitBreakerConfig.custom()
            .slidingWindowSize(20)
            .failureRateThreshold(50)        // Open after 50% failure rate
            .waitDurationInOpenState(Duration.ofSeconds(10))
            .permittedNumberOfCallsInHalfOpenState(5)
            .slowCallDurationThreshold(Duration.ofMillis(500)) // 500ms = slow
            .slowCallRateThreshold(80)        // Open if 80% calls are slow
            .build();

        this.circuitBreaker = registry.circuitBreaker("payment-gateway", config);

        TimeLimiterConfig tlConfig = TimeLimiterConfig.custom()
            .timeoutDuration(Duration.ofMillis(800))
            .cancelRunningFuture(true)
            .build();
        this.timeLimiter = timeLimiterRegistry.timeLimiter("payment-gateway", tlConfig);
    }

    public PaymentResult charge(PaymentRequest req) {
        Supplier&#x3C;CompletableFuture&#x3C;PaymentResult>> futureSupplier =
            () -> CompletableFuture.supplyAsync(() -> callExternalGateway(req), asyncExecutor);

        Callable&#x3C;PaymentResult> restrictedCall =
            TimeLimiter.decorateFutureSupplier(timeLimiter, futureSupplier);

        Callable&#x3C;PaymentResult> circuitBreakerCall =
            CircuitBreaker.decorateCallable(circuitBreaker, restrictedCall);

        return Try.ofCallable(circuitBreakerCall)
            .recover(CallNotPermittedException.class, e -> PaymentResult.circuitOpen())
            .recover(TimeoutException.class, e -> PaymentResult.timeout())
            .get();
    }
}
</code></pre>
<p>The <code>slowCallDurationThreshold</code> is critical. A circuit breaker that only trips on errors won't protect you from a slow dependency that eventually exhausts your thread pool while technically succeeding.</p>
<h2>Real Production Outage Scenario</h2>
<p><strong>System:</strong> Order processing service, Spring Boot 2.7, Tomcat 200 threads, HikariCP 10 connections, PostgreSQL RDS.</p>
<p><strong>Timeline:</strong></p>
<ul>
<li>14:00: RDS replica promotion during maintenance window, brief failover</li>
<li>14:03: During 30-second DB reconnect window, all 10 HikariCP connections time out waiting</li>
<li>14:03: Requests pile up waiting for DB connections (30s <code>connectionTimeout</code>)</li>
<li>14:04: All 200 Tomcat threads occupied, waiting for DB connections</li>
<li>14:04: Tomcat accept queue fills (50 requests), new connections refused</li>
<li>14:04: API gateway marks service unhealthy, starts shedding load</li>
<li>14:05: DB reconnects. HikariCP establishes connections. But...</li>
<li>14:05â€“14:08: Backlog of 200+ in-flight requests completes, some after 30s timeout</li>
<li>14:08: Service recovers on its own â€” but 5 minutes of downtime and thousands of errors</li>
</ul>
<p><strong>Root cause:</strong> A 30-second <code>connection-timeout</code> created a 30-second thread holding duration during DB unavailability. The fix was reducing <code>connection-timeout</code> to 2000ms and adding exponential backoff retry logic for transient DB failures.</p>
<h2>JVM Tuning for Thread-Heavy Applications</h2>
<p>Each thread reserves stack memory. Default stack size is 512KB on most JVMs:</p>
<pre><code>200 threads Ã— 512KB = 100MB of stack memory reserved
</code></pre>
<p>For applications with many threads, reduce stack size if your call stacks are shallow:</p>
<pre><code class="language-bash">-Xss256k   # Reduce thread stack from 512K to 256K
</code></pre>
<p>G1GC settings for latency-sensitive services:</p>
<pre><code class="language-bash">-XX:+UseG1GC
-XX:MaxGCPauseMillis=100        # Target 100ms max GC pause
-XX:G1HeapRegionSize=16m        # Larger regions for big heaps
-XX:InitiatingHeapOccupancyPercent=35
-XX:+ParallelRefProcEnabled
-XX:+DisableExplicitGC          # Prevent System.gc() calls
</code></pre>
<h2>Monitoring with Prometheus and Grafana</h2>
<p>Key metrics to track thread pool health:</p>
<pre><code class="language-yaml"># application.properties
management.endpoints.web.exposure.include=prometheus,health,metrics
management.metrics.enable.tomcat=true
</code></pre>
<pre><code class="language-java">// Custom metric: track thread pool utilization
@Component
public class ThreadPoolMetrics {

    private final ThreadPoolTaskExecutor asyncExecutor;
    private final MeterRegistry meterRegistry;

    @PostConstruct
    public void registerMetrics() {
        Gauge.builder("app.thread_pool.active_threads", asyncExecutor,
                      executor -> executor.getActiveCount())
            .description("Active threads in async executor")
            .register(meterRegistry);

        Gauge.builder("app.thread_pool.queue_size", asyncExecutor,
                      executor -> executor.getThreadPoolExecutor().getQueue().size())
            .description("Async executor queue depth")
            .register(meterRegistry);
    }
}
</code></pre>
<p>Grafana alert rules:</p>
<pre><code># Alert: Thread pool near exhaustion
tomcat_threads_busy_threads / tomcat_threads_config_max_threads > 0.85

# Alert: Connection pool exhausted
hikaricp_connections_pending > 0 for 30s

# Alert: High response latency (symptom of thread starvation)
http_server_requests_seconds_p99 > 2.0
</code></pre>
<h2>Thread Dump Analysis</h2>
<p>When a service is hanging, take a thread dump immediately:</p>
<pre><code class="language-bash">jstack &#x3C;pid> > thread-dump.txt
# Or via JMX:
kill -3 &#x3C;pid>   # Sends SIGQUIT, dumps to stdout
</code></pre>
<p>Patterns that indicate thread pool exhaustion:</p>
<pre><code># Thread blocked waiting for DB connection:
"http-nio-8080-exec-47" WAITING on com.zaxxer.hikari.util.ConcurrentBag$1
    at sun.misc.Unsafe.park(Native Method)
    at HikariPool.getConnection(HikariPool.java:213)
    at OrderController.getOrder(OrderController.java:45)

# Count blocked threads:
grep -c "WAITING on com.zaxxer.hikari" thread-dump.txt
</code></pre>
<p>If you see 50+ threads waiting on HikariCP, your connection pool is the bottleneck. If threads are waiting on external HTTP calls, your downstream is slow.</p>
<h2>Tomcat Configuration for Production</h2>
<pre><code class="language-java">@Bean
public TomcatServletWebServerFactory tomcatFactory() {
    TomcatServletWebServerFactory factory = new TomcatServletWebServerFactory();
    factory.addConnectorCustomizers(connector -> {
        ProtocolHandler handler = connector.getProtocolHandler();
        if (handler instanceof AbstractProtocol&#x3C;?> protocol) {
            protocol.setMaxThreads(200);
            protocol.setMinSpareThreads(20);
            protocol.setAcceptCount(50);
            protocol.setConnectionTimeout(5000);
            protocol.setKeepAliveTimeout(20000);
            protocol.setMaxKeepAliveRequests(200);
        }
    });
    return factory;
}
</code></pre>
<h2>Lessons Learned from Production</h2>
<p><strong>1. Short timeouts everywhere.</strong> Every blocking operation â€” DB query, HTTP call, lock acquisition â€” must have a timeout shorter than your SLA. A missing timeout is a thread leak waiting to happen.</p>
<p><strong>2. Size thread pools to match downstream capacity.</strong> If your DB can handle 10 concurrent queries, having 200 Tomcat threads is counterproductive â€” they'll all race for 10 connections. Align pool sizes across the call chain.</p>
<p><strong>3. Instrument thread pool utilization, not just request latency.</strong> P99 latency spikes are a lagging indicator. Thread pool utilization at 80% is an early warning.</p>
<p><strong>4. Fail fast under load.</strong> A 50-request <code>accept-count</code> and 2-second <code>connection-timeout</code> mean failures are visible in 2 seconds, not 30. Operators can respond; monitoring can alert. Silent accumulation is far worse.</p>
<p><strong>5. One slow downstream can take down your service.</strong> Circuit breakers are not optional in microservice architectures. Every external call that can be slow must be wrapped.</p>
<p>Thread pool exhaustion is entirely preventable once you understand the mechanics. The failure mode is almost always: slow downstream + missing timeout + no circuit breaker = cascading thread starvation. Fix any one of those three and the cascade stops.</p>
</article><div class="my-10 rounded-xl border border-yellow-200 bg-yellow-50 p-6"><div class="flex items-center gap-2 mb-1"><span class="text-lg">ğŸ“š</span><h3 class="text-base font-bold text-gray-900">Recommended Resources</h3></div><div class="space-y-4"><div class="flex items-start gap-3 bg-white rounded-lg p-4 border border-yellow-100"><div class="flex-1 min-w-0"><div class="flex items-center gap-2 flex-wrap mb-1"><span class="font-semibold text-gray-900 text-sm">Java Masterclass â€” Udemy</span><span class="text-xs bg-blue-100 text-blue-700 px-2 py-0.5 rounded-full font-medium">Best Seller</span></div><p class="text-xs text-gray-600">Comprehensive Java course covering Java 17+, OOP, concurrency, and modern APIs.</p></div><a href="https://www.udemy.com/course/java-the-complete-java-developer-course/" target="_blank" rel="noopener noreferrer" class="flex-shrink-0 text-xs bg-blue-600 text-white px-3 py-2 rounded-lg hover:bg-blue-700 transition-colors font-medium whitespace-nowrap">View Course<!-- --> â†’</a></div><div class="flex items-start gap-3 bg-white rounded-lg p-4 border border-yellow-100"><div class="flex-1 min-w-0"><div class="flex items-center gap-2 flex-wrap mb-1"><span class="font-semibold text-gray-900 text-sm">Effective Java, 3rd Edition</span><span class="text-xs bg-blue-100 text-blue-700 px-2 py-0.5 rounded-full font-medium">Must Read</span></div><p class="text-xs text-gray-600">Joshua Bloch&#x27;s classic guide to writing clear, correct, and efficient Java code.</p></div><a href="https://amzn.to/3RxIpuB" target="_blank" rel="noopener noreferrer" class="flex-shrink-0 text-xs bg-blue-600 text-white px-3 py-2 rounded-lg hover:bg-blue-700 transition-colors font-medium whitespace-nowrap">View on Amazon<!-- --> â†’</a></div><div class="flex items-start gap-3 bg-white rounded-lg p-4 border border-yellow-100"><div class="flex-1 min-w-0"><div class="flex items-center gap-2 flex-wrap mb-1"><span class="font-semibold text-gray-900 text-sm">Java Concurrency in Practice</span></div><p class="text-xs text-gray-600">The authoritative book on writing thread-safe, concurrent Java programs.</p></div><a href="https://amzn.to/3Rx3xM4" target="_blank" rel="noopener noreferrer" class="flex-shrink-0 text-xs bg-blue-600 text-white px-3 py-2 rounded-lg hover:bg-blue-700 transition-colors font-medium whitespace-nowrap">View on Amazon<!-- --> â†’</a></div></div></div><div class="mt-10 pt-8 border-t border-gray-100"><p class="text-sm text-gray-500 mb-3">Found this useful? Share it:</p><div class="flex gap-3"><a href="https://twitter.com/intent/tweet?text=Thread%20Pool%20Exhaustion%20in%20Spring%20Boot%3A%20Diagnosis%2C%20Prevention%2C%20and%20Recovery&amp;url=https%3A%2F%2Fcodesprintpro.com%2Fblog%2Fspring-boot-thread-pool-exhaustion%2F" target="_blank" rel="noopener noreferrer" class="text-xs bg-gray-900 text-white px-4 py-2 rounded-lg hover:bg-gray-700 transition-colors">Share on X/Twitter</a><a href="https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fcodesprintpro.com%2Fblog%2Fspring-boot-thread-pool-exhaustion%2F" target="_blank" rel="noopener noreferrer" class="text-xs bg-blue-600 text-white px-4 py-2 rounded-lg hover:bg-blue-700 transition-colors">Share on LinkedIn</a></div></div></div><aside class="hidden lg:block w-64 flex-shrink-0"><nav class="hidden lg:block sticky top-24"><h4 class="text-xs font-semibold uppercase tracking-widest text-gray-400 mb-3">On This Page</h4><ul class="space-y-1"><li class=""><a href="#how-tomcat-thread-pools-work" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">How Tomcat Thread Pools Work</a></li><li class=""><a href="#the-blocking-io-impact-the-math" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">The Blocking I/O Impact: The Math</a></li><li class=""><a href="#async-vs-sync-controller-comparison" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Async vs Sync Controller Comparison</a></li><li class=""><a href="#connection-pool-exhaustion" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Connection Pool Exhaustion</a></li><li class=""><a href="#backpressure-strategy" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Backpressure Strategy</a></li><li class=""><a href="#circuit-breaker-integration" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Circuit Breaker Integration</a></li><li class=""><a href="#real-production-outage-scenario" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Real Production Outage Scenario</a></li><li class=""><a href="#jvm-tuning-for-thread-heavy-applications" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">JVM Tuning for Thread-Heavy Applications</a></li><li class=""><a href="#monitoring-with-prometheus-and-grafana" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Monitoring with Prometheus and Grafana</a></li><li class=""><a href="#thread-dump-analysis" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Thread Dump Analysis</a></li><li class=""><a href="#tomcat-configuration-for-production" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Tomcat Configuration for Production</a></li><li class=""><a href="#lessons-learned-from-production" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Lessons Learned from Production</a></li></ul></nav></aside></div><div class="mt-16 pt-10 border-t border-gray-100"><h2 class="text-2xl font-bold text-gray-900 mb-6">Related Articles</h2><div class="grid grid-cols-1 md:grid-cols-3 gap-6"><a href="/blog/java-concurrency-patterns/"><article class="group bg-white rounded-xl border border-gray-200 p-6 h-full cursor-pointer hover:border-blue-300 hover:shadow-lg transition-all"><span class="inline-block text-xs font-semibold px-3 py-1 rounded-full mb-3 bg-orange-100 text-orange-700">Java</span><h3 class="text-lg font-bold text-gray-900 mb-2 group-hover:text-blue-600 transition-colors leading-snug">Java Concurrency Patterns: CompletableFuture, Structured Concurrency, and Thread-Safe Design</h3><p class="text-gray-600 text-sm mb-4 line-clamp-3">Java concurrency has three eras: raw  and  (Java 1-4), the  framework (Java 5+), and the virtual thread/structured concurrency era (Java 21+). Each era&#x27;s patterns still exist in production codebases. Understanding all thâ€¦</p><div class="flex items-center justify-between text-xs text-gray-400"><span>Jul 8, 2025</span><span class="flex items-center gap-1"><svg class="w-3 h-3" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>7 min read</span></div><div class="mt-3 flex flex-wrap gap-1"><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->java</span><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->concurrency</span><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->completablefuture</span></div></article></a><a href="/blog/java-memory-management-deep-dive/"><article class="group bg-white rounded-xl border border-gray-200 p-6 h-full cursor-pointer hover:border-blue-300 hover:shadow-lg transition-all"><span class="inline-block text-xs font-semibold px-3 py-1 rounded-full mb-3 bg-orange-100 text-orange-700">Java</span><h3 class="text-lg font-bold text-gray-900 mb-2 group-hover:text-blue-600 transition-colors leading-snug">Java Memory Management Deep Dive: Heap, GC, and Production Tuning</h3><p class="text-gray-600 text-sm mb-4 line-clamp-3">Java&#x27;s garbage collector is the single biggest source of unexplained latency spikes in production services. A GC pause of 2 seconds is invisible in most logs but visible to every user who happened to make a request durinâ€¦</p><div class="flex items-center justify-between text-xs text-gray-400"><span>Jun 13, 2025</span><span class="flex items-center gap-1"><svg class="w-3 h-3" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>7 min read</span></div><div class="mt-3 flex flex-wrap gap-1"><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->java</span><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->jvm</span><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->garbage collection</span></div></article></a><a href="/blog/spring-security-oauth2-jwt/"><article class="group bg-white rounded-xl border border-gray-200 p-6 h-full cursor-pointer hover:border-blue-300 hover:shadow-lg transition-all"><span class="inline-block text-xs font-semibold px-3 py-1 rounded-full mb-3 bg-orange-100 text-orange-700">Java</span><h3 class="text-lg font-bold text-gray-900 mb-2 group-hover:text-blue-600 transition-colors leading-snug">Spring Security OAuth2 and JWT: Production Implementation Guide</h3><p class="text-gray-600 text-sm mb-4 line-clamp-3">Spring Security is one of the most powerful and most misunderstood frameworks in the Java ecosystem. Its flexibility is its strength â€” and its complexity. Misconfigured security is worse than no security, because it giveâ€¦</p><div class="flex items-center justify-between text-xs text-gray-400"><span>Jun 3, 2025</span><span class="flex items-center gap-1"><svg class="w-3 h-3" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>7 min read</span></div><div class="mt-3 flex flex-wrap gap-1"><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->spring security</span><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->oauth2</span><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->jwt</span></div></article></a></div></div><div class="mt-12 text-center"><a class="inline-flex items-center gap-2 text-blue-600 hover:text-blue-700 font-medium transition-colors" href="/blog/">â† Back to all articles</a></div></div></div><footer class="bg-gray-900 text-white py-12"><div class="container mx-auto px-4 sm:px-6 lg:px-8"><div class="grid grid-cols-1 md:grid-cols-4 gap-8 mb-8"><div class="col-span-1 md:col-span-1"><div><a class="text-xl font-bold block mb-3 text-white hover:text-blue-400 transition-colors" href="/">CodeSprintPro</a></div><p class="text-gray-400 text-sm mb-4 leading-relaxed">Deep-dive technical content on System Design, Java, Databases, AI/ML, and AWS â€” by Sachin Sarawgi.</p><div class="flex space-x-4"><a href="https://github.com/codesprintpro" target="_blank" rel="noopener noreferrer" class="text-gray-400 hover:text-white transition-colors" aria-label="Visit GitHub profile"><i class="fab fa-github text-xl"></i></a><a href="https://www.linkedin.com/in/sachin-sarawgi/" target="_blank" rel="noopener noreferrer" class="text-gray-400 hover:text-white transition-colors" aria-label="Visit LinkedIn profile"><i class="fab fa-linkedin text-xl"></i></a><a href="https://medium.com/@codesprintpro" target="_blank" rel="noopener noreferrer" class="text-gray-400 hover:text-white transition-colors" aria-label="Visit Medium profile"><i class="fab fa-medium text-xl"></i></a></div></div><div><h3 class="text-sm font-semibold uppercase tracking-widest text-gray-400 mb-4">Quick Links</h3><ul class="space-y-2"><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">Blog</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/#about">About</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/#portfolio">Portfolio</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/#contact">Contact</a></div></li></ul></div><div><h3 class="text-sm font-semibold uppercase tracking-widest text-gray-400 mb-4">Categories</h3><ul class="space-y-2"><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">System Design</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">Java</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">Databases</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">AI/ML</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">AWS</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">Messaging</a></div></li></ul></div><div><h3 class="text-sm font-semibold uppercase tracking-widest text-gray-400 mb-4">Contact</h3><ul class="space-y-2 text-gray-400 text-sm"><li><a href="mailto:sachinsarawgi201143@gmail.com" class="hover:text-white transition-colors flex items-center gap-2"><i class="fas fa-envelope"></i> Email</a></li><li><a href="https://www.linkedin.com/in/sachin-sarawgi/" target="_blank" rel="noopener noreferrer" class="hover:text-white transition-colors flex items-center gap-2"><i class="fab fa-linkedin"></i> LinkedIn</a></li><li><a href="https://github.com/codesprintpro" target="_blank" rel="noopener noreferrer" class="hover:text-white transition-colors flex items-center gap-2"><i class="fab fa-github"></i> GitHub</a></li></ul></div></div><div class="border-t border-gray-800 pt-6 flex flex-col md:flex-row justify-between items-center gap-2"><p class="text-gray-500 text-sm">Â© <!-- -->2026<!-- --> CodeSprintPro Â· Sachin Sarawgi. All rights reserved.</p><p class="text-gray-600 text-xs">Built with Next.js Â· TailwindCSS Â· Deployed on GitHub Pages</p></div></div></footer></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"Thread Pool Exhaustion in Spring Boot: Diagnosis, Prevention, and Recovery","description":"How Tomcat thread pools work, why blocking I/O kills throughput, and the production patterns that prevent thread pool exhaustion in Spring Boot services. Includes real outage scenario and JVM tuning.","date":"2025-04-08","category":"Java","tags":["spring boot","java","tomcat","thread pool","async","performance","resilience"],"featured":false,"affiliateSection":"java-courses","slug":"spring-boot-thread-pool-exhaustion","readingTime":"9 min read","excerpt":"Thread pool exhaustion is one of the most deceptive production failures in Spring Boot services. The service is technically running â€” JVM process alive, health endpoint returning 200, no OutOfMemoryError in logs â€” but reâ€¦","contentHtml":"\u003cp\u003eThread pool exhaustion is one of the most deceptive production failures in Spring Boot services. The service is technically running â€” JVM process alive, health endpoint returning 200, no OutOfMemoryError in logs â€” but requests pile up, latencies spike to 30 seconds, and then everything times out. On-call gets paged. The fix is usually a restart, which masks the root cause until it happens again.\u003c/p\u003e\n\u003cp\u003eThis article explains the mechanism precisely, shows you the math, and gives you the production patterns to prevent it.\u003c/p\u003e\n\u003ch2\u003eHow Tomcat Thread Pools Work\u003c/h2\u003e\n\u003cp\u003eSpring Boot's default embedded server is Tomcat. Tomcat uses a fixed thread pool to process HTTP requests.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eHTTP Request\n     â”‚\n     â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Acceptor Thread   â”‚  (accepts TCP connections, non-blocking)\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n         â”‚\n         â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Connection Queue  â”‚  (bounded, default maxConnections=8192)\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n         â”‚\n         â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Tomcat Thread Pool                â”‚\nâ”‚  min: 10 threads (minSpareThreads) â”‚\nâ”‚  max: 200 threads (maxThreads)     â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n         â”‚\n         â–¼\n    @Controller method executes on this thread\n    (BLOCKS until method returns)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe critical constraint: \u003cstrong\u003eeach active HTTP request holds exactly one Tomcat thread\u003c/strong\u003e. The thread is occupied for the entire duration of request processing â€” including all database calls, external HTTP calls, and I/O. The default maximum is 200 threads.\u003c/p\u003e\n\u003ch2\u003eThe Blocking I/O Impact: The Math\u003c/h2\u003e\n\u003cp\u003eConsider a Spring Boot service making a database call. Assume:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDatabase query latency: 100ms average\u003c/li\u003e\n\u003cli\u003eTomcat max threads: 200\u003c/li\u003e\n\u003cli\u003eIncoming request rate: 1,000 requests/second\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eUnder steady state, how many threads are occupied?\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eThreads occupied = Request rate Ã— Average response time\n                 = 1,000 req/s Ã— 0.1 s\n                 = 100 threads occupied\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e100 threads occupied out of 200 â€” we're at 50% capacity with headroom. Now the database slows down to 500ms due to a slow query:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eThreads occupied = 1,000 req/s Ã— 0.5 s = 500 threads\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e500 threads required, only 200 available. The thread pool exhausts in milliseconds. New requests queue, then time out. This is the cascade.\u003c/p\u003e\n\u003cp\u003eThe dangerous property: \u003cstrong\u003ea 5Ã— increase in downstream latency causes a 5Ã— increase in required threads\u003c/strong\u003e. Under load, systems don't degrade linearly â€” they collapse.\u003c/p\u003e\n\u003ch2\u003eAsync vs Sync Controller Comparison\u003c/h2\u003e\n\u003cp\u003eThe conventional Spring MVC model is synchronous. Every request blocks a thread:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003e// SYNC - holds Tomcat thread for entire duration\n@GetMapping(\"/order/{id}\")\npublic OrderResponse getOrder(@PathVariable String id) {\n    Order order = orderRepository.findById(id).orElseThrow(); // blocks 20ms\n    List\u0026#x3C;Item\u003e items = itemService.getItems(order.getId());   // blocks 50ms\n    PriceResult price = pricingService.calculate(items);      // blocks 30ms\n    return OrderResponse.from(order, items, price);\n    // Total: ~100ms holding 1 Tomcat thread\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eSpring MVC supports \u003ccode\u003eDeferredResult\u003c/code\u003e and \u003ccode\u003eCallable\u003c/code\u003e for asynchronous processing, which releases the Tomcat thread while work proceeds on another thread:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003e// ASYNC with DeferredResult - releases Tomcat thread immediately\n@GetMapping(\"/order/{id}\")\npublic DeferredResult\u0026#x3C;OrderResponse\u003e getOrder(@PathVariable String id) {\n    DeferredResult\u0026#x3C;OrderResponse\u003e result = new DeferredResult\u0026#x3C;\u003e(5000L);\n\n    CompletableFuture\n        .supplyAsync(() -\u003e orderRepository.findById(id).orElseThrow(), asyncExecutor)\n        .thenApplyAsync(order -\u003e {\n            List\u0026#x3C;Item\u003e items = itemService.getItems(order.getId());\n            return Pair.of(order, items);\n        }, asyncExecutor)\n        .thenAcceptAsync(pair -\u003e {\n            PriceResult price = pricingService.calculate(pair.getSecond());\n            result.setResult(OrderResponse.from(pair.getFirst(), pair.getSecond(), price));\n        }, asyncExecutor)\n        .exceptionally(ex -\u003e {\n            result.setErrorResult(ex);\n            return null;\n        });\n\n    return result; // Tomcat thread is FREE after this return\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eSpring WebFlux (Reactor-based) takes this further with a reactive pipeline that uses a small number of event loop threads to handle many concurrent requests without blocking:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003e// WebFlux - non-blocking from top to bottom\n@GetMapping(\"/order/{id}\")\npublic Mono\u0026#x3C;OrderResponse\u003e getOrder(@PathVariable String id) {\n    return orderRepository.findById(id) // reactive repo\n        .flatMap(order -\u003e itemService.getItemsReactive(order.getId())\n            .flatMap(items -\u003e pricingService.calculateReactive(items)\n                .map(price -\u003e OrderResponse.from(order, items, price))\n            )\n        );\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWebFlux can handle 10,000+ concurrent requests with 8 threads â€” but it requires your entire stack to be non-blocking. A single blocking call inside a reactive chain pins an event loop thread and destroys your throughput.\u003c/p\u003e\n\u003ch2\u003eConnection Pool Exhaustion\u003c/h2\u003e\n\u003cp\u003eThread pool exhaustion and database connection pool exhaustion are different problems that often arrive together. HikariCP defaults:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-yaml\"\u003espring:\n  datasource:\n    hikari:\n      maximum-pool-size: 10      # default - dangerously low\n      minimum-idle: 10\n      connection-timeout: 30000  # 30s - too high for production\n      idle-timeout: 600000\n      max-lifetime: 1800000\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe right formula for HikariCP pool size:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003epool_size = (core_count * 2) + effective_spindle_count\n\nFor a 4-core server with SSD:\npool_size = (4 * 2) + 1 = 9 connections\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis seems counterintuitively small. The reason: more connections than the database can process concurrently causes context switching at the DB server level that makes everything slower. HikariCP's own research shows ~10 connections often outperforms 100.\u003c/p\u003e\n\u003cp\u003eSet \u003ccode\u003econnection-timeout\u003c/code\u003e to match your SLA minus overhead â€” if your API must respond in 2 seconds and a query takes up to 1 second, your connection timeout should be under 500ms. A 30-second connection timeout means threads wait 30 seconds for a connection before failing â€” during which they hold Tomcat threads.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003e// Explicit HikariCP config for production\n@Bean\npublic DataSource dataSource() {\n    HikariConfig config = new HikariConfig();\n    config.setJdbcUrl(\"jdbc:postgresql://db:5432/mydb\");\n    config.setMaximumPoolSize(10);\n    config.setMinimumIdle(5);\n    config.setConnectionTimeout(2000);   // Fail fast: 2s timeout\n    config.setIdleTimeout(300000);       // 5 minutes\n    config.setMaxLifetime(900000);       // 15 minutes\n    config.setValidationTimeout(1000);   // 1s validation\n    config.addDataSourceProperty(\"cachePrepStmts\", \"true\");\n    config.addDataSourceProperty(\"prepStmtCacheSize\", \"250\");\n    return new HikariDataSource(config);\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eBackpressure Strategy\u003c/h2\u003e\n\u003cp\u003eWhen your thread pool is full, Tomcat queues requests in the \u003ccode\u003eacceptCount\u003c/code\u003e queue (default: 100). When that fills, new TCP connections are refused. This is Tomcat's built-in backpressure â€” it's crude but it works.\u003c/p\u003e\n\u003cp\u003eYou can shape it:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-properties\"\u003eserver.tomcat.threads.max=200\nserver.tomcat.threads.min-spare=20\nserver.tomcat.accept-count=50       # Keep queue short - fail fast\nserver.tomcat.max-connections=2000\nserver.connection-timeout=5000      # 5s connection timeout\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eA short \u003ccode\u003eaccept-count\u003c/code\u003e means you fail fast when overloaded â€” clients see a connection refused immediately rather than waiting 30 seconds in queue. Failing fast is almost always better than hanging.\u003c/p\u003e\n\u003ch2\u003eCircuit Breaker Integration\u003c/h2\u003e\n\u003cp\u003eThread pool exhaustion almost always traces to a slow downstream dependency. Wrap external calls with Resilience4j circuit breakers:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003e@Service\npublic class PaymentGatewayClient {\n\n    private final CircuitBreaker circuitBreaker;\n    private final TimeLimiter timeLimiter;\n\n    public PaymentGatewayClient(CircuitBreakerRegistry registry,\n                                 TimeLimiterRegistry timeLimiterRegistry) {\n        CircuitBreakerConfig config = CircuitBreakerConfig.custom()\n            .slidingWindowSize(20)\n            .failureRateThreshold(50)        // Open after 50% failure rate\n            .waitDurationInOpenState(Duration.ofSeconds(10))\n            .permittedNumberOfCallsInHalfOpenState(5)\n            .slowCallDurationThreshold(Duration.ofMillis(500)) // 500ms = slow\n            .slowCallRateThreshold(80)        // Open if 80% calls are slow\n            .build();\n\n        this.circuitBreaker = registry.circuitBreaker(\"payment-gateway\", config);\n\n        TimeLimiterConfig tlConfig = TimeLimiterConfig.custom()\n            .timeoutDuration(Duration.ofMillis(800))\n            .cancelRunningFuture(true)\n            .build();\n        this.timeLimiter = timeLimiterRegistry.timeLimiter(\"payment-gateway\", tlConfig);\n    }\n\n    public PaymentResult charge(PaymentRequest req) {\n        Supplier\u0026#x3C;CompletableFuture\u0026#x3C;PaymentResult\u003e\u003e futureSupplier =\n            () -\u003e CompletableFuture.supplyAsync(() -\u003e callExternalGateway(req), asyncExecutor);\n\n        Callable\u0026#x3C;PaymentResult\u003e restrictedCall =\n            TimeLimiter.decorateFutureSupplier(timeLimiter, futureSupplier);\n\n        Callable\u0026#x3C;PaymentResult\u003e circuitBreakerCall =\n            CircuitBreaker.decorateCallable(circuitBreaker, restrictedCall);\n\n        return Try.ofCallable(circuitBreakerCall)\n            .recover(CallNotPermittedException.class, e -\u003e PaymentResult.circuitOpen())\n            .recover(TimeoutException.class, e -\u003e PaymentResult.timeout())\n            .get();\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe \u003ccode\u003eslowCallDurationThreshold\u003c/code\u003e is critical. A circuit breaker that only trips on errors won't protect you from a slow dependency that eventually exhausts your thread pool while technically succeeding.\u003c/p\u003e\n\u003ch2\u003eReal Production Outage Scenario\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eSystem:\u003c/strong\u003e Order processing service, Spring Boot 2.7, Tomcat 200 threads, HikariCP 10 connections, PostgreSQL RDS.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eTimeline:\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e14:00: RDS replica promotion during maintenance window, brief failover\u003c/li\u003e\n\u003cli\u003e14:03: During 30-second DB reconnect window, all 10 HikariCP connections time out waiting\u003c/li\u003e\n\u003cli\u003e14:03: Requests pile up waiting for DB connections (30s \u003ccode\u003econnectionTimeout\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003e14:04: All 200 Tomcat threads occupied, waiting for DB connections\u003c/li\u003e\n\u003cli\u003e14:04: Tomcat accept queue fills (50 requests), new connections refused\u003c/li\u003e\n\u003cli\u003e14:04: API gateway marks service unhealthy, starts shedding load\u003c/li\u003e\n\u003cli\u003e14:05: DB reconnects. HikariCP establishes connections. But...\u003c/li\u003e\n\u003cli\u003e14:05â€“14:08: Backlog of 200+ in-flight requests completes, some after 30s timeout\u003c/li\u003e\n\u003cli\u003e14:08: Service recovers on its own â€” but 5 minutes of downtime and thousands of errors\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eRoot cause:\u003c/strong\u003e A 30-second \u003ccode\u003econnection-timeout\u003c/code\u003e created a 30-second thread holding duration during DB unavailability. The fix was reducing \u003ccode\u003econnection-timeout\u003c/code\u003e to 2000ms and adding exponential backoff retry logic for transient DB failures.\u003c/p\u003e\n\u003ch2\u003eJVM Tuning for Thread-Heavy Applications\u003c/h2\u003e\n\u003cp\u003eEach thread reserves stack memory. Default stack size is 512KB on most JVMs:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e200 threads Ã— 512KB = 100MB of stack memory reserved\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eFor applications with many threads, reduce stack size if your call stacks are shallow:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e-Xss256k   # Reduce thread stack from 512K to 256K\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eG1GC settings for latency-sensitive services:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e-XX:+UseG1GC\n-XX:MaxGCPauseMillis=100        # Target 100ms max GC pause\n-XX:G1HeapRegionSize=16m        # Larger regions for big heaps\n-XX:InitiatingHeapOccupancyPercent=35\n-XX:+ParallelRefProcEnabled\n-XX:+DisableExplicitGC          # Prevent System.gc() calls\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eMonitoring with Prometheus and Grafana\u003c/h2\u003e\n\u003cp\u003eKey metrics to track thread pool health:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-yaml\"\u003e# application.properties\nmanagement.endpoints.web.exposure.include=prometheus,health,metrics\nmanagement.metrics.enable.tomcat=true\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003e// Custom metric: track thread pool utilization\n@Component\npublic class ThreadPoolMetrics {\n\n    private final ThreadPoolTaskExecutor asyncExecutor;\n    private final MeterRegistry meterRegistry;\n\n    @PostConstruct\n    public void registerMetrics() {\n        Gauge.builder(\"app.thread_pool.active_threads\", asyncExecutor,\n                      executor -\u003e executor.getActiveCount())\n            .description(\"Active threads in async executor\")\n            .register(meterRegistry);\n\n        Gauge.builder(\"app.thread_pool.queue_size\", asyncExecutor,\n                      executor -\u003e executor.getThreadPoolExecutor().getQueue().size())\n            .description(\"Async executor queue depth\")\n            .register(meterRegistry);\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eGrafana alert rules:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e# Alert: Thread pool near exhaustion\ntomcat_threads_busy_threads / tomcat_threads_config_max_threads \u003e 0.85\n\n# Alert: Connection pool exhausted\nhikaricp_connections_pending \u003e 0 for 30s\n\n# Alert: High response latency (symptom of thread starvation)\nhttp_server_requests_seconds_p99 \u003e 2.0\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eThread Dump Analysis\u003c/h2\u003e\n\u003cp\u003eWhen a service is hanging, take a thread dump immediately:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003ejstack \u0026#x3C;pid\u003e \u003e thread-dump.txt\n# Or via JMX:\nkill -3 \u0026#x3C;pid\u003e   # Sends SIGQUIT, dumps to stdout\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003ePatterns that indicate thread pool exhaustion:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e# Thread blocked waiting for DB connection:\n\"http-nio-8080-exec-47\" WAITING on com.zaxxer.hikari.util.ConcurrentBag$1\n    at sun.misc.Unsafe.park(Native Method)\n    at HikariPool.getConnection(HikariPool.java:213)\n    at OrderController.getOrder(OrderController.java:45)\n\n# Count blocked threads:\ngrep -c \"WAITING on com.zaxxer.hikari\" thread-dump.txt\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIf you see 50+ threads waiting on HikariCP, your connection pool is the bottleneck. If threads are waiting on external HTTP calls, your downstream is slow.\u003c/p\u003e\n\u003ch2\u003eTomcat Configuration for Production\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003e@Bean\npublic TomcatServletWebServerFactory tomcatFactory() {\n    TomcatServletWebServerFactory factory = new TomcatServletWebServerFactory();\n    factory.addConnectorCustomizers(connector -\u003e {\n        ProtocolHandler handler = connector.getProtocolHandler();\n        if (handler instanceof AbstractProtocol\u0026#x3C;?\u003e protocol) {\n            protocol.setMaxThreads(200);\n            protocol.setMinSpareThreads(20);\n            protocol.setAcceptCount(50);\n            protocol.setConnectionTimeout(5000);\n            protocol.setKeepAliveTimeout(20000);\n            protocol.setMaxKeepAliveRequests(200);\n        }\n    });\n    return factory;\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eLessons Learned from Production\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e1. Short timeouts everywhere.\u003c/strong\u003e Every blocking operation â€” DB query, HTTP call, lock acquisition â€” must have a timeout shorter than your SLA. A missing timeout is a thread leak waiting to happen.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e2. Size thread pools to match downstream capacity.\u003c/strong\u003e If your DB can handle 10 concurrent queries, having 200 Tomcat threads is counterproductive â€” they'll all race for 10 connections. Align pool sizes across the call chain.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e3. Instrument thread pool utilization, not just request latency.\u003c/strong\u003e P99 latency spikes are a lagging indicator. Thread pool utilization at 80% is an early warning.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e4. Fail fast under load.\u003c/strong\u003e A 50-request \u003ccode\u003eaccept-count\u003c/code\u003e and 2-second \u003ccode\u003econnection-timeout\u003c/code\u003e mean failures are visible in 2 seconds, not 30. Operators can respond; monitoring can alert. Silent accumulation is far worse.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e5. One slow downstream can take down your service.\u003c/strong\u003e Circuit breakers are not optional in microservice architectures. Every external call that can be slow must be wrapped.\u003c/p\u003e\n\u003cp\u003eThread pool exhaustion is entirely preventable once you understand the mechanics. The failure mode is almost always: slow downstream + missing timeout + no circuit breaker = cascading thread starvation. Fix any one of those three and the cascade stops.\u003c/p\u003e\n","tableOfContents":[{"id":"how-tomcat-thread-pools-work","text":"How Tomcat Thread Pools Work","level":2},{"id":"the-blocking-io-impact-the-math","text":"The Blocking I/O Impact: The Math","level":2},{"id":"async-vs-sync-controller-comparison","text":"Async vs Sync Controller Comparison","level":2},{"id":"connection-pool-exhaustion","text":"Connection Pool Exhaustion","level":2},{"id":"backpressure-strategy","text":"Backpressure Strategy","level":2},{"id":"circuit-breaker-integration","text":"Circuit Breaker Integration","level":2},{"id":"real-production-outage-scenario","text":"Real Production Outage Scenario","level":2},{"id":"jvm-tuning-for-thread-heavy-applications","text":"JVM Tuning for Thread-Heavy Applications","level":2},{"id":"monitoring-with-prometheus-and-grafana","text":"Monitoring with Prometheus and Grafana","level":2},{"id":"thread-dump-analysis","text":"Thread Dump Analysis","level":2},{"id":"tomcat-configuration-for-production","text":"Tomcat Configuration for Production","level":2},{"id":"lessons-learned-from-production","text":"Lessons Learned from Production","level":2}]},"relatedPosts":[{"title":"Java Concurrency Patterns: CompletableFuture, Structured Concurrency, and Thread-Safe Design","description":"Production Java concurrency: CompletableFuture pipelines, handling exceptions in async chains, Java 21 structured concurrency, thread-safe collection patterns, and the concurrency bugs that cause data corruption.","date":"2025-07-08","category":"Java","tags":["java","concurrency","completablefuture","virtual threads","java21","thread-safe","async"],"featured":false,"affiliateSection":"java-courses","slug":"java-concurrency-patterns","readingTime":"7 min read","excerpt":"Java concurrency has three eras: raw  and  (Java 1-4), the  framework (Java 5+), and the virtual thread/structured concurrency era (Java 21+). Each era's patterns still exist in production codebases. Understanding all thâ€¦"},{"title":"Java Memory Management Deep Dive: Heap, GC, and Production Tuning","description":"How the JVM allocates memory, how G1GC and ZGC work under the hood, heap analysis with JVM tools, and the GC tuning decisions that eliminate latency spikes in production Java services.","date":"2025-06-13","category":"Java","tags":["java","jvm","garbage collection","g1gc","zgc","heap","memory management","performance"],"featured":false,"affiliateSection":"java-courses","slug":"java-memory-management-deep-dive","readingTime":"7 min read","excerpt":"Java's garbage collector is the single biggest source of unexplained latency spikes in production services. A GC pause of 2 seconds is invisible in most logs but visible to every user who happened to make a request durinâ€¦"},{"title":"Spring Security OAuth2 and JWT: Production Implementation Guide","description":"Complete Spring Security OAuth2 implementation: JWT token validation, Resource Server configuration, method-level security, custom UserDetailsService, refresh token rotation, and the security pitfalls that lead to authentication bypasses.","date":"2025-06-03","category":"Java","tags":["spring security","oauth2","jwt","spring boot","authentication","authorization","java","security"],"featured":false,"affiliateSection":"java-courses","slug":"spring-security-oauth2-jwt","readingTime":"7 min read","excerpt":"Spring Security is one of the most powerful and most misunderstood frameworks in the Java ecosystem. Its flexibility is its strength â€” and its complexity. Misconfigured security is worse than no security, because it giveâ€¦"}]},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"spring-boot-thread-pool-exhaustion"},"buildId":"rpFn_jslWZ9qPkJwor7RD","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>