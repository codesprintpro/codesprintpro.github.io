<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8" data-next-head=""/><meta name="viewport" content="width=device-width" data-next-head=""/><title data-next-head="">Redis Beyond Cache: Sorted Sets, Streams, and Pub/Sub Patterns<!-- --> | CodeSprintPro</title><meta name="description" content="Redis is far more than a cache. Explore how sorted sets power leaderboards, streams enable event sourcing, and pub/sub enables real-time notifications ‚Äî with production Java examples." data-next-head=""/><meta name="author" content="Sachin Sarawgi" data-next-head=""/><link rel="canonical" href="https://codesprintpro.com/blog/redis-beyond-cache/" data-next-head=""/><meta property="og:type" content="article" data-next-head=""/><meta property="og:title" content="Redis Beyond Cache: Sorted Sets, Streams, and Pub/Sub Patterns" data-next-head=""/><meta property="og:description" content="Redis is far more than a cache. Explore how sorted sets power leaderboards, streams enable event sourcing, and pub/sub enables real-time notifications ‚Äî with production Java examples." data-next-head=""/><meta property="og:url" content="https://codesprintpro.com/blog/redis-beyond-cache/" data-next-head=""/><meta property="og:image" content="https://codesprintpro.com/images/og-default.jpg" data-next-head=""/><meta property="og:site_name" content="CodeSprintPro" data-next-head=""/><meta property="article:published_time" content="2025-01-22" data-next-head=""/><meta property="article:author" content="Sachin Sarawgi" data-next-head=""/><meta property="article:section" content="Databases" data-next-head=""/><meta property="article:tag" content="redis" data-next-head=""/><meta property="article:tag" content="cache" data-next-head=""/><meta property="article:tag" content="java" data-next-head=""/><meta property="article:tag" content="distributed systems" data-next-head=""/><meta property="article:tag" content="streams" data-next-head=""/><meta name="twitter:card" content="summary_large_image" data-next-head=""/><meta name="twitter:title" content="Redis Beyond Cache: Sorted Sets, Streams, and Pub/Sub Patterns" data-next-head=""/><meta name="twitter:description" content="Redis is far more than a cache. Explore how sorted sets power leaderboards, streams enable event sourcing, and pub/sub enables real-time notifications ‚Äî with production Java examples." data-next-head=""/><meta name="twitter:image" content="https://codesprintpro.com/images/og-default.jpg" data-next-head=""/><script type="application/ld+json" data-next-head="">{"@context":"https://schema.org","@type":"BlogPosting","headline":"Redis Beyond Cache: Sorted Sets, Streams, and Pub/Sub Patterns","description":"Redis is far more than a cache. Explore how sorted sets power leaderboards, streams enable event sourcing, and pub/sub enables real-time notifications ‚Äî with production Java examples.","image":"https://codesprintpro.com/images/og-default.jpg","datePublished":"2025-01-22","dateModified":"2025-01-22","author":{"@type":"Person","name":"Sachin Sarawgi","url":"https://codesprintpro.com","sameAs":["https://www.linkedin.com/in/sachin-sarawgi/","https://github.com/codesprintpro","https://medium.com/@codesprintpro"]},"publisher":{"@type":"Organization","name":"CodeSprintPro","url":"https://codesprintpro.com","logo":{"@type":"ImageObject","url":"https://codesprintpro.com/favicon/favicon-96x96.png"}},"mainEntityOfPage":{"@type":"WebPage","@id":"https://codesprintpro.com/blog/redis-beyond-cache/"},"keywords":"redis, cache, java, distributed systems, streams","articleSection":"Databases"}</script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" integrity="sha512-9usAa10IRO0HhonpyAIVpjrylPvoDwiPUiKdWk5t3PyolY1cOd4DSE0Ga+ri4AuTroPR5aQvXU9xC6qOPnzFeg==" crossorigin="anonymous" referrerPolicy="no-referrer"/><script async="" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-XXXXXXXXXXXXXXXX" crossorigin="anonymous"></script><link rel="preload" href="/_next/static/media/e4af272ccee01ff0-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/css/735d4373f93910ca.css" as="style"/><link rel="stylesheet" href="/_next/static/css/735d4373f93910ca.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-11a4a2dad04962bb.js" defer=""></script><script src="/_next/static/chunks/framework-1ce91eb6f9ecda85.js" defer=""></script><script src="/_next/static/chunks/main-c7f4109f032d7b6e.js" defer=""></script><script src="/_next/static/chunks/pages/_app-1a852bd9e38c70ab.js" defer=""></script><script src="/_next/static/chunks/730-db7827467817f501.js" defer=""></script><script src="/_next/static/chunks/90-1cd4611704c3dbe0.js" defer=""></script><script src="/_next/static/chunks/440-29f4b99a44e744b5.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-0c1b14a33d5e05ee.js" defer=""></script><script src="/_next/static/rpFn_jslWZ9qPkJwor7RD/_buildManifest.js" defer=""></script><script src="/_next/static/rpFn_jslWZ9qPkJwor7RD/_ssgManifest.js" defer=""></script></head><body><div id="__next"><main class="__className_f367f3"><div class="min-h-screen bg-white"><nav class="fixed w-full z-50 transition-all duration-300 bg-white shadow-md" style="transform:translateY(-100px) translateZ(0)"><div class="container mx-auto px-4 sm:px-6 lg:px-8"><div class="flex items-center justify-between h-16"><a class="text-xl font-bold transition-colors text-blue-600" href="/">CodeSprintPro</a><div class="hidden md:flex items-center space-x-8"><a class="text-sm font-medium transition-colors text-blue-600" href="/blog/">Blog</a><a class="text-sm font-medium transition-colors text-gray-600 hover:text-blue-600" href="/#about">About</a><a class="text-sm font-medium transition-colors text-gray-600 hover:text-blue-600" href="/#portfolio">Portfolio</a><a class="text-sm font-medium transition-colors text-gray-600 hover:text-blue-600" href="/#contact">Contact</a></div><button class="md:hidden p-2 rounded-lg transition-colors hover:bg-gray-100 text-gray-600" aria-label="Toggle mobile menu"><svg class="w-6 h-6" fill="none" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" stroke="currentColor"><path d="M4 6h16M4 12h16M4 18h16"></path></svg></button></div></div></nav><div class="pt-20"><div class="bg-gradient-to-br from-gray-900 to-blue-950 py-16"><div class="container mx-auto px-4 sm:px-6 lg:px-8 max-w-5xl"><nav class="flex items-center gap-2 text-sm text-gray-400 mb-6"><a class="hover:text-white transition-colors" href="/">Home</a><span>/</span><a class="hover:text-white transition-colors" href="/blog/">Blog</a><span>/</span><span class="text-gray-300 truncate max-w-xs">Redis Beyond Cache: Sorted Sets, Streams, and Pub/Sub Patterns</span></nav><span class="inline-block text-xs font-semibold px-3 py-1 rounded-full bg-blue-100 text-blue-700 mb-4">Databases</span><h1 class="text-3xl md:text-5xl font-bold text-white mb-4 leading-tight">Redis Beyond Cache: Sorted Sets, Streams, and Pub/Sub Patterns</h1><p class="text-gray-300 text-lg mb-6 max-w-3xl">Redis is far more than a cache. Explore how sorted sets power leaderboards, streams enable event sourcing, and pub/sub enables real-time notifications ‚Äî with production Java examples.</p><div class="flex flex-wrap items-center gap-4 text-gray-400 text-sm"><span class="flex items-center gap-1.5"><svg class="w-4 h-4" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M16 7a4 4 0 11-8 0 4 4 0 018 0zM12 14a7 7 0 00-7 7h14a7 7 0 00-7-7z"></path></svg>Sachin Sarawgi</span><span>¬∑</span><span>January 22, 2025</span><span>¬∑</span><span class="flex items-center gap-1"><svg class="w-4 h-4" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>13 min read</span></div><div class="flex flex-wrap gap-2 mt-4"><span class="text-xs text-gray-400 bg-gray-800 px-2 py-1 rounded">#<!-- -->redis</span><span class="text-xs text-gray-400 bg-gray-800 px-2 py-1 rounded">#<!-- -->cache</span><span class="text-xs text-gray-400 bg-gray-800 px-2 py-1 rounded">#<!-- -->java</span><span class="text-xs text-gray-400 bg-gray-800 px-2 py-1 rounded">#<!-- -->distributed systems</span><span class="text-xs text-gray-400 bg-gray-800 px-2 py-1 rounded">#<!-- -->streams</span></div></div></div><div class="container mx-auto px-4 sm:px-6 lg:px-8 max-w-5xl py-12"><div class="flex gap-12"><div class="flex-1 min-w-0"><article class="prose prose-lg max-w-none prose-headings:text-gray-900 prose-headings:font-bold prose-h2:text-2xl prose-h2:mt-10 prose-h2:mb-4 prose-h3:text-xl prose-h3:mt-8 prose-h3:mb-3 prose-p:text-gray-700 prose-p:leading-relaxed prose-a:text-blue-600 prose-a:no-underline hover:prose-a:underline prose-strong:text-gray-900 prose-blockquote:border-blue-600 prose-blockquote:text-gray-600 prose-code:text-blue-700 prose-code:bg-blue-50 prose-code:px-1.5 prose-code:py-0.5 prose-code:rounded prose-code:text-sm prose-code:before:content-none prose-code:after:content-none prose-pre:rounded-xl prose-img:rounded-xl prose-img:shadow-md prose-table:text-sm prose-th:bg-gray-100 prose-th:text-gray-700"><p>Most teams use Redis for one thing: caching. They store objects with a TTL, check the cache before hitting the database, and call it a day. This barely scratches the surface.</p>
<p>Redis is a data structure server. Its real power lies in five data structures that solve distributed computing problems elegantly ‚Äî problems that would otherwise require separate specialized systems. This article covers each with production Java examples using Lettuce (the recommended Redis client for Spring Boot).</p>
<h2>Setup: Lettuce Configuration</h2>
<p>Before you can use any of these data structures, you need a properly configured Redis connection. The setup below uses Lettuce, which is the default client bundled with Spring Boot's <code>spring-boot-starter-data-redis</code>. Notice the 2-second command timeout ‚Äî in production, a Redis call that hangs indefinitely can cascade into a full service outage, so always set a timeout that matches your SLA.</p>
<pre><code class="language-java">@Configuration
public class RedisConfig {

    @Bean
    public RedisConnectionFactory redisConnectionFactory() {
        RedisStandaloneConfiguration config = new RedisStandaloneConfiguration("localhost", 6379);
        LettuceClientConfiguration clientConfig = LettuceClientConfiguration.builder()
            .commandTimeout(Duration.ofSeconds(2))
            .build();
        return new LettuceConnectionFactory(config, clientConfig);
    }

    @Bean
    public RedisTemplate&#x3C;String, Object> redisTemplate(RedisConnectionFactory factory) {
        RedisTemplate&#x3C;String, Object> template = new RedisTemplate&#x3C;>();
        template.setConnectionFactory(factory);
        template.setKeySerializer(new StringRedisSerializer());
        template.setValueSerializer(new GenericJackson2JsonRedisSerializer());
        return template;
    }
}
</code></pre>
<p>The <code>GenericJackson2JsonRedisSerializer</code> means your Java objects are stored as JSON in Redis, which keeps them human-readable and debuggable from the Redis CLI ‚Äî a small choice that saves a lot of pain during incidents.</p>
<h2>Sorted Sets: Leaderboards and Rate Limiting</h2>
<p>The sorted set (<code>ZSET</code>) stores members with a floating-point score, automatically maintaining order. Adding, removing, and querying by rank are all O(log N).</p>
<p>Think of a sorted set like a scoreboard at an arcade: every player has a name (member) and a score, and the board is always kept in order. Redis does all the sorting for you, and any operation ‚Äî add a score, find someone's rank, get the top 10 ‚Äî runs in logarithmic time regardless of how many players are on the board.</p>
<h3>Use Case 1: Real-Time Leaderboard</h3>
<p>A leaderboard sounds simple until you try to build one with a relational database. Updating a score, querying a rank, and fetching neighbors all require either expensive queries or complex caching logic. With a sorted set, these are single-command operations. The <code>incrementScore</code> call below is atomic ‚Äî no race conditions when two requests update the same player simultaneously.</p>
<pre><code class="language-java">@Service
public class LeaderboardService {

    private static final String LEADERBOARD_KEY = "leaderboard:weekly";

    @Autowired
    private StringRedisTemplate redis;

    // Add or update a player's score ‚Äî O(log N)
    public void recordScore(String playerId, double points) {
        redis.opsForZSet().incrementScore(LEADERBOARD_KEY, playerId, points);
    }

    // Get top N players with their scores ‚Äî O(log N + N)
    public List&#x3C;PlayerRank> getTopPlayers(int count) {
        Set&#x3C;ZSetOperations.TypedTuple&#x3C;String>> topPlayers =
            redis.opsForZSet().reverseRangeWithScores(LEADERBOARD_KEY, 0, count - 1);

        List&#x3C;PlayerRank> result = new ArrayList&#x3C;>();
        int rank = 1;
        for (ZSetOperations.TypedTuple&#x3C;String> tuple : topPlayers) {
            result.add(new PlayerRank(rank++, tuple.getValue(), tuple.getScore()));
        }
        return result;
    }

    // Get a specific player's rank ‚Äî O(log N)
    public Long getPlayerRank(String playerId) {
        Long rank = redis.opsForZSet().reverseRank(LEADERBOARD_KEY, playerId);
        return rank != null ? rank + 1 : null; // Convert 0-indexed to 1-indexed
    }

    // Get players around a specific player ‚Äî for "your neighbors" feature
    public List&#x3C;PlayerRank> getNeighbors(String playerId, int range) {
        Long rank = redis.opsForZSet().reverseRank(LEADERBOARD_KEY, playerId);
        if (rank == null) return Collections.emptyList();

        long start = Math.max(0, rank - range);
        long end = rank + range;
        return getTopPlayers((int)(end - start + 1));
    }
}
</code></pre>
<p>The <code>getNeighbors</code> method is the kind of feature that would require a complex window function in SQL. In Redis, it's just two commands: find the rank, then slice the sorted set around it.</p>
<h3>Use Case 2: Sliding Window Rate Limiter</h3>
<p>A naive rate limiter counts requests in a fixed bucket (e.g., "max 100 per minute"). The problem: a user can fire 100 requests at 00:59 and 100 more at 01:01, effectively making 200 requests in 2 seconds. A sliding window fixes this by always counting the last N seconds from the current moment. Sorted sets make this elegant ‚Äî each request is stored with its timestamp as the score, so pruning old requests is a single range-delete by score.</p>
<pre><code class="language-java">@Service
public class RateLimiter {

    @Autowired
    private StringRedisTemplate redis;

    /**
     * Sliding window rate limiter using sorted sets.
     * Each request is stored with its timestamp as the score.
     * Old entries outside the window are pruned on each check.
     */
    public boolean isAllowed(String userId, int maxRequests, Duration window) {
        String key = "rate_limit:" + userId;
        long now = System.currentTimeMillis();
        long windowStart = now - window.toMillis();

        return redis.execute((RedisCallback&#x3C;Boolean>) connection -> {
            connection.multi(); // BEGIN transaction

            // Remove entries outside the window
            connection.zRemRangeByScore(key.getBytes(), 0, windowStart);

            // Count remaining entries
            connection.zCard(key.getBytes());

            // Add current request
            connection.zAdd(key.getBytes(), now, String.valueOf(now).getBytes());

            // Set expiry on the key (auto-cleanup)
            connection.expire(key.getBytes(), window.getSeconds() + 1);

            List&#x3C;Object> results = connection.exec();

            Long currentCount = (Long) results.get(1);
            return currentCount != null &#x26;&#x26; currentCount &#x3C; maxRequests;
        });
    }
}
</code></pre>
<p>The entire check-and-add is wrapped in a Redis transaction (<code>MULTI</code>/<code>EXEC</code>), which guarantees that no other client can sneak a request in between the count and the add. This is the kind of correctness that is very hard to achieve with application-level locking.</p>
<h2>Streams: Persistent Event Log</h2>
<p>Redis Streams (added in 5.0) are a persistent, append-only log similar to Kafka partitions ‚Äî but inside Redis. They support consumer groups, acknowledgment, and pending message tracking.</p>
<p>If you've used Kafka, Streams will feel familiar: producers append events, consumer groups distribute work, and unacknowledged messages stay in a Pending Entries List (PEL) so they can be retried. The key difference is scale ‚Äî Redis Streams are the right tool when your event volume fits in memory and you don't want the operational overhead of a separate Kafka cluster.</p>
<pre><code class="language-java">@Service
public class OrderEventStream {

    private static final String STREAM_KEY = "order-stream";
    private static final String CONSUMER_GROUP = "order-processors";

    @Autowired
    private StreamOperations&#x3C;String, Object, Object> streamOps;

    // Producer: publish an event
    public String publishOrderEvent(OrderEvent event) {
        Map&#x3C;String, Object> fields = Map.of(
            "orderId", event.getOrderId(),
            "status", event.getStatus(),
            "userId", event.getUserId(),
            "amount", event.getAmount(),
            "timestamp", Instant.now().toString()
        );

        // XADD order-stream * orderId 123 status PLACED ...
        // Returns auto-generated message ID: "1704067200000-0"
        RecordId messageId = streamOps.add(STREAM_KEY, fields);
        log.info("Published order event, messageId={}", messageId);
        return messageId.toString();
    }

    // Consumer: read and acknowledge messages
    public void consumeEvents() {
        // Create consumer group if not exists
        try {
            streamOps.createGroup(STREAM_KEY, ReadOffset.from("0"), CONSUMER_GROUP);
        } catch (Exception e) {
            // Group already exists ‚Äî ignore
        }

        while (true) {
            // XREADGROUP GROUP order-processors consumer-1 COUNT 10 BLOCK 2000 STREAMS order-stream >
            List&#x3C;MapRecord&#x3C;String, Object, Object>> messages = streamOps.read(
                Consumer.from(CONSUMER_GROUP, "consumer-1"),
                StreamReadOptions.empty().count(10).block(Duration.ofSeconds(2)),
                StreamOffset.create(STREAM_KEY, ReadOffset.lastConsumed())
            );

            for (MapRecord&#x3C;String, Object, Object> message : messages) {
                try {
                    processOrderEvent(message.getValue());
                    // Acknowledge successful processing
                    streamOps.acknowledge(STREAM_KEY, CONSUMER_GROUP, message.getId());
                } catch (Exception e) {
                    log.error("Failed to process message {}", message.getId(), e);
                    // Message stays in PEL (Pending Entries List) ‚Äî can be reclaimed
                }
            }
        }
    }

    // Reclaim messages that have been pending too long (crashed consumers)
    public void reclaimStalledMessages() {
        // XAUTOCLAIM: claim messages idle > 5 minutes
        PendingMessages pending = streamOps.pending(
            STREAM_KEY,
            Consumer.from(CONSUMER_GROUP, "consumer-1"),
            Range.unbounded(), 100
        );
        // Process pending messages with a different consumer
    }
}
</code></pre>
<p>Notice that <code>acknowledge</code> is only called after successful processing. If a consumer crashes mid-process, the message stays in the PEL and <code>reclaimStalledMessages</code> can hand it to another consumer ‚Äî this is how you get at-least-once delivery guarantees without a dedicated message broker.</p>
<h2>Pub/Sub: Real-Time Notifications</h2>
<p>Redis Pub/Sub is a fire-and-forget messaging system. Publishers send messages to channels; all current subscribers receive them. Messages are <strong>not persisted</strong> ‚Äî if a subscriber is down, it misses messages.</p>
<p>Think of Pub/Sub like a radio broadcast: the station transmits at all times, and you only hear it while your radio is on. This is perfect for live notifications where freshness matters more than completeness ‚Äî telling a user they have a new chat message is only useful while they're online anyway.</p>
<pre><code class="language-java">// Publisher
@Service
public class NotificationPublisher {

    @Autowired
    private RedisTemplate&#x3C;String, Object> redisTemplate;

    public void notifyUser(String userId, NotificationEvent event) {
        String channel = "notifications:" + userId;
        redisTemplate.convertAndSend(channel, event);
    }

    public void broadcastSystemAlert(AlertEvent alert) {
        redisTemplate.convertAndSend("system-alerts", alert);
    }
}

// Subscriber configuration
@Configuration
public class RedisPubSubConfig {

    @Bean
    public RedisMessageListenerContainer redisMessageListenerContainer(
            RedisConnectionFactory factory,
            NotificationMessageListener listener) {
        RedisMessageListenerContainer container = new RedisMessageListenerContainer();
        container.setConnectionFactory(factory);

        // Subscribe to user-specific notifications
        container.addMessageListener(listener,
            new PatternTopic("notifications:*")); // Wildcard subscription

        // Subscribe to system alerts
        container.addMessageListener(listener,
            new ChannelTopic("system-alerts"));

        return container;
    }
}

@Component
public class NotificationMessageListener implements MessageListener {

    @Autowired
    private WebSocketService webSocketService;

    @Override
    public void onMessage(Message message, byte[] pattern) {
        String channel = new String(message.getChannel());
        String body = new String(message.getBody());

        if (channel.startsWith("notifications:")) {
            String userId = channel.replace("notifications:", "");
            webSocketService.sendToUser(userId, body);
        } else if (channel.equals("system-alerts")) {
            webSocketService.broadcast(body);
        }
    }
}
</code></pre>
<p><strong>When to use Pub/Sub vs Streams:</strong></p>
<ul>
<li><strong>Pub/Sub</strong>: Real-time notifications where it's acceptable to miss messages (user online alerts, live dashboards)</li>
<li><strong>Streams</strong>: Event sourcing, order processing, any case where you need persistence and guaranteed delivery</li>
</ul>
<h2>Distributed Locking with SETNX</h2>
<p>Distributed locks solve a problem that seems simple but isn't: ensuring only one instance of your application performs a critical operation at a time. Imagine two payment service instances both receiving a retry for the same order ‚Äî without a lock, you could charge the user twice. Redis's <code>SETNX</code> (Set if Not eXists) combined with a TTL gives you a lock that is both exclusive and self-expiring.</p>
<pre><code class="language-java">@Service
public class DistributedLockService {

    @Autowired
    private StringRedisTemplate redis;

    private static final long LOCK_TTL_SECONDS = 30;

    /**
     * Acquire a distributed lock. Returns lock token if acquired, null if not.
     * The token is needed to safely release the lock.
     */
    public String acquireLock(String resourceId) {
        String lockKey = "lock:" + resourceId;
        String lockToken = UUID.randomUUID().toString(); // Unique per lock acquisition

        Boolean acquired = redis.opsForValue().setIfAbsent(
            lockKey,
            lockToken,
            Duration.ofSeconds(LOCK_TTL_SECONDS)
        );

        return Boolean.TRUE.equals(acquired) ? lockToken : null;
    }

    /**
     * Release only if we still own the lock. Uses Lua script for atomicity.
     * Without Lua: check-then-delete is a TOCTOU race condition.
     */
    public boolean releaseLock(String resourceId, String lockToken) {
        String lockKey = "lock:" + resourceId;

        String luaScript = """
            if redis.call('get', KEYS[1]) == ARGV[1] then
                return redis.call('del', KEYS[1])
            else
                return 0
            end
            """;

        Long result = redis.execute(
            new DefaultRedisScript&#x3C;>(luaScript, Long.class),
            List.of(lockKey),
            lockToken
        );

        return Long.valueOf(1).equals(result);
    }

    // Usage pattern
    public void processPayment(String orderId) {
        String lockToken = acquireLock("payment:" + orderId);
        if (lockToken == null) {
            throw new ResourceBusyException("Payment already being processed for order " + orderId);
        }

        try {
            paymentService.charge(orderId);
        } finally {
            releaseLock("payment:" + orderId, lockToken);
        }
    }
}
</code></pre>
<p>The Lua script for releasing the lock is the critical piece here: it checks and deletes the key atomically. Without it, there's a window where your lock could expire between the <code>GET</code> check and the <code>DEL</code> ‚Äî and you'd end up deleting another process's lock. The unique <code>lockToken</code> per acquisition is what prevents this: even if the TTL fires, you can't accidentally release a lock you don't own.</p>
<h2>HyperLogLog: Counting Unique Visitors at Scale</h2>
<p>Counting exact unique visitors requires storing every visitor ID ‚Äî expensive at scale. HyperLogLog estimates cardinality with ~0.81% error using only 12KB regardless of input size.</p>
<p>Imagine trying to count how many unique people walked through a mall's entrance over a year. You could keep a list of every face, but storing millions of names is expensive. HyperLogLog is like a probabilistic tally counter ‚Äî it can't tell you exactly who visited, but it can tell you "roughly 2.3 million unique visitors" while using the same amount of memory whether you have 100 or 100 million visitors.</p>
<pre><code class="language-java">@Service
public class UniqueVisitorCounter {

    @Autowired
    private StringRedisTemplate redis;

    public void trackVisit(String pageId, String visitorId) {
        String key = "page_visitors:" + pageId + ":" + LocalDate.now();
        // PFADD: O(1), uses ~12KB regardless of cardinality
        redis.opsForHyperLogLog().add(key, visitorId);
        redis.expire(key, Duration.ofDays(30));
    }

    public long getUniqueVisitors(String pageId) {
        String key = "page_visitors:" + pageId + ":" + LocalDate.now();
        // PFCOUNT: returns estimated cardinality with 0.81% error
        return redis.opsForHyperLogLog().size(key);
    }

    public long getUniqueVisitorsAcrossPages(List&#x3C;String> pageIds) {
        String[] keys = pageIds.stream()
            .map(id -> "page_visitors:" + id + ":" + LocalDate.now())
            .toArray(String[]::new);
        // PFCOUNT on multiple keys: union estimate
        return redis.opsForHyperLogLog().size(keys);
    }
}
</code></pre>
<p>The 0.81% error rate is the trade-off you're accepting: for a page with 1 million visitors, your count will be off by at most ~8,100. For analytics dashboards where "approximately 1 million" is meaningful, this is a worthwhile trade for a 99.9% reduction in memory usage compared to storing exact visitor IDs.</p>
<h2>Production Configuration</h2>
<p>Getting Redis working in development is easy; getting it right in production requires deliberate configuration. The settings below cover connection pooling (to avoid connection storms during traffic spikes), cluster topology awareness (so your client can find the right shard after a failover), and eviction policy (which determines what Redis does when memory fills up).</p>
<pre><code class="language-yaml"># Redis configuration for production
spring:
  redis:
    host: redis-cluster.internal
    port: 6379
    timeout: 2000ms
    lettuce:
      pool:
        max-active: 50
        max-idle: 10
        min-idle: 5
        max-wait: 1000ms
      cluster:
        refresh:
          adaptive: true           # Detect cluster topology changes
          period: 30s

# Key eviction policy ‚Äî critical for cache usage
# volatile-lru: evict keys with TTL, LRU order (recommended for mixed cache/persistent)
# allkeys-lru: evict any key, LRU order (for pure cache)
# noeviction: reject writes when full (use for persistent data)
</code></pre>
<pre><code class="language-bash"># maxmemory and eviction policy (redis.conf or CONFIG SET)
CONFIG SET maxmemory 8gb
CONFIG SET maxmemory-policy allkeys-lfu  # LFU: better than LRU for Zipf distributions

# Monitor evicted keys ‚Äî should be near 0 for persistent data
INFO stats | grep evicted_keys
</code></pre>
<p>If you are using Redis for both caching and persistent data structures (like Streams or sorted sets with leaderboard data), use <code>volatile-lru</code> so only keys with a TTL are evicted ‚Äî your persistent data stays safe. If Redis is purely a cache, <code>allkeys-lfu</code> is the best modern choice because it evicts the least-frequently-used keys, which handles the real-world "long tail" of cached objects better than a strict LRU.</p>
<h2>When to Use Redis vs What</h2>
<table>
<thead>
<tr>
<th>Use Case</th>
<th>Redis Data Structure</th>
<th>Alternative</th>
</tr>
</thead>
<tbody>
<tr>
<td>Simple cache</td>
<td>String</td>
<td>Memcached</td>
</tr>
<tr>
<td>Session storage</td>
<td>Hash</td>
<td>Database</td>
</tr>
<tr>
<td>Leaderboard</td>
<td>Sorted Set</td>
<td>PostgreSQL (complex query)</td>
</tr>
<tr>
<td>Rate limiting</td>
<td>Sorted Set / String</td>
<td>API Gateway</td>
</tr>
<tr>
<td>Pub/Sub</td>
<td>Pub/Sub</td>
<td>WebSockets (no persistence)</td>
</tr>
<tr>
<td>Event log</td>
<td>Stream</td>
<td>Kafka (for high volume)</td>
</tr>
<tr>
<td>Unique count</td>
<td>HyperLogLog</td>
<td>Exact count in DB</td>
</tr>
<tr>
<td>Distributed lock</td>
<td>String (SETNX)</td>
<td>ZooKeeper</td>
</tr>
<tr>
<td>Queue</td>
<td>List</td>
<td>RabbitMQ</td>
</tr>
<tr>
<td>Membership test</td>
<td>Bloom Filter (RedisBloom)</td>
<td>Exact set</td>
</tr>
</tbody>
</table>
<p>Redis's sweet spot is low-latency, high-throughput operations on data structures where the dataset fits in memory. The moment your dataset exceeds available RAM or you need complex query patterns, reach for PostgreSQL or a specialized system.</p>
<p>The key insight is to <strong>match the data structure to the access pattern</strong> ‚Äî not to treat Redis as a generic key-value store where everything is a serialized JSON blob.</p>
</article><div class="my-10 rounded-xl border border-yellow-200 bg-yellow-50 p-6"><div class="flex items-center gap-2 mb-1"><span class="text-lg">üìö</span><h3 class="text-base font-bold text-gray-900">Recommended Resources</h3></div><div class="space-y-4"><div class="flex items-start gap-3 bg-white rounded-lg p-4 border border-yellow-100"><div class="flex-1 min-w-0"><div class="flex items-center gap-2 flex-wrap mb-1"><span class="font-semibold text-gray-900 text-sm">Designing Data-Intensive Applications</span><span class="text-xs bg-blue-100 text-blue-700 px-2 py-0.5 rounded-full font-medium">Best Seller</span></div><p class="text-xs text-gray-600">The definitive guide to building scalable, reliable distributed systems by Martin Kleppmann.</p></div><a href="https://amzn.to/3RyKzOA" target="_blank" rel="noopener noreferrer" class="flex-shrink-0 text-xs bg-blue-600 text-white px-3 py-2 rounded-lg hover:bg-blue-700 transition-colors font-medium whitespace-nowrap">View on Amazon<!-- --> ‚Üí</a></div><div class="flex items-start gap-3 bg-white rounded-lg p-4 border border-yellow-100"><div class="flex-1 min-w-0"><div class="flex items-center gap-2 flex-wrap mb-1"><span class="font-semibold text-gray-900 text-sm">Kafka: The Definitive Guide</span><span class="text-xs bg-blue-100 text-blue-700 px-2 py-0.5 rounded-full font-medium">Editor&#x27;s Pick</span></div><p class="text-xs text-gray-600">Real-time data and stream processing by Confluent engineers.</p></div><a href="https://amzn.to/3TpGKsI" target="_blank" rel="noopener noreferrer" class="flex-shrink-0 text-xs bg-blue-600 text-white px-3 py-2 rounded-lg hover:bg-blue-700 transition-colors font-medium whitespace-nowrap">View on Amazon<!-- --> ‚Üí</a></div><div class="flex items-start gap-3 bg-white rounded-lg p-4 border border-yellow-100"><div class="flex-1 min-w-0"><div class="flex items-center gap-2 flex-wrap mb-1"><span class="font-semibold text-gray-900 text-sm">Apache Kafka Series on Udemy</span></div><p class="text-xs text-gray-600">Hands-on Kafka course covering producers, consumers, Kafka Streams, and Connect.</p></div><a href="https://www.udemy.com/course/apache-kafka/" target="_blank" rel="noopener noreferrer" class="flex-shrink-0 text-xs bg-blue-600 text-white px-3 py-2 rounded-lg hover:bg-blue-700 transition-colors font-medium whitespace-nowrap">View Course<!-- --> ‚Üí</a></div></div></div><div class="mt-10 pt-8 border-t border-gray-100"><p class="text-sm text-gray-500 mb-3">Found this useful? Share it:</p><div class="flex gap-3"><a href="https://twitter.com/intent/tweet?text=Redis%20Beyond%20Cache%3A%20Sorted%20Sets%2C%20Streams%2C%20and%20Pub%2FSub%20Patterns&amp;url=https%3A%2F%2Fcodesprintpro.com%2Fblog%2Fredis-beyond-cache%2F" target="_blank" rel="noopener noreferrer" class="text-xs bg-gray-900 text-white px-4 py-2 rounded-lg hover:bg-gray-700 transition-colors">Share on X/Twitter</a><a href="https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fcodesprintpro.com%2Fblog%2Fredis-beyond-cache%2F" target="_blank" rel="noopener noreferrer" class="text-xs bg-blue-600 text-white px-4 py-2 rounded-lg hover:bg-blue-700 transition-colors">Share on LinkedIn</a></div></div></div><aside class="hidden lg:block w-64 flex-shrink-0"><nav class="hidden lg:block sticky top-24"><h4 class="text-xs font-semibold uppercase tracking-widest text-gray-400 mb-3">On This Page</h4><ul class="space-y-1"><li class=""><a href="#setup-lettuce-configuration" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Setup: Lettuce Configuration</a></li><li class=""><a href="#sorted-sets-leaderboards-and-rate-limiting" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Sorted Sets: Leaderboards and Rate Limiting</a></li><li class="ml-4"><a href="#use-case-1-real-time-leaderboard" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 text-xs">Use Case 1: Real-Time Leaderboard</a></li><li class="ml-4"><a href="#use-case-2-sliding-window-rate-limiter" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 text-xs">Use Case 2: Sliding Window Rate Limiter</a></li><li class=""><a href="#streams-persistent-event-log" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Streams: Persistent Event Log</a></li><li class=""><a href="#pubsub-real-time-notifications" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Pub/Sub: Real-Time Notifications</a></li><li class=""><a href="#distributed-locking-with-setnx" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Distributed Locking with SETNX</a></li><li class=""><a href="#hyperloglog-counting-unique-visitors-at-scale" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">HyperLogLog: Counting Unique Visitors at Scale</a></li><li class=""><a href="#production-configuration" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Production Configuration</a></li><li class=""><a href="#when-to-use-redis-vs-what" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">When to Use Redis vs What</a></li></ul></nav></aside></div><div class="mt-16 pt-10 border-t border-gray-100"><h2 class="text-2xl font-bold text-gray-900 mb-6">Related Articles</h2><div class="grid grid-cols-1 md:grid-cols-3 gap-6"><a href="/blog/cassandra-data-modeling/"><article class="group bg-white rounded-xl border border-gray-200 p-6 h-full cursor-pointer hover:border-blue-300 hover:shadow-lg transition-all"><span class="inline-block text-xs font-semibold px-3 py-1 rounded-full mb-3 bg-green-100 text-green-700">Databases</span><h3 class="text-lg font-bold text-gray-900 mb-2 group-hover:text-blue-600 transition-colors leading-snug">Cassandra Data Modeling: Design for Queries, Not Entities</h3><p class="text-gray-600 text-sm mb-4 line-clamp-3">Cassandra is a write-optimized distributed database built for linear horizontal scalability. It stores data in a distributed hash ring ‚Äî every node is equal, there&#x27;s no primary, and data placement is determined by partit‚Ä¶</p><div class="flex items-center justify-between text-xs text-gray-400"><span>Jun 18, 2025</span><span class="flex items-center gap-1"><svg class="w-3 h-3" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>9 min read</span></div><div class="mt-3 flex flex-wrap gap-1"><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->cassandra</span><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->nosql</span><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->data modeling</span></div></article></a><a href="/blog/dynamodb-advanced-patterns/"><article class="group bg-white rounded-xl border border-gray-200 p-6 h-full cursor-pointer hover:border-blue-300 hover:shadow-lg transition-all"><span class="inline-block text-xs font-semibold px-3 py-1 rounded-full mb-3 bg-green-100 text-green-700">Databases</span><h3 class="text-lg font-bold text-gray-900 mb-2 group-hover:text-blue-600 transition-colors leading-snug">DynamoDB Advanced Patterns: Single-Table Design and Beyond</h3><p class="text-gray-600 text-sm mb-4 line-clamp-3">DynamoDB is a fully managed key-value and document database that delivers single-digit millisecond performance at any scale. It achieves this with a fundamental constraint: you must define your access patterns before you‚Ä¶</p><div class="flex items-center justify-between text-xs text-gray-400"><span>Jun 13, 2025</span><span class="flex items-center gap-1"><svg class="w-3 h-3" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>9 min read</span></div><div class="mt-3 flex flex-wrap gap-1"><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->dynamodb</span><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->aws</span><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->nosql</span></div></article></a><a href="/blog/zero-downtime-database-migrations/"><article class="group bg-white rounded-xl border border-gray-200 p-6 h-full cursor-pointer hover:border-blue-300 hover:shadow-lg transition-all"><span class="inline-block text-xs font-semibold px-3 py-1 rounded-full mb-3 bg-green-100 text-green-700">Databases</span><h3 class="text-lg font-bold text-gray-900 mb-2 group-hover:text-blue-600 transition-colors leading-snug">Zero-Downtime Database Migrations: Patterns for Production</h3><p class="text-gray-600 text-sm mb-4 line-clamp-3">Database migrations are the most dangerous part of a deployment. Application code changes are stateless and reversible ‚Äî rollback a bad deploy and your code is back to the previous version. Database schema changes are st‚Ä¶</p><div class="flex items-center justify-between text-xs text-gray-400"><span>Jun 8, 2025</span><span class="flex items-center gap-1"><svg class="w-3 h-3" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>8 min read</span></div><div class="mt-3 flex flex-wrap gap-1"><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->database</span><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->migrations</span><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->postgresql</span></div></article></a></div></div><div class="mt-12 text-center"><a class="inline-flex items-center gap-2 text-blue-600 hover:text-blue-700 font-medium transition-colors" href="/blog/">‚Üê Back to all articles</a></div></div></div><footer class="bg-gray-900 text-white py-12"><div class="container mx-auto px-4 sm:px-6 lg:px-8"><div class="grid grid-cols-1 md:grid-cols-4 gap-8 mb-8"><div class="col-span-1 md:col-span-1"><div><a class="text-xl font-bold block mb-3 text-white hover:text-blue-400 transition-colors" href="/">CodeSprintPro</a></div><p class="text-gray-400 text-sm mb-4 leading-relaxed">Deep-dive technical content on System Design, Java, Databases, AI/ML, and AWS ‚Äî by Sachin Sarawgi.</p><div class="flex space-x-4"><a href="https://github.com/codesprintpro" target="_blank" rel="noopener noreferrer" class="text-gray-400 hover:text-white transition-colors" aria-label="Visit GitHub profile"><i class="fab fa-github text-xl"></i></a><a href="https://www.linkedin.com/in/sachin-sarawgi/" target="_blank" rel="noopener noreferrer" class="text-gray-400 hover:text-white transition-colors" aria-label="Visit LinkedIn profile"><i class="fab fa-linkedin text-xl"></i></a><a href="https://medium.com/@codesprintpro" target="_blank" rel="noopener noreferrer" class="text-gray-400 hover:text-white transition-colors" aria-label="Visit Medium profile"><i class="fab fa-medium text-xl"></i></a></div></div><div><h3 class="text-sm font-semibold uppercase tracking-widest text-gray-400 mb-4">Quick Links</h3><ul class="space-y-2"><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">Blog</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/#about">About</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/#portfolio">Portfolio</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/#contact">Contact</a></div></li></ul></div><div><h3 class="text-sm font-semibold uppercase tracking-widest text-gray-400 mb-4">Categories</h3><ul class="space-y-2"><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">System Design</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">Java</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">Databases</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">AI/ML</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">AWS</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">Messaging</a></div></li></ul></div><div><h3 class="text-sm font-semibold uppercase tracking-widest text-gray-400 mb-4">Contact</h3><ul class="space-y-2 text-gray-400 text-sm"><li><a href="mailto:sachinsarawgi201143@gmail.com" class="hover:text-white transition-colors flex items-center gap-2"><i class="fas fa-envelope"></i> Email</a></li><li><a href="https://www.linkedin.com/in/sachin-sarawgi/" target="_blank" rel="noopener noreferrer" class="hover:text-white transition-colors flex items-center gap-2"><i class="fab fa-linkedin"></i> LinkedIn</a></li><li><a href="https://github.com/codesprintpro" target="_blank" rel="noopener noreferrer" class="hover:text-white transition-colors flex items-center gap-2"><i class="fab fa-github"></i> GitHub</a></li></ul></div></div><div class="border-t border-gray-800 pt-6 flex flex-col md:flex-row justify-between items-center gap-2"><p class="text-gray-500 text-sm">¬© <!-- -->2026<!-- --> CodeSprintPro ¬∑ Sachin Sarawgi. All rights reserved.</p><p class="text-gray-600 text-xs">Built with Next.js ¬∑ TailwindCSS ¬∑ Deployed on GitHub Pages</p></div></div></footer></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"Redis Beyond Cache: Sorted Sets, Streams, and Pub/Sub Patterns","description":"Redis is far more than a cache. Explore how sorted sets power leaderboards, streams enable event sourcing, and pub/sub enables real-time notifications ‚Äî with production Java examples.","date":"2025-01-22","category":"Databases","tags":["redis","cache","java","distributed systems","streams"],"featured":true,"affiliateSection":"distributed-systems-books","slug":"redis-beyond-cache","readingTime":"13 min read","excerpt":"Most teams use Redis for one thing: caching. They store objects with a TTL, check the cache before hitting the database, and call it a day. This barely scratches the surface. Redis is a data structure server. Its real po‚Ä¶","contentHtml":"\u003cp\u003eMost teams use Redis for one thing: caching. They store objects with a TTL, check the cache before hitting the database, and call it a day. This barely scratches the surface.\u003c/p\u003e\n\u003cp\u003eRedis is a data structure server. Its real power lies in five data structures that solve distributed computing problems elegantly ‚Äî problems that would otherwise require separate specialized systems. This article covers each with production Java examples using Lettuce (the recommended Redis client for Spring Boot).\u003c/p\u003e\n\u003ch2\u003eSetup: Lettuce Configuration\u003c/h2\u003e\n\u003cp\u003eBefore you can use any of these data structures, you need a properly configured Redis connection. The setup below uses Lettuce, which is the default client bundled with Spring Boot's \u003ccode\u003espring-boot-starter-data-redis\u003c/code\u003e. Notice the 2-second command timeout ‚Äî in production, a Redis call that hangs indefinitely can cascade into a full service outage, so always set a timeout that matches your SLA.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003e@Configuration\npublic class RedisConfig {\n\n    @Bean\n    public RedisConnectionFactory redisConnectionFactory() {\n        RedisStandaloneConfiguration config = new RedisStandaloneConfiguration(\"localhost\", 6379);\n        LettuceClientConfiguration clientConfig = LettuceClientConfiguration.builder()\n            .commandTimeout(Duration.ofSeconds(2))\n            .build();\n        return new LettuceConnectionFactory(config, clientConfig);\n    }\n\n    @Bean\n    public RedisTemplate\u0026#x3C;String, Object\u003e redisTemplate(RedisConnectionFactory factory) {\n        RedisTemplate\u0026#x3C;String, Object\u003e template = new RedisTemplate\u0026#x3C;\u003e();\n        template.setConnectionFactory(factory);\n        template.setKeySerializer(new StringRedisSerializer());\n        template.setValueSerializer(new GenericJackson2JsonRedisSerializer());\n        return template;\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe \u003ccode\u003eGenericJackson2JsonRedisSerializer\u003c/code\u003e means your Java objects are stored as JSON in Redis, which keeps them human-readable and debuggable from the Redis CLI ‚Äî a small choice that saves a lot of pain during incidents.\u003c/p\u003e\n\u003ch2\u003eSorted Sets: Leaderboards and Rate Limiting\u003c/h2\u003e\n\u003cp\u003eThe sorted set (\u003ccode\u003eZSET\u003c/code\u003e) stores members with a floating-point score, automatically maintaining order. Adding, removing, and querying by rank are all O(log N).\u003c/p\u003e\n\u003cp\u003eThink of a sorted set like a scoreboard at an arcade: every player has a name (member) and a score, and the board is always kept in order. Redis does all the sorting for you, and any operation ‚Äî add a score, find someone's rank, get the top 10 ‚Äî runs in logarithmic time regardless of how many players are on the board.\u003c/p\u003e\n\u003ch3\u003eUse Case 1: Real-Time Leaderboard\u003c/h3\u003e\n\u003cp\u003eA leaderboard sounds simple until you try to build one with a relational database. Updating a score, querying a rank, and fetching neighbors all require either expensive queries or complex caching logic. With a sorted set, these are single-command operations. The \u003ccode\u003eincrementScore\u003c/code\u003e call below is atomic ‚Äî no race conditions when two requests update the same player simultaneously.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003e@Service\npublic class LeaderboardService {\n\n    private static final String LEADERBOARD_KEY = \"leaderboard:weekly\";\n\n    @Autowired\n    private StringRedisTemplate redis;\n\n    // Add or update a player's score ‚Äî O(log N)\n    public void recordScore(String playerId, double points) {\n        redis.opsForZSet().incrementScore(LEADERBOARD_KEY, playerId, points);\n    }\n\n    // Get top N players with their scores ‚Äî O(log N + N)\n    public List\u0026#x3C;PlayerRank\u003e getTopPlayers(int count) {\n        Set\u0026#x3C;ZSetOperations.TypedTuple\u0026#x3C;String\u003e\u003e topPlayers =\n            redis.opsForZSet().reverseRangeWithScores(LEADERBOARD_KEY, 0, count - 1);\n\n        List\u0026#x3C;PlayerRank\u003e result = new ArrayList\u0026#x3C;\u003e();\n        int rank = 1;\n        for (ZSetOperations.TypedTuple\u0026#x3C;String\u003e tuple : topPlayers) {\n            result.add(new PlayerRank(rank++, tuple.getValue(), tuple.getScore()));\n        }\n        return result;\n    }\n\n    // Get a specific player's rank ‚Äî O(log N)\n    public Long getPlayerRank(String playerId) {\n        Long rank = redis.opsForZSet().reverseRank(LEADERBOARD_KEY, playerId);\n        return rank != null ? rank + 1 : null; // Convert 0-indexed to 1-indexed\n    }\n\n    // Get players around a specific player ‚Äî for \"your neighbors\" feature\n    public List\u0026#x3C;PlayerRank\u003e getNeighbors(String playerId, int range) {\n        Long rank = redis.opsForZSet().reverseRank(LEADERBOARD_KEY, playerId);\n        if (rank == null) return Collections.emptyList();\n\n        long start = Math.max(0, rank - range);\n        long end = rank + range;\n        return getTopPlayers((int)(end - start + 1));\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe \u003ccode\u003egetNeighbors\u003c/code\u003e method is the kind of feature that would require a complex window function in SQL. In Redis, it's just two commands: find the rank, then slice the sorted set around it.\u003c/p\u003e\n\u003ch3\u003eUse Case 2: Sliding Window Rate Limiter\u003c/h3\u003e\n\u003cp\u003eA naive rate limiter counts requests in a fixed bucket (e.g., \"max 100 per minute\"). The problem: a user can fire 100 requests at 00:59 and 100 more at 01:01, effectively making 200 requests in 2 seconds. A sliding window fixes this by always counting the last N seconds from the current moment. Sorted sets make this elegant ‚Äî each request is stored with its timestamp as the score, so pruning old requests is a single range-delete by score.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003e@Service\npublic class RateLimiter {\n\n    @Autowired\n    private StringRedisTemplate redis;\n\n    /**\n     * Sliding window rate limiter using sorted sets.\n     * Each request is stored with its timestamp as the score.\n     * Old entries outside the window are pruned on each check.\n     */\n    public boolean isAllowed(String userId, int maxRequests, Duration window) {\n        String key = \"rate_limit:\" + userId;\n        long now = System.currentTimeMillis();\n        long windowStart = now - window.toMillis();\n\n        return redis.execute((RedisCallback\u0026#x3C;Boolean\u003e) connection -\u003e {\n            connection.multi(); // BEGIN transaction\n\n            // Remove entries outside the window\n            connection.zRemRangeByScore(key.getBytes(), 0, windowStart);\n\n            // Count remaining entries\n            connection.zCard(key.getBytes());\n\n            // Add current request\n            connection.zAdd(key.getBytes(), now, String.valueOf(now).getBytes());\n\n            // Set expiry on the key (auto-cleanup)\n            connection.expire(key.getBytes(), window.getSeconds() + 1);\n\n            List\u0026#x3C;Object\u003e results = connection.exec();\n\n            Long currentCount = (Long) results.get(1);\n            return currentCount != null \u0026#x26;\u0026#x26; currentCount \u0026#x3C; maxRequests;\n        });\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe entire check-and-add is wrapped in a Redis transaction (\u003ccode\u003eMULTI\u003c/code\u003e/\u003ccode\u003eEXEC\u003c/code\u003e), which guarantees that no other client can sneak a request in between the count and the add. This is the kind of correctness that is very hard to achieve with application-level locking.\u003c/p\u003e\n\u003ch2\u003eStreams: Persistent Event Log\u003c/h2\u003e\n\u003cp\u003eRedis Streams (added in 5.0) are a persistent, append-only log similar to Kafka partitions ‚Äî but inside Redis. They support consumer groups, acknowledgment, and pending message tracking.\u003c/p\u003e\n\u003cp\u003eIf you've used Kafka, Streams will feel familiar: producers append events, consumer groups distribute work, and unacknowledged messages stay in a Pending Entries List (PEL) so they can be retried. The key difference is scale ‚Äî Redis Streams are the right tool when your event volume fits in memory and you don't want the operational overhead of a separate Kafka cluster.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003e@Service\npublic class OrderEventStream {\n\n    private static final String STREAM_KEY = \"order-stream\";\n    private static final String CONSUMER_GROUP = \"order-processors\";\n\n    @Autowired\n    private StreamOperations\u0026#x3C;String, Object, Object\u003e streamOps;\n\n    // Producer: publish an event\n    public String publishOrderEvent(OrderEvent event) {\n        Map\u0026#x3C;String, Object\u003e fields = Map.of(\n            \"orderId\", event.getOrderId(),\n            \"status\", event.getStatus(),\n            \"userId\", event.getUserId(),\n            \"amount\", event.getAmount(),\n            \"timestamp\", Instant.now().toString()\n        );\n\n        // XADD order-stream * orderId 123 status PLACED ...\n        // Returns auto-generated message ID: \"1704067200000-0\"\n        RecordId messageId = streamOps.add(STREAM_KEY, fields);\n        log.info(\"Published order event, messageId={}\", messageId);\n        return messageId.toString();\n    }\n\n    // Consumer: read and acknowledge messages\n    public void consumeEvents() {\n        // Create consumer group if not exists\n        try {\n            streamOps.createGroup(STREAM_KEY, ReadOffset.from(\"0\"), CONSUMER_GROUP);\n        } catch (Exception e) {\n            // Group already exists ‚Äî ignore\n        }\n\n        while (true) {\n            // XREADGROUP GROUP order-processors consumer-1 COUNT 10 BLOCK 2000 STREAMS order-stream \u003e\n            List\u0026#x3C;MapRecord\u0026#x3C;String, Object, Object\u003e\u003e messages = streamOps.read(\n                Consumer.from(CONSUMER_GROUP, \"consumer-1\"),\n                StreamReadOptions.empty().count(10).block(Duration.ofSeconds(2)),\n                StreamOffset.create(STREAM_KEY, ReadOffset.lastConsumed())\n            );\n\n            for (MapRecord\u0026#x3C;String, Object, Object\u003e message : messages) {\n                try {\n                    processOrderEvent(message.getValue());\n                    // Acknowledge successful processing\n                    streamOps.acknowledge(STREAM_KEY, CONSUMER_GROUP, message.getId());\n                } catch (Exception e) {\n                    log.error(\"Failed to process message {}\", message.getId(), e);\n                    // Message stays in PEL (Pending Entries List) ‚Äî can be reclaimed\n                }\n            }\n        }\n    }\n\n    // Reclaim messages that have been pending too long (crashed consumers)\n    public void reclaimStalledMessages() {\n        // XAUTOCLAIM: claim messages idle \u003e 5 minutes\n        PendingMessages pending = streamOps.pending(\n            STREAM_KEY,\n            Consumer.from(CONSUMER_GROUP, \"consumer-1\"),\n            Range.unbounded(), 100\n        );\n        // Process pending messages with a different consumer\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNotice that \u003ccode\u003eacknowledge\u003c/code\u003e is only called after successful processing. If a consumer crashes mid-process, the message stays in the PEL and \u003ccode\u003ereclaimStalledMessages\u003c/code\u003e can hand it to another consumer ‚Äî this is how you get at-least-once delivery guarantees without a dedicated message broker.\u003c/p\u003e\n\u003ch2\u003ePub/Sub: Real-Time Notifications\u003c/h2\u003e\n\u003cp\u003eRedis Pub/Sub is a fire-and-forget messaging system. Publishers send messages to channels; all current subscribers receive them. Messages are \u003cstrong\u003enot persisted\u003c/strong\u003e ‚Äî if a subscriber is down, it misses messages.\u003c/p\u003e\n\u003cp\u003eThink of Pub/Sub like a radio broadcast: the station transmits at all times, and you only hear it while your radio is on. This is perfect for live notifications where freshness matters more than completeness ‚Äî telling a user they have a new chat message is only useful while they're online anyway.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003e// Publisher\n@Service\npublic class NotificationPublisher {\n\n    @Autowired\n    private RedisTemplate\u0026#x3C;String, Object\u003e redisTemplate;\n\n    public void notifyUser(String userId, NotificationEvent event) {\n        String channel = \"notifications:\" + userId;\n        redisTemplate.convertAndSend(channel, event);\n    }\n\n    public void broadcastSystemAlert(AlertEvent alert) {\n        redisTemplate.convertAndSend(\"system-alerts\", alert);\n    }\n}\n\n// Subscriber configuration\n@Configuration\npublic class RedisPubSubConfig {\n\n    @Bean\n    public RedisMessageListenerContainer redisMessageListenerContainer(\n            RedisConnectionFactory factory,\n            NotificationMessageListener listener) {\n        RedisMessageListenerContainer container = new RedisMessageListenerContainer();\n        container.setConnectionFactory(factory);\n\n        // Subscribe to user-specific notifications\n        container.addMessageListener(listener,\n            new PatternTopic(\"notifications:*\")); // Wildcard subscription\n\n        // Subscribe to system alerts\n        container.addMessageListener(listener,\n            new ChannelTopic(\"system-alerts\"));\n\n        return container;\n    }\n}\n\n@Component\npublic class NotificationMessageListener implements MessageListener {\n\n    @Autowired\n    private WebSocketService webSocketService;\n\n    @Override\n    public void onMessage(Message message, byte[] pattern) {\n        String channel = new String(message.getChannel());\n        String body = new String(message.getBody());\n\n        if (channel.startsWith(\"notifications:\")) {\n            String userId = channel.replace(\"notifications:\", \"\");\n            webSocketService.sendToUser(userId, body);\n        } else if (channel.equals(\"system-alerts\")) {\n            webSocketService.broadcast(body);\n        }\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eWhen to use Pub/Sub vs Streams:\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003ePub/Sub\u003c/strong\u003e: Real-time notifications where it's acceptable to miss messages (user online alerts, live dashboards)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eStreams\u003c/strong\u003e: Event sourcing, order processing, any case where you need persistence and guaranteed delivery\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eDistributed Locking with SETNX\u003c/h2\u003e\n\u003cp\u003eDistributed locks solve a problem that seems simple but isn't: ensuring only one instance of your application performs a critical operation at a time. Imagine two payment service instances both receiving a retry for the same order ‚Äî without a lock, you could charge the user twice. Redis's \u003ccode\u003eSETNX\u003c/code\u003e (Set if Not eXists) combined with a TTL gives you a lock that is both exclusive and self-expiring.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003e@Service\npublic class DistributedLockService {\n\n    @Autowired\n    private StringRedisTemplate redis;\n\n    private static final long LOCK_TTL_SECONDS = 30;\n\n    /**\n     * Acquire a distributed lock. Returns lock token if acquired, null if not.\n     * The token is needed to safely release the lock.\n     */\n    public String acquireLock(String resourceId) {\n        String lockKey = \"lock:\" + resourceId;\n        String lockToken = UUID.randomUUID().toString(); // Unique per lock acquisition\n\n        Boolean acquired = redis.opsForValue().setIfAbsent(\n            lockKey,\n            lockToken,\n            Duration.ofSeconds(LOCK_TTL_SECONDS)\n        );\n\n        return Boolean.TRUE.equals(acquired) ? lockToken : null;\n    }\n\n    /**\n     * Release only if we still own the lock. Uses Lua script for atomicity.\n     * Without Lua: check-then-delete is a TOCTOU race condition.\n     */\n    public boolean releaseLock(String resourceId, String lockToken) {\n        String lockKey = \"lock:\" + resourceId;\n\n        String luaScript = \"\"\"\n            if redis.call('get', KEYS[1]) == ARGV[1] then\n                return redis.call('del', KEYS[1])\n            else\n                return 0\n            end\n            \"\"\";\n\n        Long result = redis.execute(\n            new DefaultRedisScript\u0026#x3C;\u003e(luaScript, Long.class),\n            List.of(lockKey),\n            lockToken\n        );\n\n        return Long.valueOf(1).equals(result);\n    }\n\n    // Usage pattern\n    public void processPayment(String orderId) {\n        String lockToken = acquireLock(\"payment:\" + orderId);\n        if (lockToken == null) {\n            throw new ResourceBusyException(\"Payment already being processed for order \" + orderId);\n        }\n\n        try {\n            paymentService.charge(orderId);\n        } finally {\n            releaseLock(\"payment:\" + orderId, lockToken);\n        }\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe Lua script for releasing the lock is the critical piece here: it checks and deletes the key atomically. Without it, there's a window where your lock could expire between the \u003ccode\u003eGET\u003c/code\u003e check and the \u003ccode\u003eDEL\u003c/code\u003e ‚Äî and you'd end up deleting another process's lock. The unique \u003ccode\u003elockToken\u003c/code\u003e per acquisition is what prevents this: even if the TTL fires, you can't accidentally release a lock you don't own.\u003c/p\u003e\n\u003ch2\u003eHyperLogLog: Counting Unique Visitors at Scale\u003c/h2\u003e\n\u003cp\u003eCounting exact unique visitors requires storing every visitor ID ‚Äî expensive at scale. HyperLogLog estimates cardinality with ~0.81% error using only 12KB regardless of input size.\u003c/p\u003e\n\u003cp\u003eImagine trying to count how many unique people walked through a mall's entrance over a year. You could keep a list of every face, but storing millions of names is expensive. HyperLogLog is like a probabilistic tally counter ‚Äî it can't tell you exactly who visited, but it can tell you \"roughly 2.3 million unique visitors\" while using the same amount of memory whether you have 100 or 100 million visitors.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003e@Service\npublic class UniqueVisitorCounter {\n\n    @Autowired\n    private StringRedisTemplate redis;\n\n    public void trackVisit(String pageId, String visitorId) {\n        String key = \"page_visitors:\" + pageId + \":\" + LocalDate.now();\n        // PFADD: O(1), uses ~12KB regardless of cardinality\n        redis.opsForHyperLogLog().add(key, visitorId);\n        redis.expire(key, Duration.ofDays(30));\n    }\n\n    public long getUniqueVisitors(String pageId) {\n        String key = \"page_visitors:\" + pageId + \":\" + LocalDate.now();\n        // PFCOUNT: returns estimated cardinality with 0.81% error\n        return redis.opsForHyperLogLog().size(key);\n    }\n\n    public long getUniqueVisitorsAcrossPages(List\u0026#x3C;String\u003e pageIds) {\n        String[] keys = pageIds.stream()\n            .map(id -\u003e \"page_visitors:\" + id + \":\" + LocalDate.now())\n            .toArray(String[]::new);\n        // PFCOUNT on multiple keys: union estimate\n        return redis.opsForHyperLogLog().size(keys);\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe 0.81% error rate is the trade-off you're accepting: for a page with 1 million visitors, your count will be off by at most ~8,100. For analytics dashboards where \"approximately 1 million\" is meaningful, this is a worthwhile trade for a 99.9% reduction in memory usage compared to storing exact visitor IDs.\u003c/p\u003e\n\u003ch2\u003eProduction Configuration\u003c/h2\u003e\n\u003cp\u003eGetting Redis working in development is easy; getting it right in production requires deliberate configuration. The settings below cover connection pooling (to avoid connection storms during traffic spikes), cluster topology awareness (so your client can find the right shard after a failover), and eviction policy (which determines what Redis does when memory fills up).\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-yaml\"\u003e# Redis configuration for production\nspring:\n  redis:\n    host: redis-cluster.internal\n    port: 6379\n    timeout: 2000ms\n    lettuce:\n      pool:\n        max-active: 50\n        max-idle: 10\n        min-idle: 5\n        max-wait: 1000ms\n      cluster:\n        refresh:\n          adaptive: true           # Detect cluster topology changes\n          period: 30s\n\n# Key eviction policy ‚Äî critical for cache usage\n# volatile-lru: evict keys with TTL, LRU order (recommended for mixed cache/persistent)\n# allkeys-lru: evict any key, LRU order (for pure cache)\n# noeviction: reject writes when full (use for persistent data)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e# maxmemory and eviction policy (redis.conf or CONFIG SET)\nCONFIG SET maxmemory 8gb\nCONFIG SET maxmemory-policy allkeys-lfu  # LFU: better than LRU for Zipf distributions\n\n# Monitor evicted keys ‚Äî should be near 0 for persistent data\nINFO stats | grep evicted_keys\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIf you are using Redis for both caching and persistent data structures (like Streams or sorted sets with leaderboard data), use \u003ccode\u003evolatile-lru\u003c/code\u003e so only keys with a TTL are evicted ‚Äî your persistent data stays safe. If Redis is purely a cache, \u003ccode\u003eallkeys-lfu\u003c/code\u003e is the best modern choice because it evicts the least-frequently-used keys, which handles the real-world \"long tail\" of cached objects better than a strict LRU.\u003c/p\u003e\n\u003ch2\u003eWhen to Use Redis vs What\u003c/h2\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eUse Case\u003c/th\u003e\n\u003cth\u003eRedis Data Structure\u003c/th\u003e\n\u003cth\u003eAlternative\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eSimple cache\u003c/td\u003e\n\u003ctd\u003eString\u003c/td\u003e\n\u003ctd\u003eMemcached\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eSession storage\u003c/td\u003e\n\u003ctd\u003eHash\u003c/td\u003e\n\u003ctd\u003eDatabase\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eLeaderboard\u003c/td\u003e\n\u003ctd\u003eSorted Set\u003c/td\u003e\n\u003ctd\u003ePostgreSQL (complex query)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eRate limiting\u003c/td\u003e\n\u003ctd\u003eSorted Set / String\u003c/td\u003e\n\u003ctd\u003eAPI Gateway\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ePub/Sub\u003c/td\u003e\n\u003ctd\u003ePub/Sub\u003c/td\u003e\n\u003ctd\u003eWebSockets (no persistence)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eEvent log\u003c/td\u003e\n\u003ctd\u003eStream\u003c/td\u003e\n\u003ctd\u003eKafka (for high volume)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eUnique count\u003c/td\u003e\n\u003ctd\u003eHyperLogLog\u003c/td\u003e\n\u003ctd\u003eExact count in DB\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eDistributed lock\u003c/td\u003e\n\u003ctd\u003eString (SETNX)\u003c/td\u003e\n\u003ctd\u003eZooKeeper\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eQueue\u003c/td\u003e\n\u003ctd\u003eList\u003c/td\u003e\n\u003ctd\u003eRabbitMQ\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eMembership test\u003c/td\u003e\n\u003ctd\u003eBloom Filter (RedisBloom)\u003c/td\u003e\n\u003ctd\u003eExact set\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003eRedis's sweet spot is low-latency, high-throughput operations on data structures where the dataset fits in memory. The moment your dataset exceeds available RAM or you need complex query patterns, reach for PostgreSQL or a specialized system.\u003c/p\u003e\n\u003cp\u003eThe key insight is to \u003cstrong\u003ematch the data structure to the access pattern\u003c/strong\u003e ‚Äî not to treat Redis as a generic key-value store where everything is a serialized JSON blob.\u003c/p\u003e\n","tableOfContents":[{"id":"setup-lettuce-configuration","text":"Setup: Lettuce Configuration","level":2},{"id":"sorted-sets-leaderboards-and-rate-limiting","text":"Sorted Sets: Leaderboards and Rate Limiting","level":2},{"id":"use-case-1-real-time-leaderboard","text":"Use Case 1: Real-Time Leaderboard","level":3},{"id":"use-case-2-sliding-window-rate-limiter","text":"Use Case 2: Sliding Window Rate Limiter","level":3},{"id":"streams-persistent-event-log","text":"Streams: Persistent Event Log","level":2},{"id":"pubsub-real-time-notifications","text":"Pub/Sub: Real-Time Notifications","level":2},{"id":"distributed-locking-with-setnx","text":"Distributed Locking with SETNX","level":2},{"id":"hyperloglog-counting-unique-visitors-at-scale","text":"HyperLogLog: Counting Unique Visitors at Scale","level":2},{"id":"production-configuration","text":"Production Configuration","level":2},{"id":"when-to-use-redis-vs-what","text":"When to Use Redis vs What","level":2}]},"relatedPosts":[{"title":"Cassandra Data Modeling: Design for Queries, Not Entities","description":"Apache Cassandra data modeling from first principles: partition key design, clustering columns, denormalization strategies, avoiding hot partitions, materialized views vs. manual duplication, and the anti-patterns that kill Cassandra performance.","date":"2025-06-18","category":"Databases","tags":["cassandra","nosql","data modeling","distributed databases","partition key","cql","time series"],"featured":false,"affiliateSection":"database-resources","slug":"cassandra-data-modeling","readingTime":"9 min read","excerpt":"Cassandra is a write-optimized distributed database built for linear horizontal scalability. It stores data in a distributed hash ring ‚Äî every node is equal, there's no primary, and data placement is determined by partit‚Ä¶"},{"title":"DynamoDB Advanced Patterns: Single-Table Design and Beyond","description":"Production DynamoDB: single-table design with access pattern mapping, GSI overloading, sparse indexes, adjacency lists for graph relationships, DynamoDB Streams for event-driven architectures, and the read/write capacity math that prevents bill shock.","date":"2025-06-13","category":"Databases","tags":["dynamodb","aws","nosql","single-table design","gsi","dynamodb streams","serverless"],"featured":false,"affiliateSection":"database-resources","slug":"dynamodb-advanced-patterns","readingTime":"9 min read","excerpt":"DynamoDB is a fully managed key-value and document database that delivers single-digit millisecond performance at any scale. It achieves this with a fundamental constraint: you must define your access patterns before you‚Ä¶"},{"title":"Zero-Downtime Database Migrations: Patterns for Production","description":"How to safely migrate production databases without downtime: expand-contract pattern, backward-compatible schema changes, rolling deployments with dual-write, column renaming strategies, and the PostgreSQL-specific techniques for large table alterations.","date":"2025-06-08","category":"Databases","tags":["database","migrations","postgresql","zero downtime","devops","schema evolution","flyway","liquibase"],"featured":false,"affiliateSection":"database-resources","slug":"zero-downtime-database-migrations","readingTime":"8 min read","excerpt":"Database migrations are the most dangerous part of a deployment. Application code changes are stateless and reversible ‚Äî rollback a bad deploy and your code is back to the previous version. Database schema changes are st‚Ä¶"}]},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"redis-beyond-cache"},"buildId":"rpFn_jslWZ9qPkJwor7RD","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>