<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8" data-next-head=""/><meta name="viewport" content="width=device-width" data-next-head=""/><title data-next-head="">Kafka Internals Deep Dive: Partitions, Offsets, and Consumer Groups<!-- --> | CodeSprintPro</title><meta name="description" content="Understand how Apache Kafka achieves high throughput through log-based storage, how offsets enable reliable consumption, and how consumer groups scale processing horizontally." data-next-head=""/><meta name="author" content="Sachin Sarawgi" data-next-head=""/><link rel="canonical" href="https://codesprintpro.com/blog/kafka-internals-deep-dive/" data-next-head=""/><meta property="og:type" content="article" data-next-head=""/><meta property="og:title" content="Kafka Internals Deep Dive: Partitions, Offsets, and Consumer Groups" data-next-head=""/><meta property="og:description" content="Understand how Apache Kafka achieves high throughput through log-based storage, how offsets enable reliable consumption, and how consumer groups scale processing horizontally." data-next-head=""/><meta property="og:url" content="https://codesprintpro.com/blog/kafka-internals-deep-dive/" data-next-head=""/><meta property="og:image" content="https://codesprintpro.com/images/og-default.jpg" data-next-head=""/><meta property="og:site_name" content="CodeSprintPro" data-next-head=""/><meta property="article:published_time" content="2025-01-15" data-next-head=""/><meta property="article:author" content="Sachin Sarawgi" data-next-head=""/><meta property="article:section" content="Messaging" data-next-head=""/><meta property="article:tag" content="kafka" data-next-head=""/><meta property="article:tag" content="distributed systems" data-next-head=""/><meta property="article:tag" content="streaming" data-next-head=""/><meta property="article:tag" content="java" data-next-head=""/><meta name="twitter:card" content="summary_large_image" data-next-head=""/><meta name="twitter:title" content="Kafka Internals Deep Dive: Partitions, Offsets, and Consumer Groups" data-next-head=""/><meta name="twitter:description" content="Understand how Apache Kafka achieves high throughput through log-based storage, how offsets enable reliable consumption, and how consumer groups scale processing horizontally." data-next-head=""/><meta name="twitter:image" content="https://codesprintpro.com/images/og-default.jpg" data-next-head=""/><script type="application/ld+json" data-next-head="">{"@context":"https://schema.org","@type":"BlogPosting","headline":"Kafka Internals Deep Dive: Partitions, Offsets, and Consumer Groups","description":"Understand how Apache Kafka achieves high throughput through log-based storage, how offsets enable reliable consumption, and how consumer groups scale processing horizontally.","image":"https://codesprintpro.com/images/og-default.jpg","datePublished":"2025-01-15","dateModified":"2025-01-15","author":{"@type":"Person","name":"Sachin Sarawgi","url":"https://codesprintpro.com","sameAs":["https://www.linkedin.com/in/sachin-sarawgi/","https://github.com/codesprintpro","https://medium.com/@codesprintpro"]},"publisher":{"@type":"Organization","name":"CodeSprintPro","url":"https://codesprintpro.com","logo":{"@type":"ImageObject","url":"https://codesprintpro.com/favicon/favicon-96x96.png"}},"mainEntityOfPage":{"@type":"WebPage","@id":"https://codesprintpro.com/blog/kafka-internals-deep-dive/"},"keywords":"kafka, distributed systems, streaming, java","articleSection":"Messaging"}</script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" integrity="sha512-9usAa10IRO0HhonpyAIVpjrylPvoDwiPUiKdWk5t3PyolY1cOd4DSE0Ga+ri4AuTroPR5aQvXU9xC6qOPnzFeg==" crossorigin="anonymous" referrerPolicy="no-referrer"/><script async="" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-XXXXXXXXXXXXXXXX" crossorigin="anonymous"></script><link rel="preload" href="/_next/static/media/e4af272ccee01ff0-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/css/735d4373f93910ca.css" as="style"/><link rel="stylesheet" href="/_next/static/css/735d4373f93910ca.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-11a4a2dad04962bb.js" defer=""></script><script src="/_next/static/chunks/framework-1ce91eb6f9ecda85.js" defer=""></script><script src="/_next/static/chunks/main-c7f4109f032d7b6e.js" defer=""></script><script src="/_next/static/chunks/pages/_app-1a852bd9e38c70ab.js" defer=""></script><script src="/_next/static/chunks/730-db7827467817f501.js" defer=""></script><script src="/_next/static/chunks/90-1cd4611704c3dbe0.js" defer=""></script><script src="/_next/static/chunks/440-29f4b99a44e744b5.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-0c1b14a33d5e05ee.js" defer=""></script><script src="/_next/static/rpFn_jslWZ9qPkJwor7RD/_buildManifest.js" defer=""></script><script src="/_next/static/rpFn_jslWZ9qPkJwor7RD/_ssgManifest.js" defer=""></script></head><body><div id="__next"><main class="__className_f367f3"><div class="min-h-screen bg-white"><nav class="fixed w-full z-50 transition-all duration-300 bg-white shadow-md" style="transform:translateY(-100px) translateZ(0)"><div class="container mx-auto px-4 sm:px-6 lg:px-8"><div class="flex items-center justify-between h-16"><a class="text-xl font-bold transition-colors text-blue-600" href="/">CodeSprintPro</a><div class="hidden md:flex items-center space-x-8"><a class="text-sm font-medium transition-colors text-blue-600" href="/blog/">Blog</a><a class="text-sm font-medium transition-colors text-gray-600 hover:text-blue-600" href="/#about">About</a><a class="text-sm font-medium transition-colors text-gray-600 hover:text-blue-600" href="/#portfolio">Portfolio</a><a class="text-sm font-medium transition-colors text-gray-600 hover:text-blue-600" href="/#contact">Contact</a></div><button class="md:hidden p-2 rounded-lg transition-colors hover:bg-gray-100 text-gray-600" aria-label="Toggle mobile menu"><svg class="w-6 h-6" fill="none" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" stroke="currentColor"><path d="M4 6h16M4 12h16M4 18h16"></path></svg></button></div></div></nav><div class="pt-20"><div class="bg-gradient-to-br from-gray-900 to-blue-950 py-16"><div class="container mx-auto px-4 sm:px-6 lg:px-8 max-w-5xl"><nav class="flex items-center gap-2 text-sm text-gray-400 mb-6"><a class="hover:text-white transition-colors" href="/">Home</a><span>/</span><a class="hover:text-white transition-colors" href="/blog/">Blog</a><span>/</span><span class="text-gray-300 truncate max-w-xs">Kafka Internals Deep Dive: Partitions, Offsets, and Consumer Groups</span></nav><span class="inline-block text-xs font-semibold px-3 py-1 rounded-full bg-blue-100 text-blue-700 mb-4">Messaging</span><h1 class="text-3xl md:text-5xl font-bold text-white mb-4 leading-tight">Kafka Internals Deep Dive: Partitions, Offsets, and Consumer Groups</h1><p class="text-gray-300 text-lg mb-6 max-w-3xl">Understand how Apache Kafka achieves high throughput through log-based storage, how offsets enable reliable consumption, and how consumer groups scale processing horizontally.</p><div class="flex flex-wrap items-center gap-4 text-gray-400 text-sm"><span class="flex items-center gap-1.5"><svg class="w-4 h-4" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M16 7a4 4 0 11-8 0 4 4 0 018 0zM12 14a7 7 0 00-7 7h14a7 7 0 00-7-7z"></path></svg>Sachin Sarawgi</span><span>¬∑</span><span>January 15, 2025</span><span>¬∑</span><span class="flex items-center gap-1"><svg class="w-4 h-4" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>10 min read</span></div><div class="flex flex-wrap gap-2 mt-4"><span class="text-xs text-gray-400 bg-gray-800 px-2 py-1 rounded">#<!-- -->kafka</span><span class="text-xs text-gray-400 bg-gray-800 px-2 py-1 rounded">#<!-- -->distributed systems</span><span class="text-xs text-gray-400 bg-gray-800 px-2 py-1 rounded">#<!-- -->streaming</span><span class="text-xs text-gray-400 bg-gray-800 px-2 py-1 rounded">#<!-- -->java</span></div></div></div><div class="container mx-auto px-4 sm:px-6 lg:px-8 max-w-5xl py-12"><div class="flex gap-12"><div class="flex-1 min-w-0"><article class="prose prose-lg max-w-none prose-headings:text-gray-900 prose-headings:font-bold prose-h2:text-2xl prose-h2:mt-10 prose-h2:mb-4 prose-h3:text-xl prose-h3:mt-8 prose-h3:mb-3 prose-p:text-gray-700 prose-p:leading-relaxed prose-a:text-blue-600 prose-a:no-underline hover:prose-a:underline prose-strong:text-gray-900 prose-blockquote:border-blue-600 prose-blockquote:text-gray-600 prose-code:text-blue-700 prose-code:bg-blue-50 prose-code:px-1.5 prose-code:py-0.5 prose-code:rounded prose-code:text-sm prose-code:before:content-none prose-code:after:content-none prose-pre:rounded-xl prose-img:rounded-xl prose-img:shadow-md prose-table:text-sm prose-th:bg-gray-100 prose-th:text-gray-700"><p>Apache Kafka is the de facto standard for event streaming in distributed systems, but most developers treat it as a black box ‚Äî a durable message queue with a fancy name. Understanding Kafka's internals unlocks its true potential: predictable performance at scale, reliable exactly-once processing, and horizontal scalability without coordination overhead.</p>
<p>This article goes deep on partitions, offsets, consumer groups, and replication ‚Äî with production-grade Java examples.</p>
<h2>Why Kafka Is Not a Message Queue</h2>
<p>Traditional message queues like RabbitMQ deliver messages to consumers and delete them after acknowledgment. Kafka's fundamental design is different: <strong>it is a distributed, partitioned, replicated commit log</strong>.</p>
<pre><code>Traditional Queue:                  Kafka Log:

Producer ‚Üí [Queue] ‚Üí Consumer       Producer ‚Üí [Partition Log]
           (deleted after ACK)                  offset 0: event
                                                offset 1: event
                                                offset 2: event  ‚Üê Consumer A reads here
                                                offset 3: event  ‚Üê Consumer B reads here
                                                (retained for configurable time)
</code></pre>
<p>This distinction matters enormously. With Kafka:</p>
<ul>
<li><strong>Multiple consumer groups</strong> can independently read the same data at their own pace</li>
<li><strong>Reprocessing</strong> is trivial ‚Äî reset the offset and replay</li>
<li><strong>Time travel</strong> is possible ‚Äî query data from any point in history</li>
<li><strong>Throughput is predictable</strong> ‚Äî sequential disk writes are fast and consistent</li>
</ul>
<h2>Partition Anatomy</h2>
<p>Every Kafka topic is divided into one or more <strong>partitions</strong>. A partition is an ordered, immutable sequence of records ‚Äî a physical append-only log file on disk.</p>
<pre><code>Topic: "order-events" (4 partitions, replication factor 3)

Partition 0: [ev0][ev1][ev2][ev3][ev4]...  ‚Üí Leader: Broker 1
             Replicas: Broker 2, Broker 3

Partition 1: [ev0][ev1][ev2]...            ‚Üí Leader: Broker 2
             Replicas: Broker 1, Broker 3

Partition 2: [ev0][ev1][ev2][ev3]...       ‚Üí Leader: Broker 3
             Replicas: Broker 1, Broker 2

Partition 3: [ev0][ev1]...                 ‚Üí Leader: Broker 1
             Replicas: Broker 2, Broker 3
</code></pre>
<p>Key properties:</p>
<ul>
<li><strong>Ordering is guaranteed within a partition</strong>, not across partitions</li>
<li><strong>Parallelism scales with partition count</strong> ‚Äî more partitions = more consumers</li>
<li><strong>Messages are routed to partitions by key</strong> (default: round-robin if no key)</li>
</ul>
<h3>Partition Key Selection</h3>
<p>Your partition key determines which events land in the same partition. Events in the same partition are guaranteed to be processed in order.</p>
<pre><code class="language-java">// All events for the same orderId go to the same partition
// This ensures order-placed, order-paid, order-shipped are processed in sequence
ProducerRecord&#x3C;String, OrderEvent> record = new ProducerRecord&#x3C;>(
    "order-events",
    orderId,         // partition key ‚Äî hash(orderId) % numPartitions
    orderEvent
);
producer.send(record);

// Bad key choice: random UUID or timestamp ‚Äî destroys ordering
// Good key choices: userId, orderId, deviceId, sessionId
</code></pre>
<h2>The In-Sync Replica (ISR) Set</h2>
<p>Kafka uses <strong>leader-based replication</strong>. Each partition has one leader and N-1 followers (replicas). All reads and writes go through the leader.</p>
<p>The <strong>In-Sync Replica (ISR)</strong> set is the subset of replicas that are fully caught up with the leader. A replica falls out of ISR if it lags more than <code>replica.lag.time.max.ms</code> (default: 30 seconds).</p>
<pre><code>Partition Leader (Broker 1): offset 150
  ISR = {Broker 1, Broker 2, Broker 3}  ‚Üê All caught up

Scenario: Broker 3 network hiccup, lags by 45 seconds
  ISR = {Broker 1, Broker 2}             ‚Üê Broker 3 removed from ISR

Scenario: Broker 1 crashes
  New leader elected from ISR: Broker 2
  ISR = {Broker 2}                        ‚Üê Only Broker 2 was in-sync
</code></pre>
<h2>Producer Configuration: Durability vs Throughput</h2>
<p>The <code>acks</code> setting controls when the producer considers a write successful:</p>
<pre><code class="language-java">Properties producerProps = new Properties();
producerProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "broker1:9092,broker2:9092");
producerProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
producerProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, JsonSerializer.class.getName());

// acks=0: Fire and forget ‚Äî fastest, data loss possible
// acks=1: Leader ACK ‚Äî default, leader crash before replication = data loss
// acks=all (or -1): All ISR ACK ‚Äî safest, use for critical data
producerProps.put(ProducerConfig.ACKS_CONFIG, "all");

// Prevent duplicate messages on retry
producerProps.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, true);

// Max in-flight requests per connection (must be 1 for ordering with retries, unless idempotent)
producerProps.put(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION, 5); // safe with idempotence

// Batching: wait up to 20ms for batch to fill before sending
producerProps.put(ProducerConfig.LINGER_MS_CONFIG, 20);
producerProps.put(ProducerConfig.BATCH_SIZE_CONFIG, 65536); // 64KB batch

// Compression reduces network IO by 5-7x for JSON
producerProps.put(ProducerConfig.COMPRESSION_TYPE_CONFIG, "lz4");
</code></pre>
<p><strong>Throughput numbers</strong> (rough benchmarks on commodity hardware):</p>
<ul>
<li><code>acks=0</code>: ~1M records/sec</li>
<li><code>acks=1</code>: ~500K records/sec</li>
<li><code>acks=all</code> + <code>min.insync.replicas=2</code>: ~200K records/sec</li>
</ul>
<p>The tradeoff is explicit: more durability = lower throughput.</p>
<h2>Offsets and Consumer Position</h2>
<p>Every record in a partition has an <strong>offset</strong> ‚Äî a monotonically increasing integer starting at 0. Offsets are Kafka's way of tracking consumer position.</p>
<pre><code class="language-java">Properties consumerProps = new Properties();
consumerProps.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "broker1:9092");
consumerProps.put(ConsumerConfig.GROUP_ID_CONFIG, "order-processor-v1");
consumerProps.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
consumerProps.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, JsonDeserializer.class.getName());

// auto.offset.reset: what to do when no committed offset exists
// "earliest": read from beginning (replay all history)
// "latest": read only new messages (default)
consumerProps.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");

// Disable auto-commit: commit manually after processing
consumerProps.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);

KafkaConsumer&#x3C;String, OrderEvent> consumer = new KafkaConsumer&#x3C;>(consumerProps);
consumer.subscribe(List.of("order-events"));

try {
    while (true) {
        ConsumerRecords&#x3C;String, OrderEvent> records = consumer.poll(Duration.ofMillis(100));

        for (ConsumerRecord&#x3C;String, OrderEvent> record : records) {
            try {
                processOrder(record.value());
                // Only commit AFTER successful processing
                // This prevents losing events on consumer crash
            } catch (Exception e) {
                // Dead-letter queue or retry logic here
                log.error("Failed to process {}, offset {}", record.key(), record.offset(), e);
            }
        }

        // Synchronous commit: blocks until broker confirms
        // Use commitAsync() for higher throughput if at-least-once is acceptable
        consumer.commitSync();
    }
} finally {
    consumer.close();
}
</code></pre>
<h3>Auto-Commit vs Manual Commit</h3>
<table>
<thead>
<tr>
<th></th>
<th>Auto-Commit</th>
<th>Manual Commit</th>
</tr>
</thead>
<tbody>
<tr>
<td>Config</td>
<td><code>enable.auto.commit=true</code></td>
<td><code>enable.auto.commit=false</code></td>
</tr>
<tr>
<td>Commits every</td>
<td><code>auto.commit.interval.ms</code> (5s default)</td>
<td>After you call <code>commitSync()</code>/<code>commitAsync()</code></td>
</tr>
<tr>
<td>Risk</td>
<td>Commits before processing = message loss</td>
<td>Your responsibility</td>
</tr>
<tr>
<td>Use case</td>
<td>Low-stakes analytics</td>
<td>Financial transactions, critical processing</td>
</tr>
</tbody>
</table>
<h2>Consumer Groups: Horizontal Scaling</h2>
<p>A <strong>consumer group</strong> is a set of consumers that share the work of consuming a topic. Kafka assigns each partition to exactly one consumer in the group.</p>
<pre><code>Topic: "order-events" with 6 partitions

Consumer Group: "order-processor" (3 consumers)
  Consumer 1 ‚Üí Partition 0, Partition 1
  Consumer 2 ‚Üí Partition 2, Partition 3
  Consumer 3 ‚Üí Partition 4, Partition 5

If Consumer 2 crashes:
  Consumer 1 ‚Üí Partition 0, Partition 1, Partition 2
  Consumer 3 ‚Üí Partition 3, Partition 4, Partition 5
  (Kafka triggers rebalance within session.timeout.ms)
</code></pre>
<p><strong>Scaling rules:</strong></p>
<ul>
<li>More consumers than partitions = some consumers are idle (wasted resources)</li>
<li>More partitions than consumers = each consumer handles multiple partitions</li>
<li>Max parallelism = partition count</li>
</ul>
<p>The implication of the last rule is important: if you have 4 partitions and deploy 8 consumer instances, 4 of them will sit idle doing nothing. Kafka assigns one consumer per partition within a group ‚Äî it doesn't split a single partition across consumers. This is why you should provision partitions generously at topic creation time. Kafka does not allow reducing partition count, and increasing it later can change the key-to-partition mapping, breaking ordering guarantees for existing keys.</p>
<p>Scaling out is simple: start another consumer instance with the same <code>group.id</code>. Kafka automatically triggers a rebalance and redistributes partitions across all active consumers. You can go from 3 to 6 consumers handling a 6-partition topic with zero configuration changes.</p>
<pre><code class="language-java">// Scale by starting more consumer instances with the same group.id
// Each instance handles different partitions automatically ‚Äî no config changes needed

// To check current partition assignments and consumer lag:
// bin/kafka-consumer-groups.sh --bootstrap-server broker1:9092 \
//   --describe --group order-processor
//
// Output shows:
//   GROUP            TOPIC         PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG
//   order-processor  order-events  0          1024            1050            26   ‚Üê 26 unprocessed
//   order-processor  order-events  1          876             876             0    ‚Üê fully caught up
</code></pre>
<p>A lag of 26 on partition 0 means the consumer is 26 messages behind the producer. A lag of 0 means the consumer is keeping up in real time. Growing lag is the first sign that you need more consumers or faster processing logic.</p>
<h2>Exactly-Once Semantics</h2>
<p>Kafka 0.11+ supports exactly-once processing through idempotent producers and transactions.</p>
<pre><code class="language-java">producerProps.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, true);
producerProps.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, "order-processor-1"); // unique per producer

KafkaProducer&#x3C;String, String> producer = new KafkaProducer&#x3C;>(producerProps);
producer.initTransactions();

KafkaConsumer&#x3C;String, OrderEvent> consumer = // ... configured as above

try {
    ConsumerRecords&#x3C;String, OrderEvent> records = consumer.poll(Duration.ofMillis(100));

    producer.beginTransaction();
    try {
        for (ConsumerRecord&#x3C;String, OrderEvent> record : records) {
            OrderResult result = processOrder(record.value());

            // Produce result to output topic
            producer.send(new ProducerRecord&#x3C;>("order-results", record.key(), result.toJson()));
        }

        // Atomically commit offsets and produce ‚Äî either both happen or neither
        Map&#x3C;TopicPartition, OffsetAndMetadata> offsets = new HashMap&#x3C;>();
        records.partitions().forEach(tp -> {
            long lastOffset = records.records(tp).get(records.records(tp).size() - 1).offset();
            offsets.put(tp, new OffsetAndMetadata(lastOffset + 1));
        });

        producer.sendOffsetsToTransaction(offsets, consumer.groupMetadata());
        producer.commitTransaction();

    } catch (Exception e) {
        producer.abortTransaction();
        throw e;
    }
}
</code></pre>
<h2>Monitoring Consumer Lag</h2>
<p>Consumer lag is the most critical Kafka operational metric. <strong>Lag = leader offset ‚àí consumer committed offset.</strong> It tells you how far behind the consumer is from the latest data the producer has written.</p>
<p>A lag of zero means the consumer is processing events in real time. A lag of 10,000 means there are 10,000 unprocessed events sitting in the partition waiting to be consumed. If that number is growing, your consumers cannot keep up with the incoming load. If it's stable, consumers are processing as fast as events arrive. If it's shrinking, consumers are catching up after a backlog.</p>
<p>Why does lag grow? The two most common reasons are: (1) processing logic got slower ‚Äî perhaps a downstream database query that used to take 5ms now takes 500ms; or (2) producer throughput increased ‚Äî a marketing email triggered a spike in user activity that doubled event volume. Monitoring lag gives you early warning before either of these causes a user-visible delay.</p>
<pre><code class="language-java">// Programmatic lag check ‚Äî useful for building custom alerting
AdminClient adminClient = AdminClient.create(Map.of(
    AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, "broker1:9092"
));

Map&#x3C;TopicPartition, OffsetAndMetadata> committed = adminClient
    .listConsumerGroupOffsets("order-processor")
    .partitionsToOffsetAndMetadata()
    .get();

Map&#x3C;TopicPartition, Long> endOffsets = consumer.endOffsets(committed.keySet());

long totalLag = 0;
for (Map.Entry&#x3C;TopicPartition, Long> entry : endOffsets.entrySet()) {
    OffsetAndMetadata committedOffset = committed.get(entry.getKey());
    long lag = entry.getValue() - (committedOffset != null ? committedOffset.offset() : 0);
    totalLag += lag;
    log.info("Partition {}: lag = {}", entry.getKey(), lag);
}

// Alert threshold: if totalLag > maxAcceptableLag, trigger scale-out or alert
</code></pre>
<p>Set your alert threshold based on your latency SLA. If your system must process events within 30 seconds, and your consumers handle 100 events per second per instance, a lag of 3,000 means you're 30 seconds from breaching the SLA. Alert at half that ‚Äî 1,500 ‚Äî to give yourself time to add consumers before users notice.</p>
<p>For most teams, exposing <code>kafka_consumer_records_lag_max</code> via Micrometer to Prometheus and alerting in Grafana is the right setup. The programmatic approach above is useful for building auto-scaling logic ‚Äî dynamically adding consumer instances when lag exceeds a threshold and removing them when it returns to baseline.</p>
<p>Production Kafka is not complicated ‚Äî it becomes complicated when teams skip understanding these fundamentals. The partition model, offset management, and ISR mechanics explain almost every production incident involving Kafka. Build these mental models first, then instrument them.</p>
<h2>Key Takeaways for Production</h2>
<ol>
<li><strong>Partition count is permanent</strong> ‚Äî choose based on your parallelism needs, not current load (6-12 partitions is usually sufficient to start)</li>
<li><strong><code>acks=all</code> + <code>min.insync.replicas=2</code></strong> for any data you cannot afford to lose</li>
<li><strong>Manual offset commit</strong> for business-critical processing; auto-commit for analytics</li>
<li><strong>Consumer lag</strong> is your early warning system ‚Äî monitor it obsessively</li>
<li><strong>Idempotent producers</strong> are free (negligible overhead) ‚Äî always enable them</li>
<li><strong>Keys matter</strong> ‚Äî wrong key = wrong ordering = subtle bugs under load</li>
</ol>
</article><div class="my-10 rounded-xl border border-yellow-200 bg-yellow-50 p-6"><div class="flex items-center gap-2 mb-1"><span class="text-lg">üìö</span><h3 class="text-base font-bold text-gray-900">Recommended Resources</h3></div><div class="space-y-4"><div class="flex items-start gap-3 bg-white rounded-lg p-4 border border-yellow-100"><div class="flex-1 min-w-0"><div class="flex items-center gap-2 flex-wrap mb-1"><span class="font-semibold text-gray-900 text-sm">Designing Data-Intensive Applications</span><span class="text-xs bg-blue-100 text-blue-700 px-2 py-0.5 rounded-full font-medium">Best Seller</span></div><p class="text-xs text-gray-600">The definitive guide to building scalable, reliable distributed systems by Martin Kleppmann.</p></div><a href="https://amzn.to/3RyKzOA" target="_blank" rel="noopener noreferrer" class="flex-shrink-0 text-xs bg-blue-600 text-white px-3 py-2 rounded-lg hover:bg-blue-700 transition-colors font-medium whitespace-nowrap">View on Amazon<!-- --> ‚Üí</a></div><div class="flex items-start gap-3 bg-white rounded-lg p-4 border border-yellow-100"><div class="flex-1 min-w-0"><div class="flex items-center gap-2 flex-wrap mb-1"><span class="font-semibold text-gray-900 text-sm">Kafka: The Definitive Guide</span><span class="text-xs bg-blue-100 text-blue-700 px-2 py-0.5 rounded-full font-medium">Editor&#x27;s Pick</span></div><p class="text-xs text-gray-600">Real-time data and stream processing by Confluent engineers.</p></div><a href="https://amzn.to/3TpGKsI" target="_blank" rel="noopener noreferrer" class="flex-shrink-0 text-xs bg-blue-600 text-white px-3 py-2 rounded-lg hover:bg-blue-700 transition-colors font-medium whitespace-nowrap">View on Amazon<!-- --> ‚Üí</a></div><div class="flex items-start gap-3 bg-white rounded-lg p-4 border border-yellow-100"><div class="flex-1 min-w-0"><div class="flex items-center gap-2 flex-wrap mb-1"><span class="font-semibold text-gray-900 text-sm">Apache Kafka Series on Udemy</span></div><p class="text-xs text-gray-600">Hands-on Kafka course covering producers, consumers, Kafka Streams, and Connect.</p></div><a href="https://www.udemy.com/course/apache-kafka/" target="_blank" rel="noopener noreferrer" class="flex-shrink-0 text-xs bg-blue-600 text-white px-3 py-2 rounded-lg hover:bg-blue-700 transition-colors font-medium whitespace-nowrap">View Course<!-- --> ‚Üí</a></div></div></div><div class="mt-10 pt-8 border-t border-gray-100"><p class="text-sm text-gray-500 mb-3">Found this useful? Share it:</p><div class="flex gap-3"><a href="https://twitter.com/intent/tweet?text=Kafka%20Internals%20Deep%20Dive%3A%20Partitions%2C%20Offsets%2C%20and%20Consumer%20Groups&amp;url=https%3A%2F%2Fcodesprintpro.com%2Fblog%2Fkafka-internals-deep-dive%2F" target="_blank" rel="noopener noreferrer" class="text-xs bg-gray-900 text-white px-4 py-2 rounded-lg hover:bg-gray-700 transition-colors">Share on X/Twitter</a><a href="https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fcodesprintpro.com%2Fblog%2Fkafka-internals-deep-dive%2F" target="_blank" rel="noopener noreferrer" class="text-xs bg-blue-600 text-white px-4 py-2 rounded-lg hover:bg-blue-700 transition-colors">Share on LinkedIn</a></div></div></div><aside class="hidden lg:block w-64 flex-shrink-0"><nav class="hidden lg:block sticky top-24"><h4 class="text-xs font-semibold uppercase tracking-widest text-gray-400 mb-3">On This Page</h4><ul class="space-y-1"><li class=""><a href="#why-kafka-is-not-a-message-queue" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Why Kafka Is Not a Message Queue</a></li><li class=""><a href="#partition-anatomy" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Partition Anatomy</a></li><li class="ml-4"><a href="#partition-key-selection" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 text-xs">Partition Key Selection</a></li><li class=""><a href="#the-in-sync-replica-isr-set" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">The In-Sync Replica (ISR) Set</a></li><li class=""><a href="#producer-configuration-durability-vs-throughput" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Producer Configuration: Durability vs Throughput</a></li><li class=""><a href="#offsets-and-consumer-position" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Offsets and Consumer Position</a></li><li class="ml-4"><a href="#auto-commit-vs-manual-commit" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 text-xs">Auto-Commit vs Manual Commit</a></li><li class=""><a href="#consumer-groups-horizontal-scaling" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Consumer Groups: Horizontal Scaling</a></li><li class=""><a href="#exactly-once-semantics" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Exactly-Once Semantics</a></li><li class=""><a href="#monitoring-consumer-lag" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Monitoring Consumer Lag</a></li><li class=""><a href="#key-takeaways-for-production" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Key Takeaways for Production</a></li></ul></nav></aside></div><div class="mt-16 pt-10 border-t border-gray-100"><h2 class="text-2xl font-bold text-gray-900 mb-6">Related Articles</h2><div class="grid grid-cols-1 md:grid-cols-3 gap-6"><a href="/blog/kafka-exactly-once-semantics/"><article class="group bg-white rounded-xl border border-gray-200 p-6 h-full cursor-pointer hover:border-blue-300 hover:shadow-lg transition-all"><span class="inline-block text-xs font-semibold px-3 py-1 rounded-full mb-3 bg-red-100 text-red-700">Messaging</span><h3 class="text-lg font-bold text-gray-900 mb-2 group-hover:text-blue-600 transition-colors leading-snug">Kafka Exactly-Once Semantics: Myth vs Production Reality</h3><p class="text-gray-600 text-sm mb-4 line-clamp-3">Kafka 0.11 introduced exactly-once semantics (EOS), and every architecture diagram since then has confidently placed a checkbox next to &quot;exactly once delivery.&quot; In practice, most teams deploying Kafka with EOS still see ‚Ä¶</p><div class="flex items-center justify-between text-xs text-gray-400"><span>Apr 20, 2025</span><span class="flex items-center gap-1"><svg class="w-3 h-3" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>9 min read</span></div><div class="mt-3 flex flex-wrap gap-1"><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->kafka</span><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->exactly-once</span><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->spring kafka</span></div></article></a><a href="/blog/sqs-kafka-eventbridge-aws-comparison/"><article class="group bg-white rounded-xl border border-gray-200 p-6 h-full cursor-pointer hover:border-blue-300 hover:shadow-lg transition-all"><span class="inline-block text-xs font-semibold px-3 py-1 rounded-full mb-3 bg-red-100 text-red-700">Messaging</span><h3 class="text-lg font-bold text-gray-900 mb-2 group-hover:text-blue-600 transition-colors leading-snug">SQS vs Kafka vs EventBridge: Choosing the Right Messaging System on AWS</h3><p class="text-gray-600 text-sm mb-4 line-clamp-3">Every AWS backend team eventually faces the same decision: you need asynchronous messaging. SQS is right there in the console. Your architect says you need Kafka. Someone from DevOps mentions EventBridge. Each option has‚Ä¶</p><div class="flex items-center justify-between text-xs text-gray-400"><span>Apr 2, 2025</span><span class="flex items-center gap-1"><svg class="w-3 h-3" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>10 min read</span></div><div class="mt-3 flex flex-wrap gap-1"><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->aws</span><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->sqs</span><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->kafka</span></div></article></a></div></div><div class="mt-12 text-center"><a class="inline-flex items-center gap-2 text-blue-600 hover:text-blue-700 font-medium transition-colors" href="/blog/">‚Üê Back to all articles</a></div></div></div><footer class="bg-gray-900 text-white py-12"><div class="container mx-auto px-4 sm:px-6 lg:px-8"><div class="grid grid-cols-1 md:grid-cols-4 gap-8 mb-8"><div class="col-span-1 md:col-span-1"><div><a class="text-xl font-bold block mb-3 text-white hover:text-blue-400 transition-colors" href="/">CodeSprintPro</a></div><p class="text-gray-400 text-sm mb-4 leading-relaxed">Deep-dive technical content on System Design, Java, Databases, AI/ML, and AWS ‚Äî by Sachin Sarawgi.</p><div class="flex space-x-4"><a href="https://github.com/codesprintpro" target="_blank" rel="noopener noreferrer" class="text-gray-400 hover:text-white transition-colors" aria-label="Visit GitHub profile"><i class="fab fa-github text-xl"></i></a><a href="https://www.linkedin.com/in/sachin-sarawgi/" target="_blank" rel="noopener noreferrer" class="text-gray-400 hover:text-white transition-colors" aria-label="Visit LinkedIn profile"><i class="fab fa-linkedin text-xl"></i></a><a href="https://medium.com/@codesprintpro" target="_blank" rel="noopener noreferrer" class="text-gray-400 hover:text-white transition-colors" aria-label="Visit Medium profile"><i class="fab fa-medium text-xl"></i></a></div></div><div><h3 class="text-sm font-semibold uppercase tracking-widest text-gray-400 mb-4">Quick Links</h3><ul class="space-y-2"><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">Blog</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/#about">About</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/#portfolio">Portfolio</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/#contact">Contact</a></div></li></ul></div><div><h3 class="text-sm font-semibold uppercase tracking-widest text-gray-400 mb-4">Categories</h3><ul class="space-y-2"><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">System Design</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">Java</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">Databases</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">AI/ML</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">AWS</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">Messaging</a></div></li></ul></div><div><h3 class="text-sm font-semibold uppercase tracking-widest text-gray-400 mb-4">Contact</h3><ul class="space-y-2 text-gray-400 text-sm"><li><a href="mailto:sachinsarawgi201143@gmail.com" class="hover:text-white transition-colors flex items-center gap-2"><i class="fas fa-envelope"></i> Email</a></li><li><a href="https://www.linkedin.com/in/sachin-sarawgi/" target="_blank" rel="noopener noreferrer" class="hover:text-white transition-colors flex items-center gap-2"><i class="fab fa-linkedin"></i> LinkedIn</a></li><li><a href="https://github.com/codesprintpro" target="_blank" rel="noopener noreferrer" class="hover:text-white transition-colors flex items-center gap-2"><i class="fab fa-github"></i> GitHub</a></li></ul></div></div><div class="border-t border-gray-800 pt-6 flex flex-col md:flex-row justify-between items-center gap-2"><p class="text-gray-500 text-sm">¬© <!-- -->2026<!-- --> CodeSprintPro ¬∑ Sachin Sarawgi. All rights reserved.</p><p class="text-gray-600 text-xs">Built with Next.js ¬∑ TailwindCSS ¬∑ Deployed on GitHub Pages</p></div></div></footer></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"Kafka Internals Deep Dive: Partitions, Offsets, and Consumer Groups","description":"Understand how Apache Kafka achieves high throughput through log-based storage, how offsets enable reliable consumption, and how consumer groups scale processing horizontally.","date":"2025-01-15","category":"Messaging","tags":["kafka","distributed systems","streaming","java"],"featured":true,"affiliateSection":"distributed-systems-books","slug":"kafka-internals-deep-dive","readingTime":"10 min read","excerpt":"Apache Kafka is the de facto standard for event streaming in distributed systems, but most developers treat it as a black box ‚Äî a durable message queue with a fancy name. Understanding Kafka's internals unlocks its true ‚Ä¶","contentHtml":"\u003cp\u003eApache Kafka is the de facto standard for event streaming in distributed systems, but most developers treat it as a black box ‚Äî a durable message queue with a fancy name. Understanding Kafka's internals unlocks its true potential: predictable performance at scale, reliable exactly-once processing, and horizontal scalability without coordination overhead.\u003c/p\u003e\n\u003cp\u003eThis article goes deep on partitions, offsets, consumer groups, and replication ‚Äî with production-grade Java examples.\u003c/p\u003e\n\u003ch2\u003eWhy Kafka Is Not a Message Queue\u003c/h2\u003e\n\u003cp\u003eTraditional message queues like RabbitMQ deliver messages to consumers and delete them after acknowledgment. Kafka's fundamental design is different: \u003cstrong\u003eit is a distributed, partitioned, replicated commit log\u003c/strong\u003e.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eTraditional Queue:                  Kafka Log:\n\nProducer ‚Üí [Queue] ‚Üí Consumer       Producer ‚Üí [Partition Log]\n           (deleted after ACK)                  offset 0: event\n                                                offset 1: event\n                                                offset 2: event  ‚Üê Consumer A reads here\n                                                offset 3: event  ‚Üê Consumer B reads here\n                                                (retained for configurable time)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis distinction matters enormously. With Kafka:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eMultiple consumer groups\u003c/strong\u003e can independently read the same data at their own pace\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eReprocessing\u003c/strong\u003e is trivial ‚Äî reset the offset and replay\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eTime travel\u003c/strong\u003e is possible ‚Äî query data from any point in history\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eThroughput is predictable\u003c/strong\u003e ‚Äî sequential disk writes are fast and consistent\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003ePartition Anatomy\u003c/h2\u003e\n\u003cp\u003eEvery Kafka topic is divided into one or more \u003cstrong\u003epartitions\u003c/strong\u003e. A partition is an ordered, immutable sequence of records ‚Äî a physical append-only log file on disk.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eTopic: \"order-events\" (4 partitions, replication factor 3)\n\nPartition 0: [ev0][ev1][ev2][ev3][ev4]...  ‚Üí Leader: Broker 1\n             Replicas: Broker 2, Broker 3\n\nPartition 1: [ev0][ev1][ev2]...            ‚Üí Leader: Broker 2\n             Replicas: Broker 1, Broker 3\n\nPartition 2: [ev0][ev1][ev2][ev3]...       ‚Üí Leader: Broker 3\n             Replicas: Broker 1, Broker 2\n\nPartition 3: [ev0][ev1]...                 ‚Üí Leader: Broker 1\n             Replicas: Broker 2, Broker 3\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eKey properties:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eOrdering is guaranteed within a partition\u003c/strong\u003e, not across partitions\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eParallelism scales with partition count\u003c/strong\u003e ‚Äî more partitions = more consumers\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eMessages are routed to partitions by key\u003c/strong\u003e (default: round-robin if no key)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003ePartition Key Selection\u003c/h3\u003e\n\u003cp\u003eYour partition key determines which events land in the same partition. Events in the same partition are guaranteed to be processed in order.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003e// All events for the same orderId go to the same partition\n// This ensures order-placed, order-paid, order-shipped are processed in sequence\nProducerRecord\u0026#x3C;String, OrderEvent\u003e record = new ProducerRecord\u0026#x3C;\u003e(\n    \"order-events\",\n    orderId,         // partition key ‚Äî hash(orderId) % numPartitions\n    orderEvent\n);\nproducer.send(record);\n\n// Bad key choice: random UUID or timestamp ‚Äî destroys ordering\n// Good key choices: userId, orderId, deviceId, sessionId\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eThe In-Sync Replica (ISR) Set\u003c/h2\u003e\n\u003cp\u003eKafka uses \u003cstrong\u003eleader-based replication\u003c/strong\u003e. Each partition has one leader and N-1 followers (replicas). All reads and writes go through the leader.\u003c/p\u003e\n\u003cp\u003eThe \u003cstrong\u003eIn-Sync Replica (ISR)\u003c/strong\u003e set is the subset of replicas that are fully caught up with the leader. A replica falls out of ISR if it lags more than \u003ccode\u003ereplica.lag.time.max.ms\u003c/code\u003e (default: 30 seconds).\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ePartition Leader (Broker 1): offset 150\n  ISR = {Broker 1, Broker 2, Broker 3}  ‚Üê All caught up\n\nScenario: Broker 3 network hiccup, lags by 45 seconds\n  ISR = {Broker 1, Broker 2}             ‚Üê Broker 3 removed from ISR\n\nScenario: Broker 1 crashes\n  New leader elected from ISR: Broker 2\n  ISR = {Broker 2}                        ‚Üê Only Broker 2 was in-sync\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eProducer Configuration: Durability vs Throughput\u003c/h2\u003e\n\u003cp\u003eThe \u003ccode\u003eacks\u003c/code\u003e setting controls when the producer considers a write successful:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003eProperties producerProps = new Properties();\nproducerProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"broker1:9092,broker2:9092\");\nproducerProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());\nproducerProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, JsonSerializer.class.getName());\n\n// acks=0: Fire and forget ‚Äî fastest, data loss possible\n// acks=1: Leader ACK ‚Äî default, leader crash before replication = data loss\n// acks=all (or -1): All ISR ACK ‚Äî safest, use for critical data\nproducerProps.put(ProducerConfig.ACKS_CONFIG, \"all\");\n\n// Prevent duplicate messages on retry\nproducerProps.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, true);\n\n// Max in-flight requests per connection (must be 1 for ordering with retries, unless idempotent)\nproducerProps.put(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION, 5); // safe with idempotence\n\n// Batching: wait up to 20ms for batch to fill before sending\nproducerProps.put(ProducerConfig.LINGER_MS_CONFIG, 20);\nproducerProps.put(ProducerConfig.BATCH_SIZE_CONFIG, 65536); // 64KB batch\n\n// Compression reduces network IO by 5-7x for JSON\nproducerProps.put(ProducerConfig.COMPRESSION_TYPE_CONFIG, \"lz4\");\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eThroughput numbers\u003c/strong\u003e (rough benchmarks on commodity hardware):\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eacks=0\u003c/code\u003e: ~1M records/sec\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eacks=1\u003c/code\u003e: ~500K records/sec\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eacks=all\u003c/code\u003e + \u003ccode\u003emin.insync.replicas=2\u003c/code\u003e: ~200K records/sec\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe tradeoff is explicit: more durability = lower throughput.\u003c/p\u003e\n\u003ch2\u003eOffsets and Consumer Position\u003c/h2\u003e\n\u003cp\u003eEvery record in a partition has an \u003cstrong\u003eoffset\u003c/strong\u003e ‚Äî a monotonically increasing integer starting at 0. Offsets are Kafka's way of tracking consumer position.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003eProperties consumerProps = new Properties();\nconsumerProps.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, \"broker1:9092\");\nconsumerProps.put(ConsumerConfig.GROUP_ID_CONFIG, \"order-processor-v1\");\nconsumerProps.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\nconsumerProps.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, JsonDeserializer.class.getName());\n\n// auto.offset.reset: what to do when no committed offset exists\n// \"earliest\": read from beginning (replay all history)\n// \"latest\": read only new messages (default)\nconsumerProps.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n\n// Disable auto-commit: commit manually after processing\nconsumerProps.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);\n\nKafkaConsumer\u0026#x3C;String, OrderEvent\u003e consumer = new KafkaConsumer\u0026#x3C;\u003e(consumerProps);\nconsumer.subscribe(List.of(\"order-events\"));\n\ntry {\n    while (true) {\n        ConsumerRecords\u0026#x3C;String, OrderEvent\u003e records = consumer.poll(Duration.ofMillis(100));\n\n        for (ConsumerRecord\u0026#x3C;String, OrderEvent\u003e record : records) {\n            try {\n                processOrder(record.value());\n                // Only commit AFTER successful processing\n                // This prevents losing events on consumer crash\n            } catch (Exception e) {\n                // Dead-letter queue or retry logic here\n                log.error(\"Failed to process {}, offset {}\", record.key(), record.offset(), e);\n            }\n        }\n\n        // Synchronous commit: blocks until broker confirms\n        // Use commitAsync() for higher throughput if at-least-once is acceptable\n        consumer.commitSync();\n    }\n} finally {\n    consumer.close();\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eAuto-Commit vs Manual Commit\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e\u003c/th\u003e\n\u003cth\u003eAuto-Commit\u003c/th\u003e\n\u003cth\u003eManual Commit\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eConfig\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003eenable.auto.commit=true\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003eenable.auto.commit=false\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eCommits every\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003eauto.commit.interval.ms\u003c/code\u003e (5s default)\u003c/td\u003e\n\u003ctd\u003eAfter you call \u003ccode\u003ecommitSync()\u003c/code\u003e/\u003ccode\u003ecommitAsync()\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eRisk\u003c/td\u003e\n\u003ctd\u003eCommits before processing = message loss\u003c/td\u003e\n\u003ctd\u003eYour responsibility\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eUse case\u003c/td\u003e\n\u003ctd\u003eLow-stakes analytics\u003c/td\u003e\n\u003ctd\u003eFinancial transactions, critical processing\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2\u003eConsumer Groups: Horizontal Scaling\u003c/h2\u003e\n\u003cp\u003eA \u003cstrong\u003econsumer group\u003c/strong\u003e is a set of consumers that share the work of consuming a topic. Kafka assigns each partition to exactly one consumer in the group.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eTopic: \"order-events\" with 6 partitions\n\nConsumer Group: \"order-processor\" (3 consumers)\n  Consumer 1 ‚Üí Partition 0, Partition 1\n  Consumer 2 ‚Üí Partition 2, Partition 3\n  Consumer 3 ‚Üí Partition 4, Partition 5\n\nIf Consumer 2 crashes:\n  Consumer 1 ‚Üí Partition 0, Partition 1, Partition 2\n  Consumer 3 ‚Üí Partition 3, Partition 4, Partition 5\n  (Kafka triggers rebalance within session.timeout.ms)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eScaling rules:\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eMore consumers than partitions = some consumers are idle (wasted resources)\u003c/li\u003e\n\u003cli\u003eMore partitions than consumers = each consumer handles multiple partitions\u003c/li\u003e\n\u003cli\u003eMax parallelism = partition count\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe implication of the last rule is important: if you have 4 partitions and deploy 8 consumer instances, 4 of them will sit idle doing nothing. Kafka assigns one consumer per partition within a group ‚Äî it doesn't split a single partition across consumers. This is why you should provision partitions generously at topic creation time. Kafka does not allow reducing partition count, and increasing it later can change the key-to-partition mapping, breaking ordering guarantees for existing keys.\u003c/p\u003e\n\u003cp\u003eScaling out is simple: start another consumer instance with the same \u003ccode\u003egroup.id\u003c/code\u003e. Kafka automatically triggers a rebalance and redistributes partitions across all active consumers. You can go from 3 to 6 consumers handling a 6-partition topic with zero configuration changes.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003e// Scale by starting more consumer instances with the same group.id\n// Each instance handles different partitions automatically ‚Äî no config changes needed\n\n// To check current partition assignments and consumer lag:\n// bin/kafka-consumer-groups.sh --bootstrap-server broker1:9092 \\\n//   --describe --group order-processor\n//\n// Output shows:\n//   GROUP            TOPIC         PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG\n//   order-processor  order-events  0          1024            1050            26   ‚Üê 26 unprocessed\n//   order-processor  order-events  1          876             876             0    ‚Üê fully caught up\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eA lag of 26 on partition 0 means the consumer is 26 messages behind the producer. A lag of 0 means the consumer is keeping up in real time. Growing lag is the first sign that you need more consumers or faster processing logic.\u003c/p\u003e\n\u003ch2\u003eExactly-Once Semantics\u003c/h2\u003e\n\u003cp\u003eKafka 0.11+ supports exactly-once processing through idempotent producers and transactions.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003eproducerProps.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, true);\nproducerProps.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, \"order-processor-1\"); // unique per producer\n\nKafkaProducer\u0026#x3C;String, String\u003e producer = new KafkaProducer\u0026#x3C;\u003e(producerProps);\nproducer.initTransactions();\n\nKafkaConsumer\u0026#x3C;String, OrderEvent\u003e consumer = // ... configured as above\n\ntry {\n    ConsumerRecords\u0026#x3C;String, OrderEvent\u003e records = consumer.poll(Duration.ofMillis(100));\n\n    producer.beginTransaction();\n    try {\n        for (ConsumerRecord\u0026#x3C;String, OrderEvent\u003e record : records) {\n            OrderResult result = processOrder(record.value());\n\n            // Produce result to output topic\n            producer.send(new ProducerRecord\u0026#x3C;\u003e(\"order-results\", record.key(), result.toJson()));\n        }\n\n        // Atomically commit offsets and produce ‚Äî either both happen or neither\n        Map\u0026#x3C;TopicPartition, OffsetAndMetadata\u003e offsets = new HashMap\u0026#x3C;\u003e();\n        records.partitions().forEach(tp -\u003e {\n            long lastOffset = records.records(tp).get(records.records(tp).size() - 1).offset();\n            offsets.put(tp, new OffsetAndMetadata(lastOffset + 1));\n        });\n\n        producer.sendOffsetsToTransaction(offsets, consumer.groupMetadata());\n        producer.commitTransaction();\n\n    } catch (Exception e) {\n        producer.abortTransaction();\n        throw e;\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eMonitoring Consumer Lag\u003c/h2\u003e\n\u003cp\u003eConsumer lag is the most critical Kafka operational metric. \u003cstrong\u003eLag = leader offset ‚àí consumer committed offset.\u003c/strong\u003e It tells you how far behind the consumer is from the latest data the producer has written.\u003c/p\u003e\n\u003cp\u003eA lag of zero means the consumer is processing events in real time. A lag of 10,000 means there are 10,000 unprocessed events sitting in the partition waiting to be consumed. If that number is growing, your consumers cannot keep up with the incoming load. If it's stable, consumers are processing as fast as events arrive. If it's shrinking, consumers are catching up after a backlog.\u003c/p\u003e\n\u003cp\u003eWhy does lag grow? The two most common reasons are: (1) processing logic got slower ‚Äî perhaps a downstream database query that used to take 5ms now takes 500ms; or (2) producer throughput increased ‚Äî a marketing email triggered a spike in user activity that doubled event volume. Monitoring lag gives you early warning before either of these causes a user-visible delay.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003e// Programmatic lag check ‚Äî useful for building custom alerting\nAdminClient adminClient = AdminClient.create(Map.of(\n    AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, \"broker1:9092\"\n));\n\nMap\u0026#x3C;TopicPartition, OffsetAndMetadata\u003e committed = adminClient\n    .listConsumerGroupOffsets(\"order-processor\")\n    .partitionsToOffsetAndMetadata()\n    .get();\n\nMap\u0026#x3C;TopicPartition, Long\u003e endOffsets = consumer.endOffsets(committed.keySet());\n\nlong totalLag = 0;\nfor (Map.Entry\u0026#x3C;TopicPartition, Long\u003e entry : endOffsets.entrySet()) {\n    OffsetAndMetadata committedOffset = committed.get(entry.getKey());\n    long lag = entry.getValue() - (committedOffset != null ? committedOffset.offset() : 0);\n    totalLag += lag;\n    log.info(\"Partition {}: lag = {}\", entry.getKey(), lag);\n}\n\n// Alert threshold: if totalLag \u003e maxAcceptableLag, trigger scale-out or alert\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eSet your alert threshold based on your latency SLA. If your system must process events within 30 seconds, and your consumers handle 100 events per second per instance, a lag of 3,000 means you're 30 seconds from breaching the SLA. Alert at half that ‚Äî 1,500 ‚Äî to give yourself time to add consumers before users notice.\u003c/p\u003e\n\u003cp\u003eFor most teams, exposing \u003ccode\u003ekafka_consumer_records_lag_max\u003c/code\u003e via Micrometer to Prometheus and alerting in Grafana is the right setup. The programmatic approach above is useful for building auto-scaling logic ‚Äî dynamically adding consumer instances when lag exceeds a threshold and removing them when it returns to baseline.\u003c/p\u003e\n\u003cp\u003eProduction Kafka is not complicated ‚Äî it becomes complicated when teams skip understanding these fundamentals. The partition model, offset management, and ISR mechanics explain almost every production incident involving Kafka. Build these mental models first, then instrument them.\u003c/p\u003e\n\u003ch2\u003eKey Takeaways for Production\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003ePartition count is permanent\u003c/strong\u003e ‚Äî choose based on your parallelism needs, not current load (6-12 partitions is usually sufficient to start)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e\u003ccode\u003eacks=all\u003c/code\u003e + \u003ccode\u003emin.insync.replicas=2\u003c/code\u003e\u003c/strong\u003e for any data you cannot afford to lose\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eManual offset commit\u003c/strong\u003e for business-critical processing; auto-commit for analytics\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eConsumer lag\u003c/strong\u003e is your early warning system ‚Äî monitor it obsessively\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eIdempotent producers\u003c/strong\u003e are free (negligible overhead) ‚Äî always enable them\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eKeys matter\u003c/strong\u003e ‚Äî wrong key = wrong ordering = subtle bugs under load\u003c/li\u003e\n\u003c/ol\u003e\n","tableOfContents":[{"id":"why-kafka-is-not-a-message-queue","text":"Why Kafka Is Not a Message Queue","level":2},{"id":"partition-anatomy","text":"Partition Anatomy","level":2},{"id":"partition-key-selection","text":"Partition Key Selection","level":3},{"id":"the-in-sync-replica-isr-set","text":"The In-Sync Replica (ISR) Set","level":2},{"id":"producer-configuration-durability-vs-throughput","text":"Producer Configuration: Durability vs Throughput","level":2},{"id":"offsets-and-consumer-position","text":"Offsets and Consumer Position","level":2},{"id":"auto-commit-vs-manual-commit","text":"Auto-Commit vs Manual Commit","level":3},{"id":"consumer-groups-horizontal-scaling","text":"Consumer Groups: Horizontal Scaling","level":2},{"id":"exactly-once-semantics","text":"Exactly-Once Semantics","level":2},{"id":"monitoring-consumer-lag","text":"Monitoring Consumer Lag","level":2},{"id":"key-takeaways-for-production","text":"Key Takeaways for Production","level":2}]},"relatedPosts":[{"title":"Kafka Exactly-Once Semantics: Myth vs Production Reality","description":"What Kafka's exactly-once guarantee actually covers, where duplicates still happen in practice, and how to design genuinely idempotent consumers with Spring Kafka. Real production mistakes and their fixes.","date":"2025-04-20","category":"Messaging","tags":["kafka","exactly-once","spring kafka","distributed systems","transactions","java"],"featured":false,"affiliateSection":"distributed-systems-books","slug":"kafka-exactly-once-semantics","readingTime":"9 min read","excerpt":"Kafka 0.11 introduced exactly-once semantics (EOS), and every architecture diagram since then has confidently placed a checkbox next to \"exactly once delivery.\" In practice, most teams deploying Kafka with EOS still see ‚Ä¶"},{"title":"SQS vs Kafka vs EventBridge: Choosing the Right Messaging System on AWS","description":"A senior engineer's guide to selecting between Amazon SQS, Apache Kafka on AWS, and EventBridge. Throughput benchmarks, cost breakdowns, ordering guarantees, and real production trade-offs.","date":"2025-04-02","category":"Messaging","tags":["aws","sqs","kafka","eventbridge","distributed systems","messaging","msk"],"featured":false,"affiliateSection":"aws-resources","slug":"sqs-kafka-eventbridge-aws-comparison","readingTime":"10 min read","excerpt":"Every AWS backend team eventually faces the same decision: you need asynchronous messaging. SQS is right there in the console. Your architect says you need Kafka. Someone from DevOps mentions EventBridge. Each option has‚Ä¶"}]},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"kafka-internals-deep-dive"},"buildId":"rpFn_jslWZ9qPkJwor7RD","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>