<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8" data-next-head=""/><meta name="viewport" content="width=device-width" data-next-head=""/><title data-next-head="">Microservices Patterns: Circuit Breaker, Retry, Bulkhead, and Saga<!-- --> | CodeSprintPro</title><meta name="description" content="Master the resilience patterns that keep microservices systems running when individual services fail. Covers circuit breaker, retry with backoff, bulkhead isolation, and distributed transactions with Saga." data-next-head=""/><meta name="author" content="Sachin Sarawgi" data-next-head=""/><link rel="canonical" href="https://codesprintpro.com/blog/microservices-patterns/" data-next-head=""/><meta property="og:type" content="article" data-next-head=""/><meta property="og:title" content="Microservices Patterns: Circuit Breaker, Retry, Bulkhead, and Saga" data-next-head=""/><meta property="og:description" content="Master the resilience patterns that keep microservices systems running when individual services fail. Covers circuit breaker, retry with backoff, bulkhead isolation, and distributed transactions with Saga." data-next-head=""/><meta property="og:url" content="https://codesprintpro.com/blog/microservices-patterns/" data-next-head=""/><meta property="og:image" content="https://codesprintpro.com/images/og-default.jpg" data-next-head=""/><meta property="og:site_name" content="CodeSprintPro" data-next-head=""/><meta property="article:published_time" content="2025-02-28" data-next-head=""/><meta property="article:author" content="Sachin Sarawgi" data-next-head=""/><meta property="article:section" content="System Design" data-next-head=""/><meta property="article:tag" content="microservices" data-next-head=""/><meta property="article:tag" content="resilience" data-next-head=""/><meta property="article:tag" content="circuit breaker" data-next-head=""/><meta property="article:tag" content="saga" data-next-head=""/><meta property="article:tag" content="distributed systems" data-next-head=""/><meta property="article:tag" content="spring boot" data-next-head=""/><meta name="twitter:card" content="summary_large_image" data-next-head=""/><meta name="twitter:title" content="Microservices Patterns: Circuit Breaker, Retry, Bulkhead, and Saga" data-next-head=""/><meta name="twitter:description" content="Master the resilience patterns that keep microservices systems running when individual services fail. Covers circuit breaker, retry with backoff, bulkhead isolation, and distributed transactions with Saga." data-next-head=""/><meta name="twitter:image" content="https://codesprintpro.com/images/og-default.jpg" data-next-head=""/><script type="application/ld+json" data-next-head="">{"@context":"https://schema.org","@type":"BlogPosting","headline":"Microservices Patterns: Circuit Breaker, Retry, Bulkhead, and Saga","description":"Master the resilience patterns that keep microservices systems running when individual services fail. Covers circuit breaker, retry with backoff, bulkhead isolation, and distributed transactions with Saga.","image":"https://codesprintpro.com/images/og-default.jpg","datePublished":"2025-02-28","dateModified":"2025-02-28","author":{"@type":"Person","name":"Sachin Sarawgi","url":"https://codesprintpro.com","sameAs":["https://www.linkedin.com/in/sachin-sarawgi/","https://github.com/codesprintpro","https://medium.com/@codesprintpro"]},"publisher":{"@type":"Organization","name":"CodeSprintPro","url":"https://codesprintpro.com","logo":{"@type":"ImageObject","url":"https://codesprintpro.com/favicon/favicon-96x96.png"}},"mainEntityOfPage":{"@type":"WebPage","@id":"https://codesprintpro.com/blog/microservices-patterns/"},"keywords":"microservices, resilience, circuit breaker, saga, distributed systems, spring boot","articleSection":"System Design"}</script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" integrity="sha512-9usAa10IRO0HhonpyAIVpjrylPvoDwiPUiKdWk5t3PyolY1cOd4DSE0Ga+ri4AuTroPR5aQvXU9xC6qOPnzFeg==" crossorigin="anonymous" referrerPolicy="no-referrer"/><script async="" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-XXXXXXXXXXXXXXXX" crossorigin="anonymous"></script><link rel="preload" href="/_next/static/media/e4af272ccee01ff0-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/css/735d4373f93910ca.css" as="style"/><link rel="stylesheet" href="/_next/static/css/735d4373f93910ca.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-11a4a2dad04962bb.js" defer=""></script><script src="/_next/static/chunks/framework-1ce91eb6f9ecda85.js" defer=""></script><script src="/_next/static/chunks/main-c7f4109f032d7b6e.js" defer=""></script><script src="/_next/static/chunks/pages/_app-1a852bd9e38c70ab.js" defer=""></script><script src="/_next/static/chunks/730-db7827467817f501.js" defer=""></script><script src="/_next/static/chunks/90-1cd4611704c3dbe0.js" defer=""></script><script src="/_next/static/chunks/440-29f4b99a44e744b5.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-0c1b14a33d5e05ee.js" defer=""></script><script src="/_next/static/rpFn_jslWZ9qPkJwor7RD/_buildManifest.js" defer=""></script><script src="/_next/static/rpFn_jslWZ9qPkJwor7RD/_ssgManifest.js" defer=""></script></head><body><div id="__next"><main class="__className_f367f3"><div class="min-h-screen bg-white"><nav class="fixed w-full z-50 transition-all duration-300 bg-white shadow-md" style="transform:translateY(-100px) translateZ(0)"><div class="container mx-auto px-4 sm:px-6 lg:px-8"><div class="flex items-center justify-between h-16"><a class="text-xl font-bold transition-colors text-blue-600" href="/">CodeSprintPro</a><div class="hidden md:flex items-center space-x-8"><a class="text-sm font-medium transition-colors text-blue-600" href="/blog/">Blog</a><a class="text-sm font-medium transition-colors text-gray-600 hover:text-blue-600" href="/#about">About</a><a class="text-sm font-medium transition-colors text-gray-600 hover:text-blue-600" href="/#portfolio">Portfolio</a><a class="text-sm font-medium transition-colors text-gray-600 hover:text-blue-600" href="/#contact">Contact</a></div><button class="md:hidden p-2 rounded-lg transition-colors hover:bg-gray-100 text-gray-600" aria-label="Toggle mobile menu"><svg class="w-6 h-6" fill="none" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" stroke="currentColor"><path d="M4 6h16M4 12h16M4 18h16"></path></svg></button></div></div></nav><div class="pt-20"><div class="bg-gradient-to-br from-gray-900 to-blue-950 py-16"><div class="container mx-auto px-4 sm:px-6 lg:px-8 max-w-5xl"><nav class="flex items-center gap-2 text-sm text-gray-400 mb-6"><a class="hover:text-white transition-colors" href="/">Home</a><span>/</span><a class="hover:text-white transition-colors" href="/blog/">Blog</a><span>/</span><span class="text-gray-300 truncate max-w-xs">Microservices Patterns: Circuit Breaker, Retry, Bulkhead, and Saga</span></nav><span class="inline-block text-xs font-semibold px-3 py-1 rounded-full bg-blue-100 text-blue-700 mb-4">System Design</span><h1 class="text-3xl md:text-5xl font-bold text-white mb-4 leading-tight">Microservices Patterns: Circuit Breaker, Retry, Bulkhead, and Saga</h1><p class="text-gray-300 text-lg mb-6 max-w-3xl">Master the resilience patterns that keep microservices systems running when individual services fail. Covers circuit breaker, retry with backoff, bulkhead isolation, and distributed transactions with Saga.</p><div class="flex flex-wrap items-center gap-4 text-gray-400 text-sm"><span class="flex items-center gap-1.5"><svg class="w-4 h-4" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M16 7a4 4 0 11-8 0 4 4 0 018 0zM12 14a7 7 0 00-7 7h14a7 7 0 00-7-7z"></path></svg>Sachin Sarawgi</span><span>¬∑</span><span>February 28, 2025</span><span>¬∑</span><span class="flex items-center gap-1"><svg class="w-4 h-4" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>14 min read</span></div><div class="flex flex-wrap gap-2 mt-4"><span class="text-xs text-gray-400 bg-gray-800 px-2 py-1 rounded">#<!-- -->microservices</span><span class="text-xs text-gray-400 bg-gray-800 px-2 py-1 rounded">#<!-- -->resilience</span><span class="text-xs text-gray-400 bg-gray-800 px-2 py-1 rounded">#<!-- -->circuit breaker</span><span class="text-xs text-gray-400 bg-gray-800 px-2 py-1 rounded">#<!-- -->saga</span><span class="text-xs text-gray-400 bg-gray-800 px-2 py-1 rounded">#<!-- -->distributed systems</span><span class="text-xs text-gray-400 bg-gray-800 px-2 py-1 rounded">#<!-- -->spring boot</span></div></div></div><div class="container mx-auto px-4 sm:px-6 lg:px-8 max-w-5xl py-12"><div class="flex gap-12"><div class="flex-1 min-w-0"><article class="prose prose-lg max-w-none prose-headings:text-gray-900 prose-headings:font-bold prose-h2:text-2xl prose-h2:mt-10 prose-h2:mb-4 prose-h3:text-xl prose-h3:mt-8 prose-h3:mb-3 prose-p:text-gray-700 prose-p:leading-relaxed prose-a:text-blue-600 prose-a:no-underline hover:prose-a:underline prose-strong:text-gray-900 prose-blockquote:border-blue-600 prose-blockquote:text-gray-600 prose-code:text-blue-700 prose-code:bg-blue-50 prose-code:px-1.5 prose-code:py-0.5 prose-code:rounded prose-code:text-sm prose-code:before:content-none prose-code:after:content-none prose-pre:rounded-xl prose-img:rounded-xl prose-img:shadow-md prose-table:text-sm prose-th:bg-gray-100 prose-th:text-gray-700"><p>A monolith fails as a unit ‚Äî one process, one crash, everything stops. A microservices system fails differently: some services go down, some slow to a crawl, some remain perfectly healthy. This partial-failure behaviour is actually harder to deal with than total failure, because the system is still <em>partially</em> up and clients keep sending requests into the degraded parts.</p>
<p>Without resilience patterns, one slow service can bring down your entire system in minutes through a mechanism called cascading failure. With the right patterns applied correctly, the system degrades gracefully ‚Äî the slow payment service becomes temporarily unavailable to users, while inventory browsing, cart management, and search continue working normally. This article covers the four patterns that make that possible, with Spring Boot + Resilience4j implementations.</p>
<h2>Why Microservices Fail Differently</h2>
<p>The most dangerous failure mode in distributed systems is not an immediate crash ‚Äî it's a slow response. A service that returns an error immediately frees the calling thread right away. A service that hangs for 10 seconds holds a thread for 10 seconds, and at high load those threads accumulate until the thread pool is exhausted.</p>
<pre><code>Monolith failure: Everything fails at once (simple, but total)

Microservice failure cascade:
  Order Service calls Inventory Service calls Warehouse Service

  Warehouse Service goes slow (200ms ‚Üí 10s response time)
  Inventory Service threads pile up waiting for Warehouse
  Order Service threads pile up waiting for Inventory
  All three services become unresponsive
  ‚Üí Entire system down, from one slow service

This is "cascading failure" ‚Äî the #1 microservices operational problem.
</code></pre>
<p>The patterns below address cascading failure at different levels. The circuit breaker stops calls to a failing service. Retry handles transient blips before they reach the circuit breaker. The bulkhead contains failures to one partition of the system. Saga coordinates the cleanup when a multi-step operation fails partway through.</p>
<h2>Pattern 1: Circuit Breaker</h2>
<p>The circuit breaker is named after the electrical component that trips when a circuit overloads, preventing damage. The software version does the same: when calls to a downstream service start failing at a high rate, the circuit breaker <strong>opens</strong> and immediately returns an error to callers ‚Äî without actually calling the downstream service. This gives the failing service breathing room to recover while protecting the calling service's threads.</p>
<p>The three states are the heart of the pattern:</p>
<pre><code>Circuit states:
  CLOSED: Normal operation ‚Äî calls pass through
  OPEN: Failure threshold exceeded ‚Äî calls fail immediately (fast fail)
  HALF-OPEN: Trial period ‚Äî limited calls allowed to test recovery

State transitions:
  CLOSED ‚Üí OPEN: When failure rate > threshold (e.g., 50% of last 10 calls failed)
  OPEN ‚Üí HALF-OPEN: After wait duration (e.g., 30 seconds)
  HALF-OPEN ‚Üí CLOSED: If trial calls succeed
  HALF-OPEN ‚Üí OPEN: If trial calls fail

Timeline:
  0s:  Normal. All calls succeed.
  30s: Downstream service starts failing.
  35s: Failure rate hits 50% ‚Üí Circuit OPENS.
  35s-65s: All calls fail immediately (fast fail), downstream gets no load.
  65s: Circuit HALF-OPENS, 3 trial calls allowed.
  66s: Trial calls succeed ‚Üí Circuit CLOSES.
  66s+: Normal operation resumes.
</code></pre>
<p>The HALF-OPEN state is subtle but important. Without it, a circuit that opens would never close ‚Äî you'd need manual intervention to restore service. HALF-OPEN is the automatic recovery probe: after the wait duration, the circuit allows a small number of test calls through. If they succeed, normal operation resumes. If they fail, the circuit opens again and waits longer.</p>
<p>The <code>@CircuitBreaker</code> annotation in Resilience4j wires all of this up automatically. The <code>fallbackMethod</code> is the method called when the circuit is open or when all retries are exhausted ‚Äî it's your graceful degradation path.</p>
<pre><code class="language-java">// build.gradle
// implementation 'io.github.resilience4j:resilience4j-spring-boot3:2.2.0'

@Service
public class InventoryService {

    private final CircuitBreakerRegistry circuitBreakerRegistry;
    private final InventoryClient inventoryClient;

    public InventoryService(CircuitBreakerRegistry registry, InventoryClient client) {
        this.circuitBreakerRegistry = registry;
        this.inventoryClient = client;
    }

    @CircuitBreaker(name = "inventory", fallbackMethod = "getInventoryFallback")
    public InventoryResponse checkInventory(String productId) {
        return inventoryClient.check(productId);
    }

    // The fallback runs when: circuit is OPEN, or a call fails (and no retry is configured)
    // Its signature must match the original method plus an Exception parameter
    public InventoryResponse getInventoryFallback(String productId, Exception e) {
        log.warn("Circuit breaker activated for inventory service: {}", e.getMessage());
        // Good fallback options: return stale cache, return "UNKNOWN" status,
        // or show a UI message like "Availability not currently shown"
        return inventoryCache.getLastKnown(productId)
            .orElse(new InventoryResponse(productId, AvailabilityStatus.UNKNOWN, 0));
    }
}
</code></pre>
<p>The YAML configuration gives you fine-grained control over when the circuit trips. The <code>slow-call-rate-threshold</code> is particularly useful ‚Äî a service that responds in 8 seconds is just as harmful as one that throws exceptions, and the circuit can open for slowness, not just errors.</p>
<pre><code class="language-yaml"># application.yml
resilience4j:
  circuitbreaker:
    instances:
      inventory:
        sliding-window-type: COUNT_BASED
        sliding-window-size: 10              # Evaluate the last 10 calls
        failure-rate-threshold: 50           # Open when 5 of last 10 calls fail
        slow-call-rate-threshold: 80         # Also open when 8 of 10 calls are slow
        slow-call-duration-threshold: 3s     # "Slow" means > 3 seconds
        permitted-number-of-calls-in-half-open-state: 3
        wait-duration-in-open-state: 30s
        register-health-indicator: true      # Exposes circuit state in /actuator/health
</code></pre>
<p>With <code>register-health-indicator: true</code>, your Spring Boot <code>/actuator/health</code> endpoint will show the current state of each circuit breaker. This is invaluable during incidents ‚Äî you can see immediately whether a circuit is open and which downstream service is causing it.</p>
<h2>Pattern 2: Retry with Exponential Backoff</h2>
<p>Not all failures are meaningful. A network packet gets dropped, a connection pool momentarily exhausts, a cloud provider briefly throttles a request ‚Äî these happen in production every day and resolve themselves within milliseconds or seconds. Retry with backoff handles this class of failure automatically.</p>
<p>The key word is <strong>exponential</strong> backoff. A flat retry interval (retry every 500ms) keeps hammering the service at the same rate. Exponential backoff doubles the wait time between each retry attempt, giving the downstream service progressively more time to recover: 500ms, then 1 second, then 2 seconds. This self-limiting behaviour is why exponential backoff is the industry standard.</p>
<p>The code below shows combining <code>@Retry</code> with <code>@CircuitBreaker</code> ‚Äî a common production pattern. The retry fires first (for transient failures), and the circuit breaker wraps the entire thing (for persistent failures):</p>
<pre><code class="language-java">@Service
public class PaymentService {

    // Retry is applied "inside" the circuit breaker:
    // 1. If a call fails, retry up to 3 times (Retry)
    // 2. If failure rate across all attempts exceeds threshold, open circuit (CircuitBreaker)
    @Retry(name = "payment", fallbackMethod = "paymentFallback")
    @CircuitBreaker(name = "payment")
    public PaymentResult charge(PaymentRequest request) {
        return paymentClient.charge(request);
    }

    // Called only after all retry attempts are exhausted
    // Returning "pending" is better than failing outright ‚Äî the payment can be retried async
    public PaymentResult paymentFallback(PaymentRequest request, Exception e) {
        asyncRetryQueue.enqueue(request);
        return PaymentResult.pending(request.getOrderId(), "Payment queued for retry");
    }
}
</code></pre>
<p>The YAML configuration for retry is where the subtlety lives. Two decisions matter enormously here: which exceptions to retry (network errors, not business errors), and whether to use jitter.</p>
<pre><code class="language-yaml">resilience4j:
  retry:
    instances:
      payment:
        max-attempts: 3
        wait-duration: 500ms
        enable-exponential-backoff: true
        exponential-backoff-multiplier: 2      # Retry at 500ms, 1s, 2s
        exponential-max-wait-duration: 10s
        retry-exceptions:
          - java.net.ConnectException          # Network-level failures ‚Äî safe to retry
          - java.net.SocketTimeoutException
          - feign.RetryableException
        ignore-exceptions:
          - com.example.PaymentDeclinedException  # Business failure ‚Äî retrying won't help
          - com.example.DuplicatePaymentException # Idempotency error ‚Äî don't retry!
        randomized-wait-factor: 0.5            # Adds jitter: ¬±50% of the wait time
</code></pre>
<p><strong>Why <code>ignore-exceptions</code> matters</strong>: A <code>PaymentDeclinedException</code> means the card was declined ‚Äî retrying three times won't change that outcome, and charging the card three times creates a terrible user experience. Always separate retryable infrastructure errors from non-retryable business errors.</p>
<p><strong>Jitter is critical</strong>: Without jitter, all retrying clients retry at the same time, creating a "thundering herd" that overwhelms the recovering service.</p>
<pre><code>Without jitter (thundering herd):
  T=500ms: All 1000 clients retry simultaneously ‚Üí service gets 1000 requests at once

With jitter (spread load):
  T=250-750ms: Clients retry randomly in this window ‚Üí ~4 requests per millisecond
</code></pre>
<p>With <code>randomized-wait-factor: 0.5</code>, the 500ms wait becomes anywhere from 250ms to 750ms ‚Äî a small change that dramatically reduces retry storm load on the recovering service.</p>
<h2>Pattern 3: Bulkhead ‚Äî Isolation</h2>
<p>The ship's bulkhead divides the hull into watertight compartments. When one compartment floods, the others remain dry and the ship stays afloat. The software pattern does exactly this for thread pools.</p>
<p>Without bulkheads, all downstream calls compete for the same shared thread pool. When the payment service goes slow and its threads don't return, they're borrowed from the pool indefinitely. Eventually the pool is exhausted and every service call fails ‚Äî even inventory checks that have nothing to do with payment.</p>
<pre><code>Without bulkhead:
  Thread pool: 200 threads total
  Slow payment service consumes all 200 threads
  ‚Üí No threads left for inventory, user, order services
  ‚Üí Entire system unresponsive

With bulkhead:
  Payment thread pool: 20 threads (separate pool)
  Other services share remaining 180 threads
  ‚Üí Payment slowness isolated; other services unaffected
</code></pre>
<p>The implementation below uses <code>Bulkhead.Type.THREADPOOL</code>, which gives each downstream service its own dedicated thread pool. Even if payment service threads are all blocked waiting, inventory threads are in a completely separate pool and continue working.</p>
<pre><code class="language-java">@Service
public class OrderOrchestrator {

    // THREADPOOL bulkhead: each downstream service gets its own isolated thread pool
    // If payment service blocks all 20 of its threads, inventory is unaffected
    @Bulkhead(name = "payment", type = Bulkhead.Type.THREADPOOL)
    @CircuitBreaker(name = "payment")
    public CompletableFuture&#x3C;PaymentResult> processPayment(PaymentRequest request) {
        return CompletableFuture.supplyAsync(() -> paymentClient.charge(request));
    }

    @Bulkhead(name = "inventory", type = Bulkhead.Type.THREADPOOL)
    @CircuitBreaker(name = "inventory")
    public CompletableFuture&#x3C;InventoryResult> checkInventory(String productId) {
        return CompletableFuture.supplyAsync(() -> inventoryClient.check(productId));
    }

    public OrderResult createOrder(OrderRequest request) throws Exception {
        // Fan-out: both calls start simultaneously, each in their own bulkhead pool
        // Total time = max(payment_time, inventory_time), not payment_time + inventory_time
        CompletableFuture&#x3C;PaymentResult> paymentFuture = processPayment(request.getPayment());
        CompletableFuture&#x3C;InventoryResult> inventoryFuture = checkInventory(request.getProductId());

        // Wait for both to complete before proceeding
        CompletableFuture.allOf(paymentFuture, inventoryFuture).join();

        return buildOrder(paymentFuture.get(), inventoryFuture.get());
    }
}
</code></pre>
<p>The <code>queue-capacity</code> setting in the YAML below is your overflow valve. When all threads in the pool are busy, new requests queue up to this limit before being rejected. Size it based on how long callers can reasonably wait and how many concurrent requests you expect.</p>
<pre><code class="language-yaml">resilience4j:
  thread-pool-bulkhead:
    instances:
      payment:
        max-thread-pool-size: 20           # Maximum concurrent payment calls
        core-thread-pool-size: 5           # Always-warm thread count
        queue-capacity: 50                 # Queue up to 50 requests before rejecting
        keep-alive-duration: 20ms
      inventory:
        max-thread-pool-size: 30           # Inventory is called more frequently
        core-thread-pool-size: 10
        queue-capacity: 100
</code></pre>
<p>Size your bulkhead pools based on observed concurrency, not guesswork. Run a load test, check how many threads are typically in use, and set the maximum pool to 20-30% above peak. This leaves headroom for spikes while still containing failures.</p>
<h2>Pattern 4: Saga ‚Äî Distributed Transactions</h2>
<p>The trickiest failure scenario in microservices: a multi-step business operation that spans several services. Consider order creation ‚Äî you need to reserve inventory, charge the customer, and confirm the order. In a monolith, you'd wrap all of this in a database transaction and get atomicity for free. In microservices, each service has its own database ‚Äî there's no shared transaction to roll back.</p>
<p>The Saga pattern solves this by breaking the operation into a sequence of <strong>local transactions</strong>, each followed by a <strong>compensating transaction</strong> that reverses the step if a later step fails.</p>
<pre><code>Order creation saga (Choreography-based):

Step 1: Order Service creates order (PENDING)
    ‚Üí publishes "OrderCreated" event

Step 2: Inventory Service reserves stock
    ‚Üí publishes "StockReserved" event
    (if fails ‚Üí publishes "StockReservationFailed")

Step 3: Payment Service charges customer
    ‚Üí publishes "PaymentProcessed" event
    (if fails ‚Üí publishes "PaymentFailed")

Step 4: Order Service updates order to CONFIRMED
    ‚Üí publishes "OrderConfirmed"

Failure handling (compensating transactions):
  PaymentFailed ‚Üí
    Inventory Service: release reserved stock (compensation)
    Order Service: mark order as CANCELLED

  StockReservationFailed ‚Üí
    Order Service: mark order as CANCELLED (no payment taken yet)
</code></pre>
<p>There are two ways to implement Sagas: <strong>choreography</strong> and <strong>orchestration</strong>. Understanding the difference is essential for choosing the right approach.</p>
<p><strong>Choreography</strong> has no central coordinator ‚Äî each service reacts to events and publishes its own. Services are loosely coupled and can evolve independently. The downside is that the overall business flow is difficult to visualise ‚Äî it's spread across multiple services, and tracing a failure requires correlating events from all of them.</p>
<p><strong>Orchestration</strong> has a central saga orchestrator that explicitly tells each service what to do next. The entire business flow lives in one place, making it much easier to understand and debug. The trade-off is a coordination point that must be kept resilient.</p>
<pre><code class="language-java">// === CHOREOGRAPHY: Each service reacts to events independently ===

@Service
public class InventoryService {

    // Listen for orders, reserve stock, emit result
    @KafkaListener(topics = "order-events", filter = "OrderCreated")
    public void handleOrderCreated(OrderCreatedEvent event) {
        try {
            reserveStock(event.getProductId(), event.getQuantity());
            // Success: tell the next participant (Payment Service) to proceed
            kafkaTemplate.send("inventory-events",
                new StockReservedEvent(event.getOrderId(), event.getProductId()));
        } catch (InsufficientStockException e) {
            // Failure: publish a failure event so the saga can compensate
            kafkaTemplate.send("inventory-events",
                new StockReservationFailedEvent(event.getOrderId(), e.getMessage()));
        }
    }

    // Compensating transaction: runs if payment fails AFTER stock was reserved
    // This is what "undoes" the stock reservation to keep data consistent
    @KafkaListener(topics = "payment-events", filter = "PaymentFailed")
    public void handlePaymentFailed(PaymentFailedEvent event) {
        releaseStock(event.getOrderId());
        log.info("Released stock for failed order {}", event.getOrderId());
    }
}

// === ORCHESTRATION: A central orchestrator coordinates the flow ===

@Service
public class OrderSagaOrchestrator {

    @SagaOrchestrationStart
    public void createOrder(OrderRequest request) {
        // The orchestrator explicitly tracks saga state in the database
        // This gives you a single place to see the status of any in-flight order
        OrderSaga saga = OrderSaga.builder()
            .orderId(UUID.randomUUID().toString())
            .request(request)
            .state(SagaState.STARTED)
            .build();

        sagaRepository.save(saga);

        // The orchestrator calls each service in sequence and handles outcomes
        inventoryService.reserve(saga.getOrderId(), request.getProductId(), request.getQuantity())
            .onSuccess(result -> {
                saga.setState(SagaState.INVENTORY_RESERVED);
                sagaRepository.save(saga);  // Persist progress ‚Äî survives restarts
                paymentService.charge(saga.getOrderId(), request.getPayment())
                    .onSuccess(payResult -> confirmOrder(saga))
                    .onFailure(e -> compensateInventory(saga, e));  // Run compensation explicitly
            })
            .onFailure(e -> cancelOrder(saga, "Insufficient stock: " + e.getMessage()));
    }

    private void compensateInventory(OrderSaga saga, Exception e) {
        // Explicitly undo the previous step
        inventoryService.release(saga.getOrderId());
        cancelOrder(saga, "Payment failed: " + e.getMessage());
    }
}
</code></pre>
<p>The orchestration approach saves saga state to the database after each step. This means if the orchestrator process crashes mid-saga, a new instance can pick up from the last saved state and continue from where it left off ‚Äî rather than starting over and potentially double-charging customers.</p>
<p><strong>Which to choose?</strong> For a small number of services with clear ownership, choreography's loose coupling is appealing. For complex flows involving many services, or whenever you need visibility into "where did this order get stuck?", orchestration is worth the added coordination. Most production systems with 4+ saga participants use orchestration.</p>
<h2>Combining Patterns: The Full Resilience Stack</h2>
<p>In production, you combine all four patterns for critical service calls. The annotation order matters because Resilience4j applies them inside-out:</p>
<pre><code class="language-java">// Read the annotations from innermost to outermost:
// Bulkhead ‚Üí TimeLimiter ‚Üí CircuitBreaker ‚Üí Retry
// 1. Bulkhead: assigns this call to the payment thread pool
// 2. TimeLimiter: cuts the call off if it runs longer than N seconds
// 3. CircuitBreaker: tracks failures and opens the circuit if threshold is exceeded
// 4. Retry: if the call fails, tries again (up to max-attempts) before the circuit records it
@CircuitBreaker(name = "payment", fallbackMethod = "paymentFallback")
@Retry(name = "payment")
@Bulkhead(name = "payment", type = Bulkhead.Type.THREADPOOL)
@TimeLimiter(name = "payment")
public CompletableFuture&#x3C;PaymentResult> chargeCustomer(PaymentRequest request) {
    return CompletableFuture.supplyAsync(() -> paymentClient.charge(request));
}
</code></pre>
<p>Why this order? Retry wraps around CircuitBreaker means retries can occur even when the circuit is open ‚Äî which defeats the purpose. The correct order ensures: the Bulkhead limits concurrent threads first, TimeLimiter enforces a hard deadline, CircuitBreaker accumulates failure statistics, and Retry attempts recovery before declaring a failure to the circuit breaker.</p>
<p><strong>Resilience pattern decision guide:</strong></p>
<table>
<thead>
<tr>
<th>Failure Type</th>
<th>Pattern</th>
</tr>
</thead>
<tbody>
<tr>
<td>Transient (network blip)</td>
<td>Retry with backoff</td>
</tr>
<tr>
<td>Persistent downstream failure</td>
<td>Circuit Breaker</td>
</tr>
<tr>
<td>Resource exhaustion</td>
<td>Bulkhead</td>
</tr>
<tr>
<td>Long response times</td>
<td>Timeout + Circuit Breaker</td>
</tr>
<tr>
<td>Multi-step distributed operation</td>
<td>Saga</td>
</tr>
<tr>
<td>All of the above</td>
<td>All of the above</td>
</tr>
</tbody>
</table>
<p>The key insight: <strong>resilience is not about preventing failures, it's about controlling how failures propagate</strong>. Every distributed system will experience failures ‚Äî the question is whether a payment service outage takes down your entire platform or just the checkout flow. These four patterns answer that question.</p>
<p>Start with the circuit breaker and retry ‚Äî they cover the majority of failure scenarios with minimal complexity. Add bulkheads when you identify that one slow service is stealing resources from others. Add sagas when you have multi-step operations that need compensating logic. Apply them incrementally, measure the impact, and only add the next layer when the data shows you need it.</p>
</article><div class="my-10 rounded-xl border border-yellow-200 bg-yellow-50 p-6"><div class="flex items-center gap-2 mb-1"><span class="text-lg">üìö</span><h3 class="text-base font-bold text-gray-900">Recommended Resources</h3></div><div class="space-y-4"><div class="flex items-start gap-3 bg-white rounded-lg p-4 border border-yellow-100"><div class="flex-1 min-w-0"><div class="flex items-center gap-2 flex-wrap mb-1"><span class="font-semibold text-gray-900 text-sm">System Design Interview ‚Äî Alex Xu</span><span class="text-xs bg-blue-100 text-blue-700 px-2 py-0.5 rounded-full font-medium">Best Seller</span></div><p class="text-xs text-gray-600">Step-by-step guide to ace system design interviews with real-world examples.</p></div><a href="https://amzn.to/3TqsPRp" target="_blank" rel="noopener noreferrer" class="flex-shrink-0 text-xs bg-blue-600 text-white px-3 py-2 rounded-lg hover:bg-blue-700 transition-colors font-medium whitespace-nowrap">View on Amazon<!-- --> ‚Üí</a></div><div class="flex items-start gap-3 bg-white rounded-lg p-4 border border-yellow-100"><div class="flex-1 min-w-0"><div class="flex items-center gap-2 flex-wrap mb-1"><span class="font-semibold text-gray-900 text-sm">Grokking System Design on Educative</span></div><p class="text-xs text-gray-600">Interactive course teaching system design with visual diagrams and practice problems.</p></div><a href="https://www.educative.io/courses/grokking-the-system-design-interview" target="_blank" rel="noopener noreferrer" class="flex-shrink-0 text-xs bg-blue-600 text-white px-3 py-2 rounded-lg hover:bg-blue-700 transition-colors font-medium whitespace-nowrap">View Course<!-- --> ‚Üí</a></div><div class="flex items-start gap-3 bg-white rounded-lg p-4 border border-yellow-100"><div class="flex-1 min-w-0"><div class="flex items-center gap-2 flex-wrap mb-1"><span class="font-semibold text-gray-900 text-sm">Designing Data-Intensive Applications</span></div><p class="text-xs text-gray-600">Martin Kleppmann&#x27;s book is essential reading for any system design role.</p></div><a href="https://amzn.to/3RyKzOA" target="_blank" rel="noopener noreferrer" class="flex-shrink-0 text-xs bg-blue-600 text-white px-3 py-2 rounded-lg hover:bg-blue-700 transition-colors font-medium whitespace-nowrap">View on Amazon<!-- --> ‚Üí</a></div></div></div><div class="mt-10 pt-8 border-t border-gray-100"><p class="text-sm text-gray-500 mb-3">Found this useful? Share it:</p><div class="flex gap-3"><a href="https://twitter.com/intent/tweet?text=Microservices%20Patterns%3A%20Circuit%20Breaker%2C%20Retry%2C%20Bulkhead%2C%20and%20Saga&amp;url=https%3A%2F%2Fcodesprintpro.com%2Fblog%2Fmicroservices-patterns%2F" target="_blank" rel="noopener noreferrer" class="text-xs bg-gray-900 text-white px-4 py-2 rounded-lg hover:bg-gray-700 transition-colors">Share on X/Twitter</a><a href="https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fcodesprintpro.com%2Fblog%2Fmicroservices-patterns%2F" target="_blank" rel="noopener noreferrer" class="text-xs bg-blue-600 text-white px-4 py-2 rounded-lg hover:bg-blue-700 transition-colors">Share on LinkedIn</a></div></div></div><aside class="hidden lg:block w-64 flex-shrink-0"><nav class="hidden lg:block sticky top-24"><h4 class="text-xs font-semibold uppercase tracking-widest text-gray-400 mb-3">On This Page</h4><ul class="space-y-1"><li class=""><a href="#why-microservices-fail-differently" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Why Microservices Fail Differently</a></li><li class=""><a href="#pattern-1-circuit-breaker" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Pattern 1: Circuit Breaker</a></li><li class=""><a href="#pattern-2-retry-with-exponential-backoff" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Pattern 2: Retry with Exponential Backoff</a></li><li class=""><a href="#pattern-3-bulkhead-isolation" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Pattern 3: Bulkhead ‚Äî Isolation</a></li><li class=""><a href="#pattern-4-saga-distributed-transactions" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Pattern 4: Saga ‚Äî Distributed Transactions</a></li><li class=""><a href="#combining-patterns-the-full-resilience-stack" class="block text-sm py-1 border-l-2 pl-3 transition-all border-transparent text-gray-500 hover:text-gray-900 hover:border-gray-300 ">Combining Patterns: The Full Resilience Stack</a></li></ul></nav></aside></div><div class="mt-16 pt-10 border-t border-gray-100"><h2 class="text-2xl font-bold text-gray-900 mb-6">Related Articles</h2><div class="grid grid-cols-1 md:grid-cols-3 gap-6"><a href="/blog/observability-opentelemetry-production/"><article class="group bg-white rounded-xl border border-gray-200 p-6 h-full cursor-pointer hover:border-blue-300 hover:shadow-lg transition-all"><span class="inline-block text-xs font-semibold px-3 py-1 rounded-full mb-3 bg-blue-100 text-blue-700">System Design</span><h3 class="text-lg font-bold text-gray-900 mb-2 group-hover:text-blue-600 transition-colors leading-snug">Building Production Observability with OpenTelemetry and Grafana Stack</h3><p class="text-gray-600 text-sm mb-4 line-clamp-3">Observability is not the same as monitoring. Monitoring tells you something is wrong. Observability lets you understand why ‚Äî by exploring system state through metrics, traces, and logs without needing to know in advance‚Ä¶</p><div class="flex items-center justify-between text-xs text-gray-400"><span>Jul 3, 2025</span><span class="flex items-center gap-1"><svg class="w-3 h-3" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>6 min read</span></div><div class="mt-3 flex flex-wrap gap-1"><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->observability</span><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->opentelemetry</span><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->prometheus</span></div></article></a><a href="/blog/event-sourcing-cqrs-production/"><article class="group bg-white rounded-xl border border-gray-200 p-6 h-full cursor-pointer hover:border-blue-300 hover:shadow-lg transition-all"><span class="inline-block text-xs font-semibold px-3 py-1 rounded-full mb-3 bg-blue-100 text-blue-700">System Design</span><h3 class="text-lg font-bold text-gray-900 mb-2 group-hover:text-blue-600 transition-colors leading-snug">Event Sourcing and CQRS in Production: Beyond the Theory</h3><p class="text-gray-600 text-sm mb-4 line-clamp-3">Event sourcing is one of those patterns that looks elegant in conference talks and becomes surprisingly complex in production systems. The theory ‚Äî store events instead of state, derive state by replaying events ‚Äî is sou‚Ä¶</p><div class="flex items-center justify-between text-xs text-gray-400"><span>Jun 23, 2025</span><span class="flex items-center gap-1"><svg class="w-3 h-3" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>7 min read</span></div><div class="mt-3 flex flex-wrap gap-1"><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->event sourcing</span><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->cqrs</span><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->system design</span></div></article></a><a href="/blog/grpc-vs-rest-vs-graphql/"><article class="group bg-white rounded-xl border border-gray-200 p-6 h-full cursor-pointer hover:border-blue-300 hover:shadow-lg transition-all"><span class="inline-block text-xs font-semibold px-3 py-1 rounded-full mb-3 bg-blue-100 text-blue-700">System Design</span><h3 class="text-lg font-bold text-gray-900 mb-2 group-hover:text-blue-600 transition-colors leading-snug">gRPC vs REST vs GraphQL: Choosing the Right API Protocol</h3><p class="text-gray-600 text-sm mb-4 line-clamp-3">API protocol selection has a longer lifespan than almost any other technical decision. REST APIs from 2010 are still running in production. gRPC services chosen for internal communication in 2018 are tightly coupled to t‚Ä¶</p><div class="flex items-center justify-between text-xs text-gray-400"><span>Jun 18, 2025</span><span class="flex items-center gap-1"><svg class="w-3 h-3" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>7 min read</span></div><div class="mt-3 flex flex-wrap gap-1"><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->grpc</span><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->rest</span><span class="text-xs text-gray-500 bg-gray-50 px-2 py-0.5 rounded border border-gray-100">#<!-- -->graphql</span></div></article></a></div></div><div class="mt-12 text-center"><a class="inline-flex items-center gap-2 text-blue-600 hover:text-blue-700 font-medium transition-colors" href="/blog/">‚Üê Back to all articles</a></div></div></div><footer class="bg-gray-900 text-white py-12"><div class="container mx-auto px-4 sm:px-6 lg:px-8"><div class="grid grid-cols-1 md:grid-cols-4 gap-8 mb-8"><div class="col-span-1 md:col-span-1"><div><a class="text-xl font-bold block mb-3 text-white hover:text-blue-400 transition-colors" href="/">CodeSprintPro</a></div><p class="text-gray-400 text-sm mb-4 leading-relaxed">Deep-dive technical content on System Design, Java, Databases, AI/ML, and AWS ‚Äî by Sachin Sarawgi.</p><div class="flex space-x-4"><a href="https://github.com/codesprintpro" target="_blank" rel="noopener noreferrer" class="text-gray-400 hover:text-white transition-colors" aria-label="Visit GitHub profile"><i class="fab fa-github text-xl"></i></a><a href="https://www.linkedin.com/in/sachin-sarawgi/" target="_blank" rel="noopener noreferrer" class="text-gray-400 hover:text-white transition-colors" aria-label="Visit LinkedIn profile"><i class="fab fa-linkedin text-xl"></i></a><a href="https://medium.com/@codesprintpro" target="_blank" rel="noopener noreferrer" class="text-gray-400 hover:text-white transition-colors" aria-label="Visit Medium profile"><i class="fab fa-medium text-xl"></i></a></div></div><div><h3 class="text-sm font-semibold uppercase tracking-widest text-gray-400 mb-4">Quick Links</h3><ul class="space-y-2"><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">Blog</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/#about">About</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/#portfolio">Portfolio</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/#contact">Contact</a></div></li></ul></div><div><h3 class="text-sm font-semibold uppercase tracking-widest text-gray-400 mb-4">Categories</h3><ul class="space-y-2"><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">System Design</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">Java</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">Databases</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">AI/ML</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">AWS</a></div></li><li><div><a class="text-gray-400 hover:text-white transition-colors text-sm" href="/blog/">Messaging</a></div></li></ul></div><div><h3 class="text-sm font-semibold uppercase tracking-widest text-gray-400 mb-4">Contact</h3><ul class="space-y-2 text-gray-400 text-sm"><li><a href="mailto:sachinsarawgi201143@gmail.com" class="hover:text-white transition-colors flex items-center gap-2"><i class="fas fa-envelope"></i> Email</a></li><li><a href="https://www.linkedin.com/in/sachin-sarawgi/" target="_blank" rel="noopener noreferrer" class="hover:text-white transition-colors flex items-center gap-2"><i class="fab fa-linkedin"></i> LinkedIn</a></li><li><a href="https://github.com/codesprintpro" target="_blank" rel="noopener noreferrer" class="hover:text-white transition-colors flex items-center gap-2"><i class="fab fa-github"></i> GitHub</a></li></ul></div></div><div class="border-t border-gray-800 pt-6 flex flex-col md:flex-row justify-between items-center gap-2"><p class="text-gray-500 text-sm">¬© <!-- -->2026<!-- --> CodeSprintPro ¬∑ Sachin Sarawgi. All rights reserved.</p><p class="text-gray-600 text-xs">Built with Next.js ¬∑ TailwindCSS ¬∑ Deployed on GitHub Pages</p></div></div></footer></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"Microservices Patterns: Circuit Breaker, Retry, Bulkhead, and Saga","description":"Master the resilience patterns that keep microservices systems running when individual services fail. Covers circuit breaker, retry with backoff, bulkhead isolation, and distributed transactions with Saga.","date":"2025-02-28","category":"System Design","tags":["microservices","resilience","circuit breaker","saga","distributed systems","spring boot"],"featured":false,"affiliateSection":"system-design-courses","slug":"microservices-patterns","readingTime":"14 min read","excerpt":"A monolith fails as a unit ‚Äî one process, one crash, everything stops. A microservices system fails differently: some services go down, some slow to a crawl, some remain perfectly healthy. This partial-failure behaviour ‚Ä¶","contentHtml":"\u003cp\u003eA monolith fails as a unit ‚Äî one process, one crash, everything stops. A microservices system fails differently: some services go down, some slow to a crawl, some remain perfectly healthy. This partial-failure behaviour is actually harder to deal with than total failure, because the system is still \u003cem\u003epartially\u003c/em\u003e up and clients keep sending requests into the degraded parts.\u003c/p\u003e\n\u003cp\u003eWithout resilience patterns, one slow service can bring down your entire system in minutes through a mechanism called cascading failure. With the right patterns applied correctly, the system degrades gracefully ‚Äî the slow payment service becomes temporarily unavailable to users, while inventory browsing, cart management, and search continue working normally. This article covers the four patterns that make that possible, with Spring Boot + Resilience4j implementations.\u003c/p\u003e\n\u003ch2\u003eWhy Microservices Fail Differently\u003c/h2\u003e\n\u003cp\u003eThe most dangerous failure mode in distributed systems is not an immediate crash ‚Äî it's a slow response. A service that returns an error immediately frees the calling thread right away. A service that hangs for 10 seconds holds a thread for 10 seconds, and at high load those threads accumulate until the thread pool is exhausted.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eMonolith failure: Everything fails at once (simple, but total)\n\nMicroservice failure cascade:\n  Order Service calls Inventory Service calls Warehouse Service\n\n  Warehouse Service goes slow (200ms ‚Üí 10s response time)\n  Inventory Service threads pile up waiting for Warehouse\n  Order Service threads pile up waiting for Inventory\n  All three services become unresponsive\n  ‚Üí Entire system down, from one slow service\n\nThis is \"cascading failure\" ‚Äî the #1 microservices operational problem.\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe patterns below address cascading failure at different levels. The circuit breaker stops calls to a failing service. Retry handles transient blips before they reach the circuit breaker. The bulkhead contains failures to one partition of the system. Saga coordinates the cleanup when a multi-step operation fails partway through.\u003c/p\u003e\n\u003ch2\u003ePattern 1: Circuit Breaker\u003c/h2\u003e\n\u003cp\u003eThe circuit breaker is named after the electrical component that trips when a circuit overloads, preventing damage. The software version does the same: when calls to a downstream service start failing at a high rate, the circuit breaker \u003cstrong\u003eopens\u003c/strong\u003e and immediately returns an error to callers ‚Äî without actually calling the downstream service. This gives the failing service breathing room to recover while protecting the calling service's threads.\u003c/p\u003e\n\u003cp\u003eThe three states are the heart of the pattern:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eCircuit states:\n  CLOSED: Normal operation ‚Äî calls pass through\n  OPEN: Failure threshold exceeded ‚Äî calls fail immediately (fast fail)\n  HALF-OPEN: Trial period ‚Äî limited calls allowed to test recovery\n\nState transitions:\n  CLOSED ‚Üí OPEN: When failure rate \u003e threshold (e.g., 50% of last 10 calls failed)\n  OPEN ‚Üí HALF-OPEN: After wait duration (e.g., 30 seconds)\n  HALF-OPEN ‚Üí CLOSED: If trial calls succeed\n  HALF-OPEN ‚Üí OPEN: If trial calls fail\n\nTimeline:\n  0s:  Normal. All calls succeed.\n  30s: Downstream service starts failing.\n  35s: Failure rate hits 50% ‚Üí Circuit OPENS.\n  35s-65s: All calls fail immediately (fast fail), downstream gets no load.\n  65s: Circuit HALF-OPENS, 3 trial calls allowed.\n  66s: Trial calls succeed ‚Üí Circuit CLOSES.\n  66s+: Normal operation resumes.\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe HALF-OPEN state is subtle but important. Without it, a circuit that opens would never close ‚Äî you'd need manual intervention to restore service. HALF-OPEN is the automatic recovery probe: after the wait duration, the circuit allows a small number of test calls through. If they succeed, normal operation resumes. If they fail, the circuit opens again and waits longer.\u003c/p\u003e\n\u003cp\u003eThe \u003ccode\u003e@CircuitBreaker\u003c/code\u003e annotation in Resilience4j wires all of this up automatically. The \u003ccode\u003efallbackMethod\u003c/code\u003e is the method called when the circuit is open or when all retries are exhausted ‚Äî it's your graceful degradation path.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003e// build.gradle\n// implementation 'io.github.resilience4j:resilience4j-spring-boot3:2.2.0'\n\n@Service\npublic class InventoryService {\n\n    private final CircuitBreakerRegistry circuitBreakerRegistry;\n    private final InventoryClient inventoryClient;\n\n    public InventoryService(CircuitBreakerRegistry registry, InventoryClient client) {\n        this.circuitBreakerRegistry = registry;\n        this.inventoryClient = client;\n    }\n\n    @CircuitBreaker(name = \"inventory\", fallbackMethod = \"getInventoryFallback\")\n    public InventoryResponse checkInventory(String productId) {\n        return inventoryClient.check(productId);\n    }\n\n    // The fallback runs when: circuit is OPEN, or a call fails (and no retry is configured)\n    // Its signature must match the original method plus an Exception parameter\n    public InventoryResponse getInventoryFallback(String productId, Exception e) {\n        log.warn(\"Circuit breaker activated for inventory service: {}\", e.getMessage());\n        // Good fallback options: return stale cache, return \"UNKNOWN\" status,\n        // or show a UI message like \"Availability not currently shown\"\n        return inventoryCache.getLastKnown(productId)\n            .orElse(new InventoryResponse(productId, AvailabilityStatus.UNKNOWN, 0));\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe YAML configuration gives you fine-grained control over when the circuit trips. The \u003ccode\u003eslow-call-rate-threshold\u003c/code\u003e is particularly useful ‚Äî a service that responds in 8 seconds is just as harmful as one that throws exceptions, and the circuit can open for slowness, not just errors.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-yaml\"\u003e# application.yml\nresilience4j:\n  circuitbreaker:\n    instances:\n      inventory:\n        sliding-window-type: COUNT_BASED\n        sliding-window-size: 10              # Evaluate the last 10 calls\n        failure-rate-threshold: 50           # Open when 5 of last 10 calls fail\n        slow-call-rate-threshold: 80         # Also open when 8 of 10 calls are slow\n        slow-call-duration-threshold: 3s     # \"Slow\" means \u003e 3 seconds\n        permitted-number-of-calls-in-half-open-state: 3\n        wait-duration-in-open-state: 30s\n        register-health-indicator: true      # Exposes circuit state in /actuator/health\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWith \u003ccode\u003eregister-health-indicator: true\u003c/code\u003e, your Spring Boot \u003ccode\u003e/actuator/health\u003c/code\u003e endpoint will show the current state of each circuit breaker. This is invaluable during incidents ‚Äî you can see immediately whether a circuit is open and which downstream service is causing it.\u003c/p\u003e\n\u003ch2\u003ePattern 2: Retry with Exponential Backoff\u003c/h2\u003e\n\u003cp\u003eNot all failures are meaningful. A network packet gets dropped, a connection pool momentarily exhausts, a cloud provider briefly throttles a request ‚Äî these happen in production every day and resolve themselves within milliseconds or seconds. Retry with backoff handles this class of failure automatically.\u003c/p\u003e\n\u003cp\u003eThe key word is \u003cstrong\u003eexponential\u003c/strong\u003e backoff. A flat retry interval (retry every 500ms) keeps hammering the service at the same rate. Exponential backoff doubles the wait time between each retry attempt, giving the downstream service progressively more time to recover: 500ms, then 1 second, then 2 seconds. This self-limiting behaviour is why exponential backoff is the industry standard.\u003c/p\u003e\n\u003cp\u003eThe code below shows combining \u003ccode\u003e@Retry\u003c/code\u003e with \u003ccode\u003e@CircuitBreaker\u003c/code\u003e ‚Äî a common production pattern. The retry fires first (for transient failures), and the circuit breaker wraps the entire thing (for persistent failures):\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003e@Service\npublic class PaymentService {\n\n    // Retry is applied \"inside\" the circuit breaker:\n    // 1. If a call fails, retry up to 3 times (Retry)\n    // 2. If failure rate across all attempts exceeds threshold, open circuit (CircuitBreaker)\n    @Retry(name = \"payment\", fallbackMethod = \"paymentFallback\")\n    @CircuitBreaker(name = \"payment\")\n    public PaymentResult charge(PaymentRequest request) {\n        return paymentClient.charge(request);\n    }\n\n    // Called only after all retry attempts are exhausted\n    // Returning \"pending\" is better than failing outright ‚Äî the payment can be retried async\n    public PaymentResult paymentFallback(PaymentRequest request, Exception e) {\n        asyncRetryQueue.enqueue(request);\n        return PaymentResult.pending(request.getOrderId(), \"Payment queued for retry\");\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe YAML configuration for retry is where the subtlety lives. Two decisions matter enormously here: which exceptions to retry (network errors, not business errors), and whether to use jitter.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-yaml\"\u003eresilience4j:\n  retry:\n    instances:\n      payment:\n        max-attempts: 3\n        wait-duration: 500ms\n        enable-exponential-backoff: true\n        exponential-backoff-multiplier: 2      # Retry at 500ms, 1s, 2s\n        exponential-max-wait-duration: 10s\n        retry-exceptions:\n          - java.net.ConnectException          # Network-level failures ‚Äî safe to retry\n          - java.net.SocketTimeoutException\n          - feign.RetryableException\n        ignore-exceptions:\n          - com.example.PaymentDeclinedException  # Business failure ‚Äî retrying won't help\n          - com.example.DuplicatePaymentException # Idempotency error ‚Äî don't retry!\n        randomized-wait-factor: 0.5            # Adds jitter: ¬±50% of the wait time\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eWhy \u003ccode\u003eignore-exceptions\u003c/code\u003e matters\u003c/strong\u003e: A \u003ccode\u003ePaymentDeclinedException\u003c/code\u003e means the card was declined ‚Äî retrying three times won't change that outcome, and charging the card three times creates a terrible user experience. Always separate retryable infrastructure errors from non-retryable business errors.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eJitter is critical\u003c/strong\u003e: Without jitter, all retrying clients retry at the same time, creating a \"thundering herd\" that overwhelms the recovering service.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eWithout jitter (thundering herd):\n  T=500ms: All 1000 clients retry simultaneously ‚Üí service gets 1000 requests at once\n\nWith jitter (spread load):\n  T=250-750ms: Clients retry randomly in this window ‚Üí ~4 requests per millisecond\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWith \u003ccode\u003erandomized-wait-factor: 0.5\u003c/code\u003e, the 500ms wait becomes anywhere from 250ms to 750ms ‚Äî a small change that dramatically reduces retry storm load on the recovering service.\u003c/p\u003e\n\u003ch2\u003ePattern 3: Bulkhead ‚Äî Isolation\u003c/h2\u003e\n\u003cp\u003eThe ship's bulkhead divides the hull into watertight compartments. When one compartment floods, the others remain dry and the ship stays afloat. The software pattern does exactly this for thread pools.\u003c/p\u003e\n\u003cp\u003eWithout bulkheads, all downstream calls compete for the same shared thread pool. When the payment service goes slow and its threads don't return, they're borrowed from the pool indefinitely. Eventually the pool is exhausted and every service call fails ‚Äî even inventory checks that have nothing to do with payment.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eWithout bulkhead:\n  Thread pool: 200 threads total\n  Slow payment service consumes all 200 threads\n  ‚Üí No threads left for inventory, user, order services\n  ‚Üí Entire system unresponsive\n\nWith bulkhead:\n  Payment thread pool: 20 threads (separate pool)\n  Other services share remaining 180 threads\n  ‚Üí Payment slowness isolated; other services unaffected\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe implementation below uses \u003ccode\u003eBulkhead.Type.THREADPOOL\u003c/code\u003e, which gives each downstream service its own dedicated thread pool. Even if payment service threads are all blocked waiting, inventory threads are in a completely separate pool and continue working.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003e@Service\npublic class OrderOrchestrator {\n\n    // THREADPOOL bulkhead: each downstream service gets its own isolated thread pool\n    // If payment service blocks all 20 of its threads, inventory is unaffected\n    @Bulkhead(name = \"payment\", type = Bulkhead.Type.THREADPOOL)\n    @CircuitBreaker(name = \"payment\")\n    public CompletableFuture\u0026#x3C;PaymentResult\u003e processPayment(PaymentRequest request) {\n        return CompletableFuture.supplyAsync(() -\u003e paymentClient.charge(request));\n    }\n\n    @Bulkhead(name = \"inventory\", type = Bulkhead.Type.THREADPOOL)\n    @CircuitBreaker(name = \"inventory\")\n    public CompletableFuture\u0026#x3C;InventoryResult\u003e checkInventory(String productId) {\n        return CompletableFuture.supplyAsync(() -\u003e inventoryClient.check(productId));\n    }\n\n    public OrderResult createOrder(OrderRequest request) throws Exception {\n        // Fan-out: both calls start simultaneously, each in their own bulkhead pool\n        // Total time = max(payment_time, inventory_time), not payment_time + inventory_time\n        CompletableFuture\u0026#x3C;PaymentResult\u003e paymentFuture = processPayment(request.getPayment());\n        CompletableFuture\u0026#x3C;InventoryResult\u003e inventoryFuture = checkInventory(request.getProductId());\n\n        // Wait for both to complete before proceeding\n        CompletableFuture.allOf(paymentFuture, inventoryFuture).join();\n\n        return buildOrder(paymentFuture.get(), inventoryFuture.get());\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe \u003ccode\u003equeue-capacity\u003c/code\u003e setting in the YAML below is your overflow valve. When all threads in the pool are busy, new requests queue up to this limit before being rejected. Size it based on how long callers can reasonably wait and how many concurrent requests you expect.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-yaml\"\u003eresilience4j:\n  thread-pool-bulkhead:\n    instances:\n      payment:\n        max-thread-pool-size: 20           # Maximum concurrent payment calls\n        core-thread-pool-size: 5           # Always-warm thread count\n        queue-capacity: 50                 # Queue up to 50 requests before rejecting\n        keep-alive-duration: 20ms\n      inventory:\n        max-thread-pool-size: 30           # Inventory is called more frequently\n        core-thread-pool-size: 10\n        queue-capacity: 100\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eSize your bulkhead pools based on observed concurrency, not guesswork. Run a load test, check how many threads are typically in use, and set the maximum pool to 20-30% above peak. This leaves headroom for spikes while still containing failures.\u003c/p\u003e\n\u003ch2\u003ePattern 4: Saga ‚Äî Distributed Transactions\u003c/h2\u003e\n\u003cp\u003eThe trickiest failure scenario in microservices: a multi-step business operation that spans several services. Consider order creation ‚Äî you need to reserve inventory, charge the customer, and confirm the order. In a monolith, you'd wrap all of this in a database transaction and get atomicity for free. In microservices, each service has its own database ‚Äî there's no shared transaction to roll back.\u003c/p\u003e\n\u003cp\u003eThe Saga pattern solves this by breaking the operation into a sequence of \u003cstrong\u003elocal transactions\u003c/strong\u003e, each followed by a \u003cstrong\u003ecompensating transaction\u003c/strong\u003e that reverses the step if a later step fails.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eOrder creation saga (Choreography-based):\n\nStep 1: Order Service creates order (PENDING)\n    ‚Üí publishes \"OrderCreated\" event\n\nStep 2: Inventory Service reserves stock\n    ‚Üí publishes \"StockReserved\" event\n    (if fails ‚Üí publishes \"StockReservationFailed\")\n\nStep 3: Payment Service charges customer\n    ‚Üí publishes \"PaymentProcessed\" event\n    (if fails ‚Üí publishes \"PaymentFailed\")\n\nStep 4: Order Service updates order to CONFIRMED\n    ‚Üí publishes \"OrderConfirmed\"\n\nFailure handling (compensating transactions):\n  PaymentFailed ‚Üí\n    Inventory Service: release reserved stock (compensation)\n    Order Service: mark order as CANCELLED\n\n  StockReservationFailed ‚Üí\n    Order Service: mark order as CANCELLED (no payment taken yet)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThere are two ways to implement Sagas: \u003cstrong\u003echoreography\u003c/strong\u003e and \u003cstrong\u003eorchestration\u003c/strong\u003e. Understanding the difference is essential for choosing the right approach.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eChoreography\u003c/strong\u003e has no central coordinator ‚Äî each service reacts to events and publishes its own. Services are loosely coupled and can evolve independently. The downside is that the overall business flow is difficult to visualise ‚Äî it's spread across multiple services, and tracing a failure requires correlating events from all of them.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eOrchestration\u003c/strong\u003e has a central saga orchestrator that explicitly tells each service what to do next. The entire business flow lives in one place, making it much easier to understand and debug. The trade-off is a coordination point that must be kept resilient.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003e// === CHOREOGRAPHY: Each service reacts to events independently ===\n\n@Service\npublic class InventoryService {\n\n    // Listen for orders, reserve stock, emit result\n    @KafkaListener(topics = \"order-events\", filter = \"OrderCreated\")\n    public void handleOrderCreated(OrderCreatedEvent event) {\n        try {\n            reserveStock(event.getProductId(), event.getQuantity());\n            // Success: tell the next participant (Payment Service) to proceed\n            kafkaTemplate.send(\"inventory-events\",\n                new StockReservedEvent(event.getOrderId(), event.getProductId()));\n        } catch (InsufficientStockException e) {\n            // Failure: publish a failure event so the saga can compensate\n            kafkaTemplate.send(\"inventory-events\",\n                new StockReservationFailedEvent(event.getOrderId(), e.getMessage()));\n        }\n    }\n\n    // Compensating transaction: runs if payment fails AFTER stock was reserved\n    // This is what \"undoes\" the stock reservation to keep data consistent\n    @KafkaListener(topics = \"payment-events\", filter = \"PaymentFailed\")\n    public void handlePaymentFailed(PaymentFailedEvent event) {\n        releaseStock(event.getOrderId());\n        log.info(\"Released stock for failed order {}\", event.getOrderId());\n    }\n}\n\n// === ORCHESTRATION: A central orchestrator coordinates the flow ===\n\n@Service\npublic class OrderSagaOrchestrator {\n\n    @SagaOrchestrationStart\n    public void createOrder(OrderRequest request) {\n        // The orchestrator explicitly tracks saga state in the database\n        // This gives you a single place to see the status of any in-flight order\n        OrderSaga saga = OrderSaga.builder()\n            .orderId(UUID.randomUUID().toString())\n            .request(request)\n            .state(SagaState.STARTED)\n            .build();\n\n        sagaRepository.save(saga);\n\n        // The orchestrator calls each service in sequence and handles outcomes\n        inventoryService.reserve(saga.getOrderId(), request.getProductId(), request.getQuantity())\n            .onSuccess(result -\u003e {\n                saga.setState(SagaState.INVENTORY_RESERVED);\n                sagaRepository.save(saga);  // Persist progress ‚Äî survives restarts\n                paymentService.charge(saga.getOrderId(), request.getPayment())\n                    .onSuccess(payResult -\u003e confirmOrder(saga))\n                    .onFailure(e -\u003e compensateInventory(saga, e));  // Run compensation explicitly\n            })\n            .onFailure(e -\u003e cancelOrder(saga, \"Insufficient stock: \" + e.getMessage()));\n    }\n\n    private void compensateInventory(OrderSaga saga, Exception e) {\n        // Explicitly undo the previous step\n        inventoryService.release(saga.getOrderId());\n        cancelOrder(saga, \"Payment failed: \" + e.getMessage());\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe orchestration approach saves saga state to the database after each step. This means if the orchestrator process crashes mid-saga, a new instance can pick up from the last saved state and continue from where it left off ‚Äî rather than starting over and potentially double-charging customers.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eWhich to choose?\u003c/strong\u003e For a small number of services with clear ownership, choreography's loose coupling is appealing. For complex flows involving many services, or whenever you need visibility into \"where did this order get stuck?\", orchestration is worth the added coordination. Most production systems with 4+ saga participants use orchestration.\u003c/p\u003e\n\u003ch2\u003eCombining Patterns: The Full Resilience Stack\u003c/h2\u003e\n\u003cp\u003eIn production, you combine all four patterns for critical service calls. The annotation order matters because Resilience4j applies them inside-out:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003e// Read the annotations from innermost to outermost:\n// Bulkhead ‚Üí TimeLimiter ‚Üí CircuitBreaker ‚Üí Retry\n// 1. Bulkhead: assigns this call to the payment thread pool\n// 2. TimeLimiter: cuts the call off if it runs longer than N seconds\n// 3. CircuitBreaker: tracks failures and opens the circuit if threshold is exceeded\n// 4. Retry: if the call fails, tries again (up to max-attempts) before the circuit records it\n@CircuitBreaker(name = \"payment\", fallbackMethod = \"paymentFallback\")\n@Retry(name = \"payment\")\n@Bulkhead(name = \"payment\", type = Bulkhead.Type.THREADPOOL)\n@TimeLimiter(name = \"payment\")\npublic CompletableFuture\u0026#x3C;PaymentResult\u003e chargeCustomer(PaymentRequest request) {\n    return CompletableFuture.supplyAsync(() -\u003e paymentClient.charge(request));\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWhy this order? Retry wraps around CircuitBreaker means retries can occur even when the circuit is open ‚Äî which defeats the purpose. The correct order ensures: the Bulkhead limits concurrent threads first, TimeLimiter enforces a hard deadline, CircuitBreaker accumulates failure statistics, and Retry attempts recovery before declaring a failure to the circuit breaker.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eResilience pattern decision guide:\u003c/strong\u003e\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eFailure Type\u003c/th\u003e\n\u003cth\u003ePattern\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eTransient (network blip)\u003c/td\u003e\n\u003ctd\u003eRetry with backoff\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ePersistent downstream failure\u003c/td\u003e\n\u003ctd\u003eCircuit Breaker\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eResource exhaustion\u003c/td\u003e\n\u003ctd\u003eBulkhead\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eLong response times\u003c/td\u003e\n\u003ctd\u003eTimeout + Circuit Breaker\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eMulti-step distributed operation\u003c/td\u003e\n\u003ctd\u003eSaga\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eAll of the above\u003c/td\u003e\n\u003ctd\u003eAll of the above\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003eThe key insight: \u003cstrong\u003eresilience is not about preventing failures, it's about controlling how failures propagate\u003c/strong\u003e. Every distributed system will experience failures ‚Äî the question is whether a payment service outage takes down your entire platform or just the checkout flow. These four patterns answer that question.\u003c/p\u003e\n\u003cp\u003eStart with the circuit breaker and retry ‚Äî they cover the majority of failure scenarios with minimal complexity. Add bulkheads when you identify that one slow service is stealing resources from others. Add sagas when you have multi-step operations that need compensating logic. Apply them incrementally, measure the impact, and only add the next layer when the data shows you need it.\u003c/p\u003e\n","tableOfContents":[{"id":"why-microservices-fail-differently","text":"Why Microservices Fail Differently","level":2},{"id":"pattern-1-circuit-breaker","text":"Pattern 1: Circuit Breaker","level":2},{"id":"pattern-2-retry-with-exponential-backoff","text":"Pattern 2: Retry with Exponential Backoff","level":2},{"id":"pattern-3-bulkhead-isolation","text":"Pattern 3: Bulkhead ‚Äî Isolation","level":2},{"id":"pattern-4-saga-distributed-transactions","text":"Pattern 4: Saga ‚Äî Distributed Transactions","level":2},{"id":"combining-patterns-the-full-resilience-stack","text":"Combining Patterns: The Full Resilience Stack","level":2}]},"relatedPosts":[{"title":"Building Production Observability with OpenTelemetry and Grafana Stack","description":"End-to-end observability implementation: distributed tracing with OpenTelemetry, metrics with Prometheus, structured logging with Loki, and the dashboards and alerts that actually help during incidents.","date":"2025-07-03","category":"System Design","tags":["observability","opentelemetry","prometheus","grafana","loki","tracing","spring boot","monitoring"],"featured":false,"affiliateSection":"system-design-courses","slug":"observability-opentelemetry-production","readingTime":"6 min read","excerpt":"Observability is not the same as monitoring. Monitoring tells you something is wrong. Observability lets you understand why ‚Äî by exploring system state through metrics, traces, and logs without needing to know in advance‚Ä¶"},{"title":"Event Sourcing and CQRS in Production: Beyond the Theory","description":"What event sourcing actually looks like in production Java systems: event store design, snapshot strategies, projection rebuilding, CQRS read model synchronization, and the operational challenges nobody talks about.","date":"2025-06-23","category":"System Design","tags":["event sourcing","cqrs","system design","java","distributed systems","kafka","spring boot"],"featured":false,"affiliateSection":"distributed-systems-books","slug":"event-sourcing-cqrs-production","readingTime":"7 min read","excerpt":"Event sourcing is one of those patterns that looks elegant in conference talks and becomes surprisingly complex in production systems. The theory ‚Äî store events instead of state, derive state by replaying events ‚Äî is sou‚Ä¶"},{"title":"gRPC vs REST vs GraphQL: Choosing the Right API Protocol","description":"A technical comparison of REST, gRPC, and GraphQL across performance, developer experience, schema evolution, streaming, and real production use cases. When each protocol wins and where each falls short.","date":"2025-06-18","category":"System Design","tags":["grpc","rest","graphql","api design","system design","microservices","protocol buffers"],"featured":false,"affiliateSection":"system-design-courses","slug":"grpc-vs-rest-vs-graphql","readingTime":"7 min read","excerpt":"API protocol selection has a longer lifespan than almost any other technical decision. REST APIs from 2010 are still running in production. gRPC services chosen for internal communication in 2018 are tightly coupled to t‚Ä¶"}]},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"microservices-patterns"},"buildId":"rpFn_jslWZ9qPkJwor7RD","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>